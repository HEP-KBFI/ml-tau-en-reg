{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da35eee-d75a-4baa-a21c-796afbe7c71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import mplhep as hep\n",
    "import awkward as ak\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hep.style.use(hep.styles.CMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933cb07-de04-440e-8d9b-07cdfb17f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRACS = [\"2e3\", \"1e4\", \"1e5\", \"1e6\"]\n",
    "MODEL_TYPES = {\n",
    "    'fine_tuning': \"Fine-tuning\",\n",
    "    'from_scratch': \"From scratch\",\n",
    "    'fixed_backbone': \"Fine-tuning \\n(fixed backbone)\",\n",
    "    \n",
    "}\n",
    "TRAINING_TYPES = ['jet_regression', 'dm_multiclass', \"binary_classification\"]\n",
    "PERFORMANCE_KEYS = {\n",
    "    \"jet_regression\": [\"loss_validation\", \"IQR_validation\", \"median_validation\"],\n",
    "    \"binary_classification\": [\"loss_validation\", \"precision_validation\", \"recall_validation\", \"F1_validation\"],\n",
    "    \"dm_multiclass\": [\"loss_validation\", \"precision_validation\", \"recall_validation\", \"F1_validation\"]\n",
    "}\n",
    "Y_LABELS = {\n",
    "    \"IQR_validation\": r\"$p_T \\, \\, resol. (q_{75} - q_{25})/q_{50}$\",\n",
    "    \"median_validation\": r\"$p_T scale (q_{50})$\",\n",
    "    \"precision_validation\": \"precision\",\n",
    "    \"recall_validation\": \"recall\",\n",
    "    \"F1_validation\": \"F1\",\n",
    "    \"loss_validation\": \"validation loss\"\n",
    "}\n",
    "\n",
    "COLORS = {\n",
    "    \"fine_tuning\": \"green\",\n",
    "    \"from_scratch\": \"red\",\n",
    "    \"fixed_backbone\": \"blue\",\n",
    "}\n",
    "EPOCH_COLORS = {\n",
    "    \"epoch_0\": \"green\",\n",
    "    \"epoch_30\": \"red\",\n",
    "    \"epoch_60\": \"magenta\",\n",
    "    \"fixed_backbone\": \"blue\",\n",
    "}\n",
    "LAYER_COLORS = {\n",
    "    \"GPT_layers_1\": \"green\",\n",
    "    \"GPT_layers_2\": \"red\",\n",
    "    \"GPT_layers_3\": \"blue\",\n",
    "}\n",
    "\n",
    "\n",
    "EPOCH_0_UNFREEZE_DIR = \"/home/laurits/ml-tau-en-reg/training-outputs/20250119_unfreeze_epoch_0/\"\n",
    "EPOCH_60_UNFREEZE_DIR = \"/home/laurits/ml-tau-en-reg/training-outputs/20250123_unfreeze_epoch_60/\"\n",
    "BASE_DIR = \"/home/laurits/ml-tau-en-reg/training-outputs/20201204_ParT_ntrain_v2\"\n",
    "GPT_LAYERS_1_DIR = \"/home/laurits/ml-tau-en-reg/training-outputs/20250119_GPT_Layers_1/\"\n",
    "GPT_LAYERS_2_DIR = \"/home/laurits/ml-tau-en-reg/training-outputs/20250119_GPT_Layers_2/\"\n",
    "OUTPUT_DIR = \"/home/laurits/20250203_OmniParT_effects\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070ada60-e7a9-4da0-8a5a-5b21f8b43b65",
   "metadata": {},
   "source": [
    "# Effects of unfreezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1202a892-c56e-4243-9dd9-406a7948edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_dirs = {\n",
    "    \"epoch_0\": EPOCH_0_UNFREEZE_DIR,\n",
    "    \"epoch_30\": BASE_DIR,\n",
    "    \"epoch_60\": EPOCH_60_UNFREEZE_DIR,\n",
    "    \"fixed_backbone\": BASE_DIR\n",
    "}\n",
    "\n",
    "epoch_name_mapping = {\n",
    "    \"epoch_0\": \"Epoch 0\",\n",
    "    \"epoch_30\": \"Epoch 30\",\n",
    "    \"epoch_60\": \"Epoch 60\",\n",
    "    \"fixed_backbone\": \"Frozen\"\n",
    "}\n",
    "\n",
    "\n",
    "def calculate_scenario_measures(wcp_path, keys):\n",
    "    model_metrics = {key: {} for key in keys}\n",
    "    metric_values = {key: [] for key in keys}\n",
    "    for metrics_path in glob.glob(wcp_path):  # Loop over all runs (v_1, .. v_n)\n",
    "        if not os.path.exists(metrics_path):\n",
    "            print(f\"ERROR: {metrics_path} is not started\")\n",
    "            continue\n",
    "        with open(metrics_path, \"rt\") as in_file:\n",
    "            metrics_info = json.load(in_file)\n",
    "        min_loss_idx = np.argmin(metrics_info[\"loss_validation\"])\n",
    "        for key in keys:\n",
    "            metric_values[key].append(np.nan_to_num(metrics_info[key][min_loss_idx]))\n",
    "    for key in keys:\n",
    "        model_metrics[key][\"mean\"] = np.mean(metric_values[key])\n",
    "        model_metrics[key][\"std\"] = np.std(metric_values[key])\n",
    "    return model_metrics\n",
    "\n",
    "\n",
    "def restructure_results(model_metrics: dict, keys):\n",
    "    restructured_results = {key: {} for key in keys}\n",
    "    for key in keys:\n",
    "        means = []\n",
    "        stdevs = []\n",
    "        for frac in FRACS:\n",
    "            means.append(model_metrics[frac][key][\"mean\"])\n",
    "            stdevs.append(model_metrics[frac][key][\"std\"])\n",
    "        restructured_results[key][\"mean\"] = means\n",
    "        restructured_results[key][\"std\"] = stdevs\n",
    "    return restructured_results        \n",
    "    \n",
    "\n",
    "\n",
    "def get_model_metrics_values(training_type, em):\n",
    "    model = \"OmniParT_fine_tuning\" if \"epoch\" in em else \"OmniParT_fixed_backbone\"\n",
    "    keys = PERFORMANCE_KEYS[training_type]\n",
    "    model_metrics = {}\n",
    "    for frac in FRACS:\n",
    "        wcp_path = os.path.join(epoch_dirs[em], \"*\", f\"trainfrac_{frac}\", training_type, model, \"history.json\")\n",
    "        model_metrics[frac] = calculate_scenario_measures(wcp_path, keys)\n",
    "    restructured_results = restructure_results(model_metrics, keys)\n",
    "    return restructured_results\n",
    "\n",
    "\n",
    "def get_unfreezing_metrics_values(training_type):\n",
    "    # epoch_models = [\"epoch_0\", \"epoch_30\", \"epoch_60\", \"fixed_backbone\"]\n",
    "    epoch_models = epoch_name_mapping.keys()\n",
    "    # epoch_models = [\"epoch_30\", \"fixed_backbone\"]\n",
    "    model_versions = {}\n",
    "    for em in epoch_models:\n",
    "        model_versions[em] = get_model_metrics_values(training_type, em)\n",
    "    return model_versions\n",
    "\n",
    "\n",
    "def plot_performance(metrics_values, key, output_path):\n",
    "    fs = [float(f) for f in FRACS]\n",
    "    for m_type, name in epoch_name_mapping.items():\n",
    "        mean = np.array(metrics_values[m_type][key][\"mean\"])\n",
    "        std = np.array(metrics_values[m_type][key][\"std\"])\n",
    "        plt.plot(fs, mean, label=name, color=EPOCH_COLORS[m_type])\n",
    "        plt.fill_between(fs, mean - std, mean + std, color=EPOCH_COLORS[m_type], alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"Number of training jets\")\n",
    "    plt.ylabel(Y_LABELS[key])\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\", format=\"pdf\")\n",
    "    plt.close(\"all\")\n",
    "\n",
    "\n",
    "def plot_all_performances(training_type):\n",
    "    metrics_values = get_unfreezing_metrics_values(training_type)\n",
    "    output_dir = os.path.join(OUTPUT_DIR, training_type)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for key in PERFORMANCE_KEYS[training_type]:\n",
    "        output_path = os.path.join(output_dir, f\"{key}_layerFreeze.pdf\")\n",
    "        plot_performance(metrics_values, key, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f86341-384d-4423-9d53-036189cb67d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_type = 'jet_regression'\n",
    "key = 'loss_validation'\n",
    "metrics_values_freeze = get_unfreezing_metrics_values(training_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d28021-3fc2-4737-86ac-8755bfcf7fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for training_type in PERFORMANCE_KEYS.keys():\n",
    "    plot_all_performances(training_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76465f41-66b0-4d28-8a75-a46294c1dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "metric_key = 'loss_validation'\n",
    "trainSize = '2e3'\n",
    "size_mapping = {i: value for i, value in enumerate(FRACS)}\n",
    "inverse_size_mapping = {value: i for i, value in enumerate(FRACS)}\n",
    "fig, axes = plt.subplots(3, 1, sharex=True)\n",
    "color_mapping = {\n",
    "    'jet_regression': 'red',\n",
    "    'dm_multiclass': 'green',\n",
    "    \"binary_classification\": \"blue\"\n",
    "}\n",
    "name_mapping = {\n",
    "    'jet_regression': 'Kinematic reconstruction',\n",
    "    'dm_multiclass': 'Decay mode reconstruction',\n",
    "    \"binary_classification\": \"Tagging\"\n",
    "}\n",
    "plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "for training_type, ax in zip(PERFORMANCE_KEYS.keys(), axes):\n",
    "    metrics_values_gpt = get_unfreezing_metrics_values(training_type)\n",
    "    means = []\n",
    "    stds = []\n",
    "    for key, values in metrics_values_gpt.items():\n",
    "        means.append(values[metric_key]['mean'][inverse_size_mapping[trainSize]])\n",
    "        stds.append(values[metric_key]['std'][inverse_size_mapping[trainSize]])\n",
    "    means = np.array(means)\n",
    "    stds = np.array(stds)\n",
    "\n",
    "    normed_means = means/np.min(means)\n",
    "    normed_max_err = (means + stds) / np.min(means)\n",
    "    normed_min_err = (means - stds) / np.min(means)\n",
    "    ax.plot(np.arange(len(means)), normed_means, ls='--', marker=\"^\", ms=15, label=name_mapping[training_type], color=color_mapping[training_type])\n",
    "    ax.fill_between(np.arange(len(means)), normed_min_err, normed_max_err, alpha=0.3, color=color_mapping[training_type])\n",
    "    # ax.legend(loc='upper center')\n",
    "    ax.set_ylabel(r'$\\mathcal{L}_{val} / min(\\mathcal{L}_{val})$')\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    # ax.set_title(name_mapping[training_type], x=0.5, y=0.7, fontsize=22)\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.xticks(range(4), ['0', '30', '60', '100'])\n",
    "plt.xlim(-0.1, 3.1)\n",
    "plt.xlabel('Backbone unfreezing epoch')\n",
    "    \n",
    "freeze_output_path = os.path.join(OUTPUT_DIR, \"freeze_ablation.pdf\")\n",
    "fig.savefig(freeze_output_path, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8970fdf8-6694-4a4e-8aa3-742c59a8b4f4",
   "metadata": {},
   "source": [
    "# Effects of number of GPT layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1309dfcf-cce5-4754-910d-ce55918d1586",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dirs = {\n",
    "    \"GPT_layers_1\": GPT_LAYERS_1_DIR,\n",
    "    \"GPT_layers_2\": GPT_LAYERS_2_DIR,\n",
    "    \"GPT_layers_3\": BASE_DIR,\n",
    "}\n",
    "\n",
    "layer_name_mapping = {\n",
    "    \"GPT_layers_1\": \"1 GPT layer\",\n",
    "    \"GPT_layers_2\": \"2 GPT layers\",\n",
    "    \"GPT_layers_3\": \"3 GPT layers\",\n",
    "}\n",
    "\n",
    "\n",
    "def get_model_metrics_values_gptLayer(training_type, em):\n",
    "    keys = PERFORMANCE_KEYS[training_type]\n",
    "    model_metrics = {}\n",
    "    for frac in FRACS:\n",
    "        wcp_path = os.path.join(layer_dirs[em], \"*\", f\"trainfrac_{frac}\", training_type, \"OmniParT_fine_tuning\", \"history.json\")\n",
    "        model_metrics[frac] = calculate_scenario_measures(wcp_path, keys)\n",
    "    restructured_results = restructure_results(model_metrics, keys)\n",
    "    return restructured_results\n",
    "\n",
    "\n",
    "def get_metrics_values_gptLayer(training_type):\n",
    "    model_types = layer_name_mapping.keys()\n",
    "    model_versions = {}\n",
    "    for em in model_types:\n",
    "        model_versions[em] = get_model_metrics_values_gptLayer(training_type, em)\n",
    "    return model_versions\n",
    "\n",
    "\n",
    "def plot_performance_gptLayer(metrics_values, key, output_path):\n",
    "    fs = [float(f) for f in FRACS]\n",
    "    for m_type, name in layer_name_mapping.items():\n",
    "        mean = np.array(metrics_values[m_type][key][\"mean\"])\n",
    "        std = np.array(metrics_values[m_type][key][\"std\"])\n",
    "        plt.plot(fs, mean, label=name, color=LAYER_COLORS[m_type])\n",
    "        plt.fill_between(fs, mean - std, mean + std, color=LAYER_COLORS[m_type], alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"Number of training jets\")\n",
    "    plt.ylabel(Y_LABELS[key])\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\", format=\"pdf\")\n",
    "    plt.close(\"all\")\n",
    "\n",
    "\n",
    "def plot_all_performances_gptLayer(training_type):\n",
    "    metrics_values = get_metrics_values_gptLayer(training_type)\n",
    "    output_dir = os.path.join(OUTPUT_DIR, training_type)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for key in PERFORMANCE_KEYS[training_type]:\n",
    "        output_path = os.path.join(output_dir, f\"{key}_gptLayerCount.pdf\")\n",
    "        plot_performance_gptLayer(metrics_values, key, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd5ee54-d5be-47f1-bd63-b85e10a6829b",
   "metadata": {},
   "source": [
    "# GPT layer impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadddb29-7c15-4274-aaea-a8ae036c002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for training_type in PERFORMANCE_KEYS.keys():\n",
    "    plot_all_performances_gptLayer(training_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab879145-07b4-47ba-8a45-d6da98de07a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_key = 'loss_validation'\n",
    "trainSize = '2e3'\n",
    "size_mapping = {i: value for i, value in enumerate(FRACS)}\n",
    "inverse_size_mapping = {value: i for i, value in enumerate(FRACS)}\n",
    "fig, axes = plt.subplots(3, 1, sharex=True)\n",
    "color_mapping = {\n",
    "    'jet_regression': 'red',\n",
    "    'dm_multiclass': 'green',\n",
    "    \"binary_classification\": \"blue\"\n",
    "}\n",
    "name_mapping = {\n",
    "    'jet_regression': 'Kinematic reconstruction',\n",
    "    'dm_multiclass': 'Decay mode reconstruction',\n",
    "    \"binary_classification\": \"Tagging\"\n",
    "}\n",
    "plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "for training_type, ax in zip(PERFORMANCE_KEYS.keys(), axes):\n",
    "    metrics_values_gpt = get_metrics_values_gptLayer(training_type)\n",
    "    means = []\n",
    "    stds = []\n",
    "    for key, values in metrics_values_gpt.items():\n",
    "        means.append(values[metric_key]['mean'][inverse_size_mapping[trainSize]])\n",
    "        stds.append(values[metric_key]['std'][inverse_size_mapping[trainSize]])\n",
    "    means = np.array(means)\n",
    "    stds = np.array(stds)\n",
    "\n",
    "    normed_means = means/np.min(means)\n",
    "    normed_max_err = (means + stds) / np.min(means)\n",
    "    normed_min_err = (means - stds) / np.min(means)\n",
    "    ax.plot(np.arange(len(means)), normed_means, ls='--', marker=\"^\", ms=15, label=name_mapping[training_type], color=color_mapping[training_type])\n",
    "    ax.fill_between(np.arange(len(means)), normed_min_err, normed_max_err, alpha=0.3, color=color_mapping[training_type])\n",
    "    # ax.legend(loc='upper center')\n",
    "    ax.set_ylabel(r'$\\mathcal{L}_{val} / min(\\mathcal{L}_{val})$')\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    ax.set_title(name_mapping[training_type], x=0.75, y=0.7, fontsize=22)\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.xticks(range(3), [\"1\", \"2\", \"3\"])\n",
    "plt.minorticks_off()\n",
    "plt.xlim(-0.1, 2.1)\n",
    "plt.xlabel(\"Number of GPT layers\")\n",
    "    \n",
    "freeze_output_path = os.path.join(OUTPUT_DIR, \"GPT_layer_ablation.pdf\")\n",
    "fig.savefig(freeze_output_path, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05df7407-e233-42a0-aa3c-514148429b2a",
   "metadata": {},
   "source": [
    "# Jet resolution improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e6fd46-be7e-440f-ac3f-3ab1383c5403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boost_histogram as bh\n",
    "\n",
    "def to_bh(data, bins, cumulative=False):\n",
    "    h1 = bh.Histogram(bh.axis.Variable(bins))\n",
    "    h1.fill(data)\n",
    "    if cumulative:\n",
    "        h1[:] = np.sum(h1.values()) - np.cumsum(h1)\n",
    "    return h1\n",
    "\n",
    "def calculate_bin_centers(edges: list) -> np.array:\n",
    "    bin_widths = np.array([edges[i + 1] - edges[i] for i in range(len(edges) - 1)])\n",
    "    bin_centers = []\n",
    "    for i in range(len(edges) - 1):\n",
    "        bin_centers.append(edges[i] + (bin_widths[i] / 2))\n",
    "    return np.array(bin_centers), bin_widths / 2\n",
    "\n",
    "\n",
    "def IQR(ratios: np.array) -> np.array:\n",
    "    return np.quantile(ratios, 0.75) - np.quantile(ratios, 0.25)\n",
    "\n",
    "\n",
    "algo_colors = {\n",
    "    \"fine_tuning\": \"green\",\n",
    "    \"from_scratch\": \"red\"\n",
    "}\n",
    "\n",
    "\n",
    "def calculate_response(data):\n",
    "    pred = data.jet_regression.pred\n",
    "    target = data.jet_regression.target\n",
    "    return pred/target\n",
    "\n",
    "bins = np.linspace(0.5, 1.5, 31)\n",
    "\n",
    "sample = \"z\"\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "for algo in [\"fine_tuning\", \"from_scratch\"]:\n",
    "    histograms = []\n",
    "    resolutions = []\n",
    "    avg_responses = []\n",
    "    for version in ['v1', \"v2\", \"v3\"]:\n",
    "        predictions_path = os.path.join(BASE_DIR, version, f\"trainfrac_1e4\", \"jet_regression\", f\"OmniParT_{algo}\", f\"{sample}_test.parquet\")\n",
    "        data = ak.from_parquet(predictions_path)\n",
    "        responses = calculate_response(data)\n",
    "        avg_response = np.mean(responses)\n",
    "        avg_responses.append(avg_response)\n",
    "        resolution = IQR(responses)\n",
    "        resolutions.append(resolution)\n",
    "        # print(fr\"{algo} {version} IQR: {resolution:.3f}\\t $\\mu$: {avg_response}\")\n",
    "        histograms.append(np.histogram(responses, bins=bins)[0])\n",
    "    histograms = np.array(histograms)\n",
    "    mean_values = np.mean(histograms, axis=0)\n",
    "    std_values = np.std(histograms, axis=0)\n",
    "    runs_avg_response = np.mean(avg_responses)\n",
    "    runs_std_response = np.std(avg_responses)\n",
    "    print(f\"{algo}\")\n",
    "    print(f\"Response: {runs_avg_response:.3f} +/- {runs_std_response:.3f}\")\n",
    "    runs_avg_resolution = np.mean(resolutions)\n",
    "    runs_std_resolution = np.std(resolutions)\n",
    "    print(f\"Resolution: {runs_avg_resolution:.3f} +/- {runs_std_resolution:.3f}\")\n",
    "    # bin_centers = calculate_bin_centers(bins)[0]\n",
    "    # ax.plot(bin_centers, mean_values, label=fr\"{MODEL_TYPES[algo]}\", color=algo_colors[algo])\n",
    "    # ax.fill_between(bin_centers, mean_values, mean_values - std_values, mean_values + std_values, alpha=0.3, color=algo_colors[algo])\n",
    "    hep.histplot((mean_values, bins), yerr=std_values, histtype='band', ax=ax, density=True, color=algo_colors[algo], edgecolor=algo_colors[algo])\n",
    "    hep.histplot((mean_values, bins), ax=ax, density=True, label=fr\"{MODEL_TYPES[algo]}\", color=algo_colors[algo])\n",
    "ax.set_ylabel(\"Bin content [a.u.]\")\n",
    "ax.set_xlabel(r\"$p_{T}^{pred} / p_{T}^{true}$\")\n",
    "plt.legend()\n",
    "# # plt.grid()\n",
    "reso_output_path = os.path.join('/home/laurits', \"resolution_10k.pdf\")\n",
    "plt.savefig(reso_output_path, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad7fc04-1d04-4108-85e7-3a5cd47f7001",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Resolution improvement: {100* (0.143 - 0.068) / 0.143:.1f}%\")\n",
    "print(f\"Response improvement: {100* (1.082 - 1.027) / 1.082:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ea225e-4604-43b1-894c-c32b35a224b0",
   "metadata": {},
   "source": [
    "# Decay mode ROC plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b22835-f7e9-440c-a9d7-6425cf8986d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X, theta = 1.0, axis = None):\n",
    "    \"\"\"\n",
    "    Compute the softmax of each element along an axis of X.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: ND-Array. Probably should be floats.\n",
    "    theta (optional): float parameter, used as a multiplier\n",
    "        prior to exponentiation. Default = 1.0\n",
    "    axis (optional): axis to compute values along. Default is the\n",
    "        first non-singleton axis.\n",
    "\n",
    "    Returns an array the same size as X. The result will sum to 1\n",
    "    along the specified axis.\n",
    "    \"\"\"\n",
    "\n",
    "    # make X at least 2d\n",
    "    y = np.atleast_2d(X)\n",
    "\n",
    "    # find axis\n",
    "    if axis is None:\n",
    "        axis = next(j[0] for j in enumerate(y.shape) if j[1] > 1)\n",
    "\n",
    "    # multiply y against the theta parameter,\n",
    "    y = y * float(theta)\n",
    "\n",
    "    # subtract the max for numerical stability\n",
    "    y = y - np.expand_dims(np.max(y, axis = axis), axis)\n",
    "\n",
    "    # exponentiate y\n",
    "    y = np.exp(y)\n",
    "\n",
    "    # take the sum along the specified axis\n",
    "    ax_sum = np.expand_dims(np.sum(y, axis = axis), axis)\n",
    "\n",
    "    # finally: divide elementwise\n",
    "    p = y / ax_sum\n",
    "\n",
    "    # flatten if X was 1D\n",
    "    if len(X.shape) == 1: p = p.flatten()\n",
    "\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745f915d-ec46-414b-b38b-bb93b2ccee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fpr_tpr_with_thresholds(y_true, y_pred, thresholds):\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "    signal_mask = y_true == 1\n",
    "    background_mask = y_true == 0\n",
    "    signal_samples = y_pred[signal_mask]\n",
    "    background_samples = y_pred[background_mask]\n",
    "    total_signal = sum(signal_mask)\n",
    "    total_background = sum(background_mask)\n",
    "    for thr in thresholds:\n",
    "        bkg_above_thr = sum(background_samples > thr)\n",
    "        fpr.append(bkg_above_thr / total_background)\n",
    "        sig_above_thr = sum(signal_samples > thr)\n",
    "        tpr.append(sig_above_thr / total_signal)\n",
    "    return np.array(fpr), np.array(tpr)\n",
    "\n",
    "\n",
    "def calculate_eff_fake(pred, true, thresholds):\n",
    "    efficiencies = []\n",
    "    fakerates = []\n",
    "    signal_mask = true == 1\n",
    "    num_sig = ak.sum(signal_mask)\n",
    "    num_bkg = ak.sum(~signal_mask)\n",
    "    for threshold in thresholds:\n",
    "        efficiency = ak.sum((pred[signal_mask] > threshold)) / num_sig\n",
    "        fakerate = ak.sum((pred[~signal_mask] > threshold)) / num_bkg\n",
    "        efficiencies.append(efficiency)\n",
    "        fakerates.append(fakerate)\n",
    "    return np.array(fakerates), np.array(efficiencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299b2774-149b-49e5-9ee2-c24534be1eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"z\"\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "import tqdm\n",
    "import torch\n",
    "from enreg.tools.models.OmniParT import OmniParT\n",
    "from enreg.tools.models.ParticleTransformer import ParticleTransformer\n",
    "from torch.utils.data import DataLoader\n",
    "from enreg.tools.data_management.particleTransformer_dataset import load_row_groups, ParticleTransformerDataset\n",
    "from sklearn.metrics import roc_curve\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../enreg/config/\", job_name=\"test_app\"):\n",
    "    cfg = compose(config_name=\"model_training\")\n",
    "\n",
    "\n",
    "def one_hot_encode(values):\n",
    "    a = np.array(values)\n",
    "    b = np.zeros((a.size, a.max() + 1))\n",
    "    b[np.arange(a.size), a] = 1\n",
    "    return b\n",
    "\n",
    "def unpack_data(X, dev, feature_set):\n",
    "    # Create a dictionary for each feature\n",
    "    features_as_dict = {\n",
    "        feature: X[feature].to(device=dev) for feature in feature_set\n",
    "    }\n",
    "\n",
    "    # Concatenate chosen features\n",
    "    particle_features = torch.cat([features_as_dict[feat] for feat in feature_set], axis=1)\n",
    "\n",
    "    cand_kinematics = X[\"cand_kinematics\"].to(device=dev)\n",
    "    mask = X[\"mask\"].to(device=dev).bool()\n",
    "    return particle_features, cand_kinematics, mask\n",
    "\n",
    "\n",
    "def create_pred_true(algo, version='v1'):\n",
    "    algo_model_path = os.path.join(BASE_DIR, version, f\"trainfrac_{frac}\", \"dm_multiclass\", f\"OmniParT_{algo}\", f\"model_best.pt\")\n",
    "    cfg.models.OmniParT.version = algo\n",
    "    model = OmniParT(\n",
    "        input_dim=10,\n",
    "        cfg=cfg.models.OmniParT,\n",
    "        num_classes=6,\n",
    "        num_layers=cfg.models.OmniParT.hyperparameters.num_layers,\n",
    "        embed_dims=cfg.models.OmniParT.hyperparameters.embed_dims,\n",
    "        use_pre_activation_pair=False,\n",
    "        for_inference=False,\n",
    "        use_amp=False,\n",
    "        metric='eta-phi',\n",
    "        verbosity=cfg.verbosity,\n",
    "    ).to(device='cpu')\n",
    "    \n",
    "    model.load_state_dict(torch.load(algo_model_path, map_location=\"cpu\"))\n",
    "    model.eval()\n",
    "\n",
    "    \n",
    "    data = load_row_groups(os.path.join(cfg.data_path, f\"{sample}_test.parquet\"))\n",
    "    dataset_full = ParticleTransformerDataset(\n",
    "        row_groups=data,\n",
    "        cfg=cfg.dataset,\n",
    "        reco_jet_pt_cut=cfg.reco_jet_pt_cut[cfg.training_type]\n",
    "    )\n",
    "\n",
    "    dataloader_full = DataLoader(\n",
    "        dataset_full,\n",
    "        batch_size=cfg.training.batch_size,\n",
    "    )\n",
    "    preds = []\n",
    "    targets = []\n",
    "\n",
    "    for (X, y, weight) in tqdm.tqdm(dataloader_full, total=len(dataloader_full)):\n",
    "        model_inputs = unpack_data(X, \"cpu\", [\"cand_omni_features_wPID\"])\n",
    "        y_for_loss = y[\"dm_multiclass\"]\n",
    "        with torch.no_grad():\n",
    "            pred = model(*model_inputs)\n",
    "            preds.extend(pred.detach().cpu().numpy())\n",
    "            targets.extend(y_for_loss.detach().cpu().numpy())\n",
    "    preds = np.array(preds)\n",
    "    targets = np.array(targets)\n",
    "    return preds, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f24e94-489f-45d8-8bdc-ed55fc782f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "decay_mode_name_mapping = {\n",
    "            0: r\"$h^{\\pm}$\",\n",
    "            1: r\"$h^{\\pm}\\pi^0$\",\n",
    "            2: r'$h^\\pm+\\geq2\\pi^0$',\n",
    "            3: r\"$h^{\\pm}h^{\\mp}h^{\\pm}$\",\n",
    "            4: r\"$h^{\\pm}h^{\\mp}h^{\\pm}+\\geq\\pi^0$\",\n",
    "            5: \"Rare\",\n",
    "        }\n",
    "\n",
    "def get_eff_fr(true, preds, output_path):\n",
    "    thresholds = np.linspace(0, 1, num=100)\n",
    "    fakerates = {}\n",
    "    efficiencies = {}\n",
    "    all_fprs = []\n",
    "    all_tprs = []\n",
    "    all_aucs = []\n",
    "    for i in range(6):\n",
    "        # fakerates[version], efficiencies[version] = calculate_eff_fake(preds[:, i], true[:, i], thresholds)\n",
    "        fpr, tpr = calculate_fpr_tpr_with_thresholds(true[:, i], preds[:, i], thresholds)\n",
    "        class_proportion = (np.sum(np.argmax(true, axis=1) == i)) / len(true)\n",
    "        # plt.plot(efficiencies[version], fakerates[version], label=decay_mode_name_mapping[i])\n",
    "        plt.plot(tpr, fpr, label=decay_mode_name_mapping[i])\n",
    "        auc = roc_auc_score(true[:, i], preds[:, i])\n",
    "        print(f\"{decay_mode_name_mapping[i]}: {auc}\")\n",
    "        all_aucs.append(auc*class_proportion)\n",
    "        all_fprs.append(fpr*class_proportion)\n",
    "        all_tprs.append(tpr*class_proportion)\n",
    "    all_fprs = np.array(all_fprs)\n",
    "    all_tprs = np.array(all_tprs)\n",
    "    all_aucs = np.array(all_aucs)\n",
    "    plt.legend()\n",
    "    plt.ylabel(r\"$P_{misID}$\")\n",
    "    plt.xlabel(r\"$\\epsilon_{DM}$\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.savefig(output_path)\n",
    "    plt.close('all')\n",
    "    avg_auc = np.sum(all_aucs)\n",
    "    print(f\"avg auc: {avg_auc}\")\n",
    "    avg_fpr = np.sum(all_fprs, axis=0)\n",
    "    avg_tpr = np.sum(all_tprs, axis=0)\n",
    "    return avg_fpr, avg_tpr, avg_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc24197-bb5f-4899-8e34-2ae113cc7afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dm_algo_results(algorithm):\n",
    "    avg_fr = {}\n",
    "    avg_eff = {}\n",
    "    aucs = []\n",
    "    for version in ['v1', 'v2', 'v3']:\n",
    "        preds, targets = create_pred_true(algorithm, version=version)\n",
    "        preds_sm = softmax(preds, axis=1)\n",
    "        y_true_ohe = one_hot_encode(targets)\n",
    "        output_path = f\"/home/laurits/tmp/{algorithm}_dm_multiclass_{version}.pdf\"\n",
    "        avg_fr[version], avg_eff[version], auc = get_eff_fr(y_true_ohe, preds_sm, output_path)\n",
    "        aucs.append(auc)\n",
    "    print(fr\"{algorithm} AUC: {np.mean(aucs):.3f} +/- {np.std(aucs):.3f}\")\n",
    "    return avg_fr, avg_eff\n",
    "\n",
    "\n",
    "avg_fr_ft, avg_eff_ft = get_dm_algo_results(\"fine_tuning\")\n",
    "# avg_fr_fs, avg_eff_fs = get_dm_algo_results(\"from_scratch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b957332b-65e9-434c-8f2f-aba5d54468e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_common = np.linspace(0, 1, 101)\n",
    "y1_interp_ft = interp1d(avg_fr_ft['v1'], avg_eff_ft['v1'], kind='linear', fill_value='extrapolate')(x_common)\n",
    "y2_interp_ft = interp1d(avg_fr_ft['v2'], avg_eff_ft['v2'], kind='linear', fill_value='extrapolate')(x_common)\n",
    "y3_interp_ft = interp1d(avg_fr_ft['v3'], avg_eff_ft['v3'], kind='linear', fill_value='extrapolate')(x_common)\n",
    "y_stack_ft = np.vstack([y1_interp_ft, y2_interp_ft, y3_interp_ft])\n",
    "y_mean_ft = np.mean(y_stack_ft, axis=0)\n",
    "y_std_ft = np.std(y_stack_ft, axis=0)\n",
    "\n",
    "y1_interp_fs = interp1d(avg_fr_fs['v1'], avg_eff_fs['v1'], kind='linear', fill_value='extrapolate')(x_common)\n",
    "y2_interp_fs = interp1d(avg_fr_fs['v2'], avg_eff_fs['v2'], kind='linear', fill_value='extrapolate')(x_common)\n",
    "y3_interp_fs = interp1d(avg_fr_fs['v3'], avg_eff_fs['v3'], kind='linear', fill_value='extrapolate')(x_common)\n",
    "\n",
    "y_stack_fs = np.vstack([y1_interp_fs, y2_interp_fs, y3_interp_fs])\n",
    "y_mean_fs = np.mean(y_stack_fs, axis=0)\n",
    "y_std_fs = np.std(y_stack_fs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d739494b-0448-49ac-bfea-215131526fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_common, y_mean_fs, label=\"From scratch\", color=\"red\")\n",
    "plt.fill_between(x_common, y_mean_fs - y_std_fs, y_mean_fs + y_std_fs, alpha=0.3, color=\"red\")\n",
    "plt.plot(x_common, y_mean_ft, label=\"Fine-tuning\", color=\"green\")\n",
    "plt.fill_between(x_common, y_mean_ft - y_std_ft, y_mean_ft + y_std_ft, alpha=0.3, color=\"green\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Average true positive rate\")\n",
    "plt.xlabel(\"Average false positive rate\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.savefig(\"/home/laurits/tmp/dm_multiclass_roc.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada0398-60c7-4614-9573-1bcceb427759",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_AUC = np.sum(np.multiply(0.01, y_mean_ft))\n",
    "fs_AUC = np.sum(np.multiply(0.01, np.nan_to_num(y_mean_fs, 0)))\n",
    "\n",
    "print(f\"Fine-tuning AUC: {ft_AUC:.3f}\")\n",
    "print(f\"From scratch AUC: {fs_AUC:.3f}\")\n",
    "print(f\"Improvement: {100*abs(fs_AUC-ft_AUC)/fs_AUC:.3f} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb5f893-fc9b-45f6-af90-bbfbf8daeb8d",
   "metadata": {},
   "source": [
    "# Tagger ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522aa919-7875-41ad-80b9-4b8c89697cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_algo_results(algorithm):\n",
    "    aucs = []\n",
    "    fakerates = {}\n",
    "    efficiencies = {}\n",
    "    thresholds = np.linspace(0, 1, 101)\n",
    "    for version in ['v1', 'v2', 'v3']:\n",
    "        path = os.path.join(BASE_DIR, version, f\"trainfrac_{frac}\", \"binary_classification\", f\"OmniParT_{algorithm}\", f\"{sample}_test.parquet\")\n",
    "        bkg_path = os.path.join(BASE_DIR, version, f\"trainfrac_{frac}\", \"binary_classification\", f\"OmniParT_{algorithm}\", f\"qq_test.parquet\")\n",
    "        data = ak.from_parquet(path).binary_classification\n",
    "        bkg = ak.from_parquet(bkg_path).binary_classification\n",
    "    \n",
    "        pred = ak.concatenate([data.pred, bkg.pred])\n",
    "        true = ak.concatenate([data.target, bkg.target])\n",
    "    \n",
    "        fakerates[version], efficiencies[version] = calculate_eff_fake(pred, true, thresholds)\n",
    "        auc = roc_auc_score(true, pred)\n",
    "        # print(f\"{algorithm} {version} AUC: {auc}\")\n",
    "        aucs.append(auc)\n",
    "    print(fr\"{algorithm} AUC: {np.mean(aucs):.3f} +/- {np.std(aucs):.3f}\")\n",
    "    return fakerates, efficiencies, aucs\n",
    "\n",
    "\n",
    "\n",
    "x_common = np.linspace(0, 1, 101)\n",
    "\n",
    "fprs_ft, tprs_ft, aucs_ft = get_algo_results(\"fine_tuning\")\n",
    "y1_interp_ft = interp1d(tprs_ft['v1'], fprs_ft['v1'], kind='linear', fill_value='extrapolate')(x_common)\n",
    "y2_interp_ft = interp1d(tprs_ft['v2'], fprs_ft['v2'], kind='linear', fill_value='extrapolate')(x_common)\n",
    "y3_interp_ft = interp1d(tprs_ft['v3'], fprs_ft['v3'], kind='linear', fill_value='extrapolate')(x_common)\n",
    "y_stack_ft = np.vstack([y1_interp_ft, y2_interp_ft, y3_interp_ft])\n",
    "y_mean_ft = np.mean(y_stack_ft, axis=0)\n",
    "y_std_ft = np.std(y_stack_ft, axis=0)\n",
    "\n",
    "fprs_fs, tprs_fs, aucs_fs = get_algo_results(\"from_scratch\")\n",
    "y1_interp_fs = interp1d(tprs_fs['v1'], fprs_fs['v1'], kind='linear', fill_value='extrapolate')(x_common)\n",
    "y2_interp_fs = interp1d(tprs_fs['v2'], fprs_fs['v2'], kind='linear', fill_value='extrapolate')(x_common)\n",
    "y3_interp_fs = interp1d(tprs_fs['v3'], fprs_fs['v3'], kind='linear', fill_value='extrapolate')(x_common)\n",
    "\n",
    "y_stack_fs = np.vstack([y1_interp_fs, y2_interp_fs, y3_interp_fs])\n",
    "y_mean_fs = np.mean(y_stack_fs, axis=0)\n",
    "y_std_fs = np.std(y_stack_fs, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f5f38d-ee27-4274-a60a-c3ed92489e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_common, y_mean_fs, label=\"From scratch\", color=\"red\")\n",
    "plt.fill_between(x_common, y_mean_fs - y_std_fs, y_mean_fs + y_std_fs, alpha=0.3, color=\"red\")\n",
    "plt.plot(x_common, y_mean_ft, label=\"Fine-tuning\", color=\"green\")\n",
    "plt.fill_between(x_common, y_mean_ft - y_std_ft, y_mean_ft + y_std_ft, alpha=0.3, color=\"green\")\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(r\"$P_{misID}$\")\n",
    "plt.xlabel(r\"$\\epsilon_{\\tau}$\")\n",
    "plt.xlim([0, 1])\n",
    "plt.savefig(\"/home/laurits/tmp/binary_cls_roc.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e4efae-8907-4479-8639-d1e60d416a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At 80% efficiency:\n",
    "print(f\"From scratch \\t P_misID: {y_mean_fs[80]:.3f} +/- {y_std_fs[80]:.3f}\")\n",
    "print(f\"Fine-tuning \\t  P_misID: {y_mean_ft[80]:.3f} +/- {y_std_ft[80]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58287a7-fd62-4ff7-9aed-6004be9183c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"P_misID improvement at 80% efficiency: {100*(0.039 - 0.031)/0.039:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e56e929-e573-4669-8039-ffb687208f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

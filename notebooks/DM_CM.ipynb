{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038cc922-a195-4941-bce5-dbc4aa8e0694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hydra\n",
    "import numpy as np\n",
    "from math import isclose\n",
    "import enreg.tools.general as g\n",
    "import mplhep as hep\n",
    "import awkward as ak\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import DictConfig\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from matplotlib import cm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from matplotlib.ticker import FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3580249-c747-4234-8267-c298f826d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.style.use(\"CMS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb490e4-cf9b-4a74-bb3d-a02a6e0f8012",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_zh_model = {\n",
    "    \"ParticleTransformer\": g.load_all_data(\"/home/laurits/ml-tau-en-reg/training-outputs/20240921_recoPtCut_removed_samples/v1/dm_multiclass/ParticleTransformer/zh_test.parquet\").dm_multiclass,\n",
    "    \"LorentzNet\": g.load_all_data(\"/home/laurits/ml-tau-en-reg/training-outputs/20240921_recoPtCut_removed_samples/v1/dm_multiclass/LorentzNet/zh_test.parquet\").dm_multiclass,\n",
    "    \"DeepSet\": g.load_all_data(\"/home/laurits/ml-tau-en-reg/training-outputs/20240921_recoPtCut_removed_samples/v1/dm_multiclass/DeepSet/zh_test.parquet\").dm_multiclass,\n",
    "    \"HPS\": g.load_all_data(\"/home/laurits/HPS_recoCut0_ntuples/zh.parquet\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8530cf6d-cfea-4e5c-91ff-2d76ef326607",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_z_model = {\n",
    "    \"ParticleTransformer\": g.load_all_data(\"/home/laurits/ml-tau-en-reg/training-outputs/20240921_recoPtCut_removed_samples/v1/dm_multiclass/ParticleTransformer/z_test.parquet\").dm_multiclass,\n",
    "    \"LorentzNet\": g.load_all_data(\"/home/laurits/ml-tau-en-reg/training-outputs/20240921_recoPtCut_removed_samples/v1/dm_multiclass/LorentzNet/z_test.parquet\").dm_multiclass,\n",
    "    \"DeepSet\": g.load_all_data(\"/home/laurits/ml-tau-en-reg/training-outputs/20240921_recoPtCut_removed_samples/v1/dm_multiclass/DeepSet/z_test.parquet\").dm_multiclass,\n",
    "    \"HPS\": g.load_all_data(\"/home/laurits/HPS_recoCut0_ntuples/z.parquet\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ef30a-a66e-4806-a129-605219ae7385",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(\"../outputs/20240923_decaymode_plots/\")\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7445c1ea-7e5d-42c8-b8dd-bdbc4a75e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions\n",
    "\n",
    "#---------------For getting the distribution of the decay modes-----------------------------------------------------------------------------\n",
    "\n",
    "# Function for plotting the distribution of the decay modes\n",
    "def plot_decay_modes(model):\n",
    "    dms = np.arange(17)\n",
    "    if model == \"HPS\":\n",
    "        x = data_zh_model[model].true_decay_mode\n",
    "        y = data_zh_model[model].pred_decay_mode\n",
    "    else:\n",
    "        x = data_zh_model[model].target\n",
    "        y = data_zh_model[model].pred\n",
    "    bins=dms\n",
    "    if model == \"SimpleDNN\":\n",
    "        plt.hist([x, y], bins, label=['Actual decaymode', 'DeepSet'])\n",
    "    else:\n",
    "        plt.hist([x, y], bins, label=['Actual decaymode', model])\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(\"Actual vs predicted decaymodes\")\n",
    "    plt.yscale('log')\n",
    "    plt.xticks(dms+0.4, dms);\n",
    "    plt.savefig(os.path.join(output_dir, f\"dm_{model}.pdf\"), bbox_inches='tight', format='pdf')\n",
    "    plt.close(\"all\")\n",
    "\n",
    "#---------------For getting the confusion matrices-----------------------------------------------------------------------------\n",
    "\n",
    "# Function for aggregating specific classes of the confusion matrix\n",
    "def aggregate_classes(cm, classes_to_merge):\n",
    "    num_classes = cm.shape[0]\n",
    "    new_num_classes = num_classes - len(classes_to_merge) + 1\n",
    "    new_cm = np.zeros((new_num_classes, new_num_classes))\n",
    "    \n",
    "    if classes_to_merge == [2, 3, 4]:\n",
    "        merge_index = 2  # Index for the merged class\n",
    "    elif classes_to_merge == [4, 5]:\n",
    "        merge_index = 4\n",
    "\n",
    "    # Classes that are not being merged\n",
    "    classes_to_keep = [i for i in range(num_classes) if i not in classes_to_merge]\n",
    "\n",
    "    # Mapping old indices to new indices\n",
    "    index_map = {}\n",
    "    new_index = 0\n",
    "\n",
    "    # Insert classes to keep before the merge_index\n",
    "    for old_index in classes_to_keep:\n",
    "        if new_index == merge_index:\n",
    "            new_index += 1\n",
    "        index_map[old_index] = new_index\n",
    "        new_index += 1\n",
    "\n",
    "    # Map the merged classes to the merge_index\n",
    "    for cls in classes_to_merge:\n",
    "        index_map[cls] = merge_index\n",
    "\n",
    "    # Aggregate the confusion matrix\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            new_i = index_map[i]\n",
    "            new_j = index_map[j]\n",
    "            new_cm[new_i, new_j] += cm[i, j]\n",
    "\n",
    "    return new_cm\n",
    "\n",
    "# Function for normalizing the confusion matrix\n",
    "def normalize_confusion_matrix(cm):\n",
    "    column_sums = cm.sum(axis=0, keepdims=True)\n",
    "    normalized_cm = cm / column_sums\n",
    "    return normalized_cm\n",
    "\n",
    "# Function for plotting the DM confusion matrices\n",
    "def CM_plot(dataset):\n",
    "\n",
    "    models = [\"DeepSet\", \"LorentzNet\", \"ParticleTransformer\", \"HPS\"]\n",
    "    for model_name in models:\n",
    "        if dataset == \"ZH\":\n",
    "            if model_name == \"HPS\":\n",
    "                y_true = g.get_reduced_decaymodes(np.array(data_zh_model[model_name].true_decay_mode))\n",
    "                y_pred = g.get_reduced_decaymodes(np.array(data_zh_model[model_name].pred_decay_mode))\n",
    "            else:\n",
    "                y_true = g.get_reduced_decaymodes(np.array(data_zh_model[model_name].target))\n",
    "                y_pred = g.get_reduced_decaymodes(np.array(data_zh_model[model_name].pred))\n",
    "        elif dataset == \"Z\":\n",
    "            if model_name == \"HPS\":\n",
    "                y_true = g.get_reduced_decaymodes(np.array(data_z_model[model_name].true_decay_mode))\n",
    "                y_pred = g.get_reduced_decaymodes(np.array(data_z_model[model_name].pred_decay_mode))\n",
    "            else:\n",
    "                y_true = g.get_reduced_decaymodes(np.array(data_z_model[model_name].target))\n",
    "                y_pred = g.get_reduced_decaymodes(np.array(data_z_model[model_name].pred))\n",
    "        missing_mask = y_pred != -1\n",
    "        y_true = y_true[missing_mask]\n",
    "        y_pred = y_pred[missing_mask]\n",
    "        \n",
    "        cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "            \n",
    "        categories = [r'$h^\\pm$', r'$h^\\pm+\\pi^0$', r'$h^\\pm+\\geq2\\pi^0$', r'$h^\\pm h^\\mp h^\\pm$', r'$h^\\pm h^\\mp h^\\pm$' '\\n' r'$+\\geq\\pi^0$', 'Rare']\n",
    "    \n",
    "        fig, ax = plt.subplots()\n",
    "        xbins = ybins = np.arange(len(categories) + 1)\n",
    "        tick_values = np.arange(len(categories)) + 0.5\n",
    "\n",
    "        hep.hist2dplot(cm, xbins, ybins, cmap='GnBu', cbar=True, flow=None, ax=ax)\n",
    "\n",
    "        for i in range(len(ybins) - 1):\n",
    "            for j in range(len(xbins) - 1):\n",
    "                bin_value = cm.T[i, j]\n",
    "                ax.text(\n",
    "                    float(xbins[j] + 0.5),\n",
    "                    float(ybins[i] + 0.5),\n",
    "                    f\"{bin_value:.2f}\",\n",
    "                    color='k',\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    fontweight=\"bold\",\n",
    "                )\n",
    "        ax.set_xticks(tick_values, categories)\n",
    "        ax.set_yticks(tick_values + 0.2, categories)\n",
    "        ax.set_xticklabels(categories, rotation=45)\n",
    "        ax.tick_params(axis='x', which='both', bottom=True, top=True, labeltop=False, labelbottom=True)\n",
    "        ax.set_yticklabels(categories)\n",
    "        ax.set_xlabel('Generated decay mode')\n",
    "        ax.set_ylabel('Reconstructed decay mode')\n",
    "        ax.set_title(f\"{dataset} Confusion Matrix\", y=1.05)\n",
    "        plt.savefig(os.path.join(output_dir, f\"{dataset}_cm_{model_name}.pdf\"), bbox_inches='tight', format='pdf')\n",
    "        plt.close(\"all\")\n",
    "\n",
    "#---------------For plotting the classification precision of the DMs-----------------------------------------------------------------------------\n",
    "\n",
    "# Function to get precisions of the models\n",
    "def get_precision(dataset):\n",
    "    \n",
    "    model_precisions = []\n",
    "    models = [\"DeepSet\", \"LorentzNet\", \"ParticleTransformer\", \"HPS\"]\n",
    "    for model_name in models:\n",
    "        if dataset == \"ZH\":\n",
    "            if model_name == \"HPS\":\n",
    "                y_true = g.get_reduced_decaymodes(np.array(data_zh_model[model_name].true_decay_mode))\n",
    "                y_pred = g.get_reduced_decaymodes(np.array(data_zh_model[model_name].pred_decay_mode))\n",
    "            else:\n",
    "                y_true = g.get_reduced_decaymodes(np.array(data_zh_model[model_name].target))\n",
    "                y_pred = g.get_reduced_decaymodes(np.array(data_zh_model[model_name].pred))\n",
    "        elif dataset == \"Z\":\n",
    "            if model_name == \"HPS\":\n",
    "                y_true = g.get_reduced_decaymodes(np.array(data_z_model[model_name].true_decay_mode))\n",
    "                y_pred = g.get_reduced_decaymodes(np.array(data_z_model[model_name].pred_decay_mode))\n",
    "            else:\n",
    "                y_true = g.get_reduced_decaymodes(np.array(data_z_model[model_name].target))\n",
    "                y_pred = g.get_reduced_decaymodes(np.array(data_z_model[model_name].pred))\n",
    "        missing_mask = y_pred != -1\n",
    "        y_true = y_true[missing_mask]\n",
    "        y_pred = y_pred[missing_mask]\n",
    "        \n",
    "        precision = precision_score(y_true, y_pred, average=None)\n",
    "\n",
    "        model_precisions.append(precision)\n",
    "    return model_precisions\n",
    "\n",
    "# Function to plot the classification precision of the DMs\n",
    "def plot_dm_prec(dataset):\n",
    "    \n",
    "    if dataset == \"ZH\":\n",
    "        pr = get_precision(\"ZH\")\n",
    "    elif dataset == \"Z\":\n",
    "        pr = get_precision(\"Z\")\n",
    "\n",
    "    pr_sdnn, pr_ln, pr_pt, pr_hps = pr[0], pr[1], pr[2], pr[3]\n",
    "    pr_sdnn = list(pr_sdnn)\n",
    "    pr_ln = list(pr_ln)\n",
    "    pr_pt = list(pr_pt)\n",
    "    pr_hps = list(pr_hps)\n",
    "    labels = [r'$h^\\pm$', r'$h^\\pm+\\pi^0$', r'$h^\\pm+\\geq2\\pi^0$', r'$h^\\pm h^\\mp h^\\pm$', r'$h^\\pm h^\\mp h^\\pm$' '\\n' r'$+\\geq\\pi^0$', 'Rare', 'Overall']\n",
    "    PDG_ratios = np.array([0.1777, 0.4002, 0.1668, 0.1513, 0.0816, 0.0224])\n",
    "    \n",
    "    pr_sdnn += [np.sum(np.array(pr_sdnn) * PDG_ratios)]\n",
    "    pr_ln += [np.sum(np.array(pr_ln) * PDG_ratios)]\n",
    "    pr_pt += [np.sum(np.array(pr_pt) * PDG_ratios)]\n",
    "    pr_hps += [np.sum(np.array(pr_hps) * PDG_ratios)]\n",
    "\n",
    "    # Create a mapping from labels to their positions on the x-axis\n",
    "    x = range(len(labels))\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Define small offsets for each dataset\n",
    "    offsets = [-0.3, -0.1, 0.1, 0.3]\n",
    "    \n",
    "    # Plotting the data as points\n",
    "    ax.scatter(np.array(range(len(labels))) + offsets[0], pr_sdnn, label='DeepSet', color='#ff5b5b', marker='o', s=100)\n",
    "    ax.scatter(np.array(range(len(labels))) + offsets[1], pr_ln, label='LorentzNet', color='#ffc140', marker='o', s=100)\n",
    "    ax.scatter(np.array(range(len(labels))) + offsets[2], pr_pt, label='ParticleTransformer', color='#89cded', marker='o', s=100)\n",
    "    ax.scatter(np.array(range(len(labels))) + offsets[3], pr_hps, label='HPS', color='green', marker='o', s=100)\n",
    "    \n",
    "    ax.set_xlabel('Decay Modes')\n",
    "    ax.set_ylabel('Precision', x=1.05)\n",
    "    ax.set_title(f\"Classification Precision of the DMs for {dataset}\", y=1.05)\n",
    "    ax.set_xticks(x)\n",
    "    ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=True)\n",
    "    ax.tick_params(axis='y', which='both', left=True, right=False, labelleft=True)\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    ax.set_xticklabels(labels, rotation=45)\n",
    "    legend = ax.legend(loc='lower left', shadow=True, fancybox=True, framealpha=1, borderpad=1)\n",
    "    \n",
    "    # Vertical lines between the DMs\n",
    "    for i in range(len(labels)):\n",
    "        ax.axvline(i - 0.5, color='gray', linestyle='--', linewidth=0.5, zorder=0)\n",
    "\n",
    "    # Function to add labels to the datapoints\n",
    "    def annotate_points(x, y, offset):\n",
    "        for ii, (i, j) in enumerate(zip(x, y)):\n",
    "            ax.annotate(f'{j:.3f}', (i, j), textcoords=\"offset points\", xytext=offset, ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    # Annotate the datapoints with different alignments\n",
    "    annotate_points(np.array(range(len(labels))) + offsets[0], pr_sdnn, (-18, -4))\n",
    "    annotate_points(np.array(range(len(labels))) + offsets[1], pr_ln, (-18, -4))\n",
    "    annotate_points(np.array(range(len(labels))) + offsets[2], pr_pt, (-18, -4))\n",
    "    annotate_points(np.array(range(len(labels))) + offsets[2], pr_hps, (-18, -4))\n",
    "\n",
    "    legend = ax.legend(loc='lower left', shadow=True, fancybox=True, framealpha=1, borderpad=1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"{dataset}_dm_precision.pdf\"), bbox_inches='tight', format='pdf')\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c2de54-97b7-4d6f-95d8-4c5c2da7c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decay_modes(\"DeepSet\")\n",
    "plot_decay_modes(\"LorentzNet\")\n",
    "plot_decay_modes(\"ParticleTransformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ee92d-ace3-4dc9-b57a-3a3d5ca38821",
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_plot(\"ZH\")\n",
    "CM_plot(\"Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c34850b-b7f9-4117-95c3-034c885e3296",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dm_prec(\"ZH\")\n",
    "plot_dm_prec(\"Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de3d6da-937a-4f86-9164-067667f19f74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

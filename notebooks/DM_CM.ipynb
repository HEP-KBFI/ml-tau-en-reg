{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "038cc922-a195-4941-bce5-dbc4aa8e0694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hydra\n",
    "import numpy as np\n",
    "import enreg.tools.general as g\n",
    "import mplhep as hep\n",
    "import awkward as ak\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import DictConfig\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from matplotlib import cm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3580249-c747-4234-8267-c298f826d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.style.use(\"CMS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bc3194a-8d4e-48d9-b010-eeca4adf6273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1] Loading from /scratch/persistent/joosep/ml-tau/20240520_qq_zh_2m_merged/zh_test.parquet\n",
      "Input data loaded\n",
      "[1/1] Loading from /scratch/persistent/joosep/ml-tau/20240520_qq_zh_2m_merged/z_test.parquet\n",
      "Input data loaded\n"
     ]
    }
   ],
   "source": [
    "data_zh = g.load_all_data([\"/scratch/persistent/joosep/ml-tau/20240520_qq_zh_2m_merged/zh_test.parquet\"])\n",
    "data_z = g.load_all_data([\"/scratch/persistent/joosep/ml-tau/20240520_qq_zh_2m_merged/z_test.parquet\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fb490e4-cf9b-4a74-bb3d-a02a6e0f8012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1] Loading from /local/joosep/ml-tau-en-reg/results/240524_cosinescheduler/dm_multiclass/ParticleTransformer/zh_test.parquet\n",
      "Input data loaded\n",
      "[1/1] Loading from /local/joosep/ml-tau-en-reg/results/240524_cosinescheduler/dm_multiclass/LorentzNet/zh_test.parquet\n",
      "Input data loaded\n",
      "[1/1] Loading from /local/joosep/ml-tau-en-reg/results/240524_cosinescheduler/dm_multiclass/SimpleDNN/zh_test.parquet\n",
      "Input data loaded\n"
     ]
    }
   ],
   "source": [
    "paths_zh_model = {\n",
    "    \"ParticleTransformer\": \"/local/joosep/ml-tau-en-reg/results/240524_cosinescheduler/dm_multiclass/ParticleTransformer/zh_test.parquet\",\n",
    "    \"LorentzNet\": \"/local/joosep/ml-tau-en-reg/results/240524_cosinescheduler/dm_multiclass/LorentzNet/zh_test.parquet\",\n",
    "    \"SimpleDNN\": \"/local/joosep/ml-tau-en-reg/results/240524_cosinescheduler/dm_multiclass/SimpleDNN/zh_test.parquet\",\n",
    "}\n",
    "\n",
    "data_zh_model = {k: g.load_all_data([v])[\"dm_multiclass\"][\"pred\"] for (k, v) in paths_zh_model.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8530cf6d-cfea-4e5c-91ff-2d76ef326607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1] Loading from /local/joosep/ml-tau-en-reg/results/240524_cosinescheduler/dm_multiclass/ParticleTransformer/z_test.parquet\n",
      "Input data loaded\n",
      "[1/1] Loading from /local/joosep/ml-tau-en-reg/results/240524_cosinescheduler/dm_multiclass/LorentzNet/z_test.parquet\n",
      "Input data loaded\n",
      "[1/1] Loading from /local/joosep/ml-tau-en-reg/results/240524_cosinescheduler/dm_multiclass/SimpleDNN/z_test.parquet\n",
      "Input data loaded\n"
     ]
    }
   ],
   "source": [
    "paths_z_model = {\n",
    "    \"ParticleTransformer\": \"/local/joosep/ml-tau-en-reg/results/240524_cosinescheduler/dm_multiclass/ParticleTransformer/z_test.parquet\",\n",
    "    \"LorentzNet\": \"/local/joosep/ml-tau-en-reg/results/240524_cosinescheduler/dm_multiclass/LorentzNet/z_test.parquet\",\n",
    "    \"SimpleDNN\": \"/local/joosep/ml-tau-en-reg/results/240524_cosinescheduler/dm_multiclass/SimpleDNN/z_test.parquet\",\n",
    "}\n",
    "\n",
    "data_z_model = {k: g.load_all_data([v])[\"dm_multiclass\"][\"pred\"] for (k, v) in paths_z_model.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e09ef30a-a66e-4806-a129-605219ae7385",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(\"../outputs/plots/\")\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7445c1ea-7e5d-42c8-b8dd-bdbc4a75e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions\n",
    "\n",
    "#---------------For getting the distribution of the decay modes-----------------------------------------------------------------------------\n",
    "\n",
    "# Function for plotting the distribution of the decay modes\n",
    "def plot_decay_modes(model):\n",
    "    dms = np.arange(17)\n",
    "    x = data_zh[\"gen_jet_tau_decaymode\"]\n",
    "    y = data_zh_model[model]\n",
    "    bins=dms\n",
    "    if model == \"SimpleDNN\":\n",
    "        plt.hist([x, y], bins, label=['Actual decaymode', 'DeepSet'])\n",
    "    else:\n",
    "        plt.hist([x, y], bins, label=['Actual decaymode', model])\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(\"Actual vs predicted decaymodes\")\n",
    "    plt.yscale('log')\n",
    "    plt.xticks(dms+0.4, dms);\n",
    "    plt.savefig(os.path.join(output_dir, f\"dm_{model}.pdf\"), bbox_inches='tight', format='pdf')\n",
    "    plt.close(\"all\")\n",
    "\n",
    "#---------------For getting the confusion matrices-----------------------------------------------------------------------------\n",
    "\n",
    "# Function for aggregating specific classes of the confusion matrix\n",
    "def aggregate_classes(cm, classes_to_merge):\n",
    "    num_classes = cm.shape[0]\n",
    "    new_num_classes = num_classes - len(classes_to_merge) + 1\n",
    "    new_cm = np.zeros((new_num_classes, new_num_classes))\n",
    "    \n",
    "    if classes_to_merge == [2, 3, 4]:\n",
    "        merge_index = 2  # Index for the merged class\n",
    "    elif classes_to_merge == [4, 5]:\n",
    "        merge_index = 4\n",
    "\n",
    "    # Classes that are not being merged\n",
    "    classes_to_keep = [i for i in range(num_classes) if i not in classes_to_merge]\n",
    "\n",
    "    # Mapping old indices to new indices\n",
    "    index_map = {}\n",
    "    new_index = 0\n",
    "\n",
    "    # Insert classes to keep before the merge_index\n",
    "    for old_index in classes_to_keep:\n",
    "        if new_index == merge_index:\n",
    "            new_index += 1\n",
    "        index_map[old_index] = new_index\n",
    "        new_index += 1\n",
    "\n",
    "    # Map the merged classes to the merge_index\n",
    "    for cls in classes_to_merge:\n",
    "        index_map[cls] = merge_index\n",
    "\n",
    "    # Aggregate the confusion matrix\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            new_i = index_map[i]\n",
    "            new_j = index_map[j]\n",
    "            new_cm[new_i, new_j] += cm[i, j]\n",
    "\n",
    "    return new_cm\n",
    "\n",
    "# Function for normalizing the confusion matrix\n",
    "def normalize_confusion_matrix(cm):\n",
    "    column_sums = cm.sum(axis=0, keepdims=True)\n",
    "    normalized_cm = cm / column_sums\n",
    "    return normalized_cm\n",
    "\n",
    "# Function for plotting the DM confusion matrices\n",
    "def CM_plot(dataset):\n",
    "\n",
    "    models = [\"SimpleDNN\", \"LorentzNet\", \"ParticleTransformer\"]\n",
    "    for model_name in models:\n",
    "        if dataset == \"ZH\":\n",
    "            y_true = np.array(data_zh[\"gen_jet_tau_decaymode\"])\n",
    "            y_pred = np.array(data_zh_model[model_name])\n",
    "        elif dataset == \"Z\":\n",
    "            y_true = np.array(data_z[\"gen_jet_tau_decaymode\"])\n",
    "            y_pred = np.array(data_z_model[model_name])    \n",
    "        \n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        # Aggregate classes in the confusion matrix\n",
    "        new_cm_ = aggregate_classes(cm, [2, 3, 4]) # These are 1h2pi0, 1h3pi0, 1hNpi0\n",
    "        new_cm = aggregate_classes(new_cm_, [4, 5]) # These are 3h1pi0, 3h2pi0 in the new aggregated matrix\n",
    "\n",
    "        # Normalize the matrix\n",
    "        normalized_cm = normalize_confusion_matrix(new_cm)\n",
    "    \n",
    "        mirrored_cm = np.flipud(normalized_cm)\n",
    "        \n",
    "        new_labels = [r'$h^\\pm$', r'$h^\\pm+\\pi^0$', r'$h^\\pm+\\geq2\\pi^0$', r'$h^\\pm h^\\mp h^\\pm$', r'$h^\\pm h^\\mp h^\\pm$' '\\n' r'$+\\geq\\pi^0$', 'Rare']\n",
    "    \n",
    "        fig, ax = plt.subplots()\n",
    "        cax = ax.matshow(mirrored_cm, cmap='GnBu') # color scheme\n",
    "        \n",
    "        for (i, j), val in np.ndenumerate(mirrored_cm):\n",
    "            ax.text(j, i, f'{val:.2f}', ha='center', va='center', color='black')\n",
    "    \n",
    "        ax.set_xticks(np.arange(len(new_labels)))\n",
    "        ax.set_yticks(np.arange(len(new_labels)))\n",
    "        ax.set_xticklabels(new_labels, rotation=45)\n",
    "        ax.tick_params(axis='x', which='both', bottom=True, top=True, labeltop=False, labelbottom=True)\n",
    "        ax.set_yticklabels(new_labels[::-1]) \n",
    "        ax.set_xlabel('Predicted')\n",
    "        ax.set_ylabel('True')\n",
    "        ax.set_title(f\"{dataset} Confusion Matrix\", y=1.05)\n",
    "        fig.colorbar(cax)\n",
    "        plt.savefig(os.path.join(output_dir, f\"{dataset}_cm_{model_name}.pdf\"), bbox_inches='tight', format='pdf')\n",
    "        plt.close(\"all\")\n",
    "\n",
    "#---------------For plotting the classification precision of the DMs-----------------------------------------------------------------------------\n",
    "\n",
    "# Function to get precisions of the models\n",
    "def get_precision(dataset):\n",
    "    \n",
    "    model_precisions = []\n",
    "    models = [\"SimpleDNN\", \"LorentzNet\", \"ParticleTransformer\"]\n",
    "    for model_name in models:\n",
    "        if dataset == \"ZH\":\n",
    "            y_true = np.array(data_zh[\"gen_jet_tau_decaymode\"])\n",
    "            y_pred = np.array(data_zh_model[model_name])\n",
    "        elif dataset == \"Z\":\n",
    "            y_true = np.array(data_z[\"gen_jet_tau_decaymode\"])\n",
    "            y_pred = np.array(data_z_model[model_name])    \n",
    "        \n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        new_cm_ = aggregate_classes(cm, [2, 3, 4])\n",
    "        new_cm = aggregate_classes(new_cm_, [4, 5])\n",
    "        normalized_cm = normalize_confusion_matrix(new_cm)\n",
    "        \n",
    "        #compute neccesary values to get precision\n",
    "        tp_and_fn = normalized_cm.sum(1)\n",
    "        tp_and_fp = normalized_cm.sum(0)\n",
    "        tp = normalized_cm.diagonal()\n",
    "        \n",
    "        precision = tp / tp_and_fp\n",
    "\n",
    "        model_precisions.append(precision)\n",
    "    return model_precisions\n",
    "\n",
    "# Function to plot the classification precision of the DMs\n",
    "def plot_dm_prec(dataset):\n",
    "    \n",
    "    if dataset == \"ZH\":\n",
    "        pr = get_precision(\"ZH\")\n",
    "    elif dataset == \"Z\":\n",
    "        pr = get_precision(\"Z\")\n",
    "\n",
    "    pr_sdnn, pr_ln, pr_pt = pr[0], pr[1], pr[2]\n",
    "    \n",
    "    labels = [r'$h^\\pm$', r'$h^\\pm+\\pi^0$', r'$h^\\pm+\\geq2\\pi^0$', r'$h^\\pm h^\\mp h^\\pm$', r'$h^\\pm h^\\mp h^\\pm$' '\\n' r'$+\\geq\\pi^0$', 'Rare']\n",
    "    \n",
    "    # Create a mapping from labels to their positions on the x-axis\n",
    "    x = range(len(labels))\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # Plotting the data as points\n",
    "    ax.scatter(x, pr_sdnn, label='DeepSet', color='#ff5b5b', marker='o', s=100)\n",
    "    ax.scatter(x, pr_ln, label='LorentzNet', color='#ffc140', marker='o', s=100)\n",
    "    ax.scatter(x, pr_pt, label='ParticleTransformer', color='#89cded', marker='o', s=100)\n",
    "    \n",
    "    ax.set_xlabel('Decay Modes')\n",
    "    ax.set_ylabel('Precision', x=1.05)\n",
    "    ax.set_title(f\"Classification Precision of the DMs for {dataset}\", y=1.05)\n",
    "    ax.set_xticks(x)\n",
    "    ax.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=True)\n",
    "    ax.tick_params(axis='y', which='both', left=True, right=False, labelleft=True)\n",
    "    ax.set_xticklabels(labels, rotation=45)\n",
    "    legend = ax.legend(loc='lower left', shadow=True, fancybox=True, framealpha=1, borderpad=1)\n",
    "    \n",
    "    # Vertical lines between the DMs\n",
    "    for i in range(len(labels)):\n",
    "        ax.axvline(i - 0.5, color='gray', linestyle='--', linewidth=0.5, zorder=0)\n",
    "\n",
    "    # Function to add labels to the datapoints\n",
    "    def annotate_points(x, y, offset):\n",
    "        for (i, j) in zip(x, y):\n",
    "            ax.annotate(f'{j:.2f}', (i, j), textcoords=\"offset points\", xytext=offset, ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    # Annotate the datapoints with different alignments\n",
    "    annotate_points(x, pr_sdnn, (-16, -4))\n",
    "    annotate_points(x, pr_ln, (16, -4))\n",
    "    annotate_points(x, pr_pt, (-16, -4))\n",
    "\n",
    "    legend = ax.legend(loc='lower left', shadow=True, fancybox=True, framealpha=1, borderpad=1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"{dataset}_dm_precision.pdf\"), bbox_inches='tight', format='pdf')\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58c2de54-97b7-4d6f-95d8-4c5c2da7c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decay_modes(\"SimpleDNN\")\n",
    "plot_decay_modes(\"LorentzNet\")\n",
    "plot_decay_modes(\"ParticleTransformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a2ee92d-ace3-4dc9-b57a-3a3d5ca38821",
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_plot(\"ZH\")\n",
    "CM_plot(\"Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c34850b-b7f9-4117-95c3-034c885e3296",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dm_prec(\"ZH\")\n",
    "plot_dm_prec(\"Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f061a3fb-881a-4c73-a827-b574db87ffd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf2e03a-2a98-4267-a4a4-707c76abe414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import torch\n",
    "import numpy as np\n",
    "import vector\n",
    "import tqdm\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80efbc5d-a691-4272-8e1c-1d59586d2284",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "cls_loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "reg_loss = nn.L1Loss(reduction=\"none\")\n",
    "dm_loss = nn.CrossEntropyLoss(reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc2025e-ae5f-479a-96db-ac4563109346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def med_iqr(arr):\n",
    "    if len(arr) > 0:\n",
    "        p25 = np.percentile(arr, 25)\n",
    "        p50 = np.percentile(arr, 50)\n",
    "        p75 = np.percentile(arr, 75)\n",
    "    else:\n",
    "        p25 = 0.0\n",
    "        p50 = 0.0\n",
    "        p75 = 0.0\n",
    "    return p50, p75 - p25\n",
    "\n",
    "def to_p4(p4_obj):\n",
    "    if \"tau\" in p4_obj.fields:\n",
    "        return vector.awk(\n",
    "            ak.zip(\n",
    "                {\n",
    "                    \"mass\": p4_obj.tau,\n",
    "                    \"px\": p4_obj.x,\n",
    "                    \"py\": p4_obj.y,\n",
    "                    \"pz\": p4_obj.z,\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    elif \"t\" in p4_obj.fields:\n",
    "        return vector.awk(\n",
    "            ak.zip(\n",
    "                {\n",
    "                    \"energy\": p4_obj.t,\n",
    "                    \"px\": p4_obj.x,\n",
    "                    \"py\": p4_obj.y,\n",
    "                    \"pz\": p4_obj.z,\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        raise Exception(\"Unknown fields: {}\".format(p4_obj.fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf21d0e-7195-47fb-90a3-d57abc0abbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ak.from_parquet(\"/home/norman/ml-tau-en-reg/enreg/data/zh.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d447c6-6c7b-4bf4-b639-40a8ffad7d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " ...,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True]\n",
       "-------------------\n",
       "type: 530722 * bool</pre>"
      ],
      "text/plain": [
       "<Array [True, True, True, True, ..., True, True, True] type='530722 * bool'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['gen_jet_tau_decaymode'] != -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef41054a-7d01-42a1-953b-3cb4fee97df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        module\n",
       "\u001b[0;31mString form:\u001b[0m <module 'torch.nn.functional' from '/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py'>\n",
       "\u001b[0;31mFile:\u001b[0m        /opt/conda/lib/python3.10/site-packages/torch/nn/functional.py\n",
       "\u001b[0;31mDocstring:\u001b[0m   Functional interface."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.nn.functional?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "224302fa-c097-4cc4-bf29-3717f3e94c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stores the observables and targets for either one jet, or a batch of jets\n",
    "class Jet:\n",
    "    def __init__(\n",
    "        self,\n",
    "        pfs: torch.Tensor,\n",
    "        pfs_mask: torch.Tensor,\n",
    "        reco_jet_pt: torch.Tensor,\n",
    "        gen_tau_label: torch.Tensor,\n",
    "        gen_tau_pt: torch.Tensor\n",
    "    ):\n",
    "        self.pfs = pfs\n",
    "        self.pfs_mask = pfs_mask\n",
    "        self.reco_jet_pt = reco_jet_pt\n",
    "        self.gen_tau_label = gen_tau_label\n",
    "        self.gen_tau_pt = gen_tau_pt\n",
    "        \n",
    "class TauDataset(Dataset):\n",
    "    def __init__(self, filenames):\n",
    "        datas = []\n",
    "\n",
    "        #load all files, concatenate, shuffle\n",
    "        for fn in filenames:\n",
    "            d = ak.from_parquet(fn)\n",
    "            datas.append(d)\n",
    "        data_all = ak.concatenate(datas, axis=0)\n",
    "        sort_idx = np.random.permutation(len(data_all))\n",
    "        data_all = data_all[sort_idx]\n",
    "\n",
    "        #per-jet PF candidates\n",
    "        pf_p4s = to_p4(data_all[\"reco_cand_p4s\"])\n",
    "\n",
    "        #indices to map each PF candidate to jet \n",
    "        self.pf_lengths = ak.to_numpy(ak.num(pf_p4s))\n",
    "        self.pf_startidx = np.cumsum(self.pf_lengths)\n",
    "        self.pf_startidx -= self.pf_lengths\n",
    "\n",
    "        #per PF candidate observables\n",
    "        self.pf_pt = torch.unsqueeze(torch.tensor(ak.to_numpy(ak.flatten(pf_p4s.pt))), axis=-1).to(torch.float32)\n",
    "        self.pf_eta = torch.unsqueeze(torch.tensor(ak.to_numpy(ak.flatten(pf_p4s.eta))), axis=-1).to(torch.float32)\n",
    "        self.pf_phi = torch.unsqueeze(torch.tensor(ak.to_numpy(ak.flatten(pf_p4s.phi))), axis=-1).to(torch.float32)\n",
    "        self.pf_energy = torch.unsqueeze(torch.tensor(ak.to_numpy(ak.flatten(pf_p4s.energy))), axis=-1).to(torch.float32)\n",
    "        self.pf_pdg = torch.unsqueeze(torch.tensor(ak.to_numpy(ak.flatten(np.abs(data_all[\"reco_cand_pdg\"])))), axis=-1).to(torch.float32)\n",
    "        self.pf_charge = torch.unsqueeze(torch.tensor(ak.to_numpy(ak.flatten(data_all[\"reco_cand_charge\"]))), axis=-1).to(torch.float32)\n",
    "\n",
    "        #per-jet observables\n",
    "        reco_jet_p4s = to_p4(data_all[\"reco_jet_p4s\"])\n",
    "        self.reco_jet_pts = torch.unsqueeze(torch.tensor(ak.to_numpy(reco_jet_p4s.pt)), axis=-1).to(torch.float32)\n",
    "\n",
    "        #per-jet targets\n",
    "        gen_jet_p4s = to_p4(data_all[\"gen_jet_tau_p4s\"])\n",
    "        print(gen_jet_p4s.fields)\n",
    "        self.gen_tau_labels = torch.unsqueeze(torch.tensor(ak.to_numpy(data_all[\"gen_jet_tau_decaymode\"])), axis=-1).to(torch.float32)\n",
    "        self.gen_tau_pts = torch.unsqueeze(torch.tensor(ak.to_numpy(gen_jet_p4s.pt)), axis=-1).to(torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pf_lengths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert(isinstance(idx, int))\n",
    "\n",
    "        #get the indices of the PF candidates of the jet at 'idx'\n",
    "        pf_range = range(self.pf_startidx[idx], self.pf_startidx[idx] + self.pf_lengths[idx])\n",
    "        pf_pt = self.pf_pt[pf_range]\n",
    "        pf_eta = self.pf_eta[pf_range]\n",
    "        pf_phi = self.pf_phi[pf_range]\n",
    "        pf_energy = self.pf_energy[pf_range]\n",
    "        pf_pdg = self.pf_pdg[pf_range] #FIXME: this could be better as a one-hot encoded value, rather than a floating-point PDGID value\n",
    "        pf_charge = self.pf_charge[pf_range]\n",
    "        pfs = torch.concatenate([pf_pt, pf_eta, torch.sin(pf_phi), torch.cos(pf_phi), pf_energy, pf_pdg, pf_charge], axis=-1)\n",
    "        \n",
    "        return Jet(\n",
    "            pfs=pfs,\n",
    "            pfs_mask=torch.ones(pfs.shape[0], dtype=torch.float32),\n",
    "            reco_jet_pt=self.reco_jet_pts[idx],\n",
    "            gen_tau_label=self.gen_tau_labels[idx],\n",
    "            gen_tau_pt=self.gen_tau_pts[idx]\n",
    "        )\n",
    "        \n",
    "#given multiple jets with a variable number of PF candidates per jet, create 3d-padded arrays\n",
    "#in the shape [Njets, Npfs_max, Nfeat]\n",
    "def pad_collate(jets):\n",
    "    pfs = [jet.pfs for jet in jets]\n",
    "    pfs_mask = [jet.pfs_mask for jet in jets]\n",
    "    gen_tau_label = [jet.gen_tau_label for jet in jets]\n",
    "    gen_tau_pt = [jet.gen_tau_pt for jet in jets]\n",
    "    reco_jet_pt = [jet.reco_jet_pt for jet in jets]\n",
    "    \n",
    "    pfs = torch.nn.utils.rnn.pad_sequence(pfs, batch_first=True)\n",
    "    pfs_mask = torch.nn.utils.rnn.pad_sequence(pfs_mask, batch_first=True)\n",
    "    gen_tau_label = torch.concatenate(gen_tau_label, axis=0)\n",
    "    gen_tau_pt = torch.concatenate(gen_tau_pt, axis=0)\n",
    "    reco_jet_pt = torch.concatenate(reco_jet_pt, axis=0)\n",
    "    \n",
    "    return Jet(\n",
    "        pfs=pfs,\n",
    "        pfs_mask=pfs_mask,\n",
    "        reco_jet_pt=reco_jet_pt,\n",
    "        gen_tau_label=gen_tau_label,\n",
    "        gen_tau_pt=gen_tau_pt\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8876aaf-8ff8-47c5-bb27-6c064f1fe69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_kwargs = {\n",
    "    \"batch_size\": 2048,\n",
    "    \"collate_fn\": pad_collate,\n",
    "    \"num_workers\": 8,\n",
    "    \"prefetch_factor\": 20,\n",
    "    # \"pin_memory\": True,\n",
    "    # \"pin_memory_device\": \"cuda\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01eee254-84e3-47c8-994b-70da77619a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'y', 'z', 'tau']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = ak.from_parquet(\"/home/norman/ml-tau-en-reg/enreg/data/qq.parquet\")\n",
    "d1[\"gen_jet_tau_p4s\"].fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5df4435-d30a-45a2-b700-2b49be8dc90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'y', 'z', 'tau']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = ak.from_parquet(\"/home/norman/ml-tau-en-reg/enreg/data/z.parquet\")\n",
    "d2[\"gen_jet_tau_p4s\"].fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35ad1701-8f8a-444d-963e-c8976b4aff4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'y', 'z', 'tau']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3 = ak.from_parquet(\"/home/norman/ml-tau-en-reg/enreg/data/zh.parquet\")\n",
    "d3[\"gen_jet_tau_p4s\"].fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87179ebc-dfbb-4fc1-81aa-535766736dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'y', 'z', 'tau']\n"
     ]
    }
   ],
   "source": [
    "#for training the tau classifier, use tau and non-tau datasets\n",
    "ds_sig_and_bkg = TauDataset([\"/home/norman/ml-tau-en-reg/enreg/data/qq.parquet\", \"/home/norman/ml-tau-en-reg/enreg/data/z.parquet\"])\n",
    "# ds_sig_and_bkg = torch.utils.data.Subset(ds_sig_and_bkg, range(200000))\n",
    "ds_train, ds_val = torch.utils.data.random_split(ds_sig_and_bkg, [0.6, 0.4])\n",
    "\n",
    "dl_sig_and_bkg_train = torch.utils.data.DataLoader(ds_train, **loader_kwargs)\n",
    "dl_sig_and_bkg_val = torch.utils.data.DataLoader(ds_val, **loader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18afa5ca-cf47-47e5-9ef3-22969e07d53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'y', 'z', 'tau']\n"
     ]
    }
   ],
   "source": [
    "#for training tau pt regression and decay mode, only use the tau dataset\n",
    "ds_sig = TauDataset([\"/home/norman/ml-tau-en-reg/enreg/data/z.parquet\", \"/home/norman/ml-tau-en-reg/enreg/data/zh.parquet\"])\n",
    "# ds_sig = torch.utils.data.Subset(ds_sig, range(200000))\n",
    "ds_train, ds_val = torch.utils.data.random_split(ds_sig_and_bkg, [0.6, 0.4])\n",
    "\n",
    "dl_sig_train = torch.utils.data.DataLoader(ds_train, **loader_kwargs)\n",
    "dl_sig_val = torch.utils.data.DataLoader(ds_val, **loader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "489ad1c9-b51c-4c7c-bfe5-bfa009362975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffn(input_dim, output_dim, width, act, dropout):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, width),\n",
    "        act(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(width, width),\n",
    "        act(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(width, width),\n",
    "        act(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(width, output_dim),\n",
    "    )\n",
    "    \n",
    "class DeepSet(nn.Module):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(DeepSet, self).__init__()\n",
    "\n",
    "        self.act = nn.ReLU\n",
    "        self.act_obj = self.act()\n",
    "        self.dropout = 0.1\n",
    "        self.width = 64\n",
    "        self.embedding_dim = 64\n",
    "\n",
    "        #number of inputs\n",
    "        self.num_pf_features = 7\n",
    "\n",
    "        self.nn_pf_embedding = ffn(self.num_pf_features, self.embedding_dim, self.width, self.act, self.dropout)\n",
    "        self.nn_pred = ffn(self.embedding_dim, num_outputs, self.width, self.act, self.dropout)\n",
    "\n",
    "    def forward(self, pfs_pad, pfs_mask):\n",
    "        pfs_mask = torch.unsqueeze(pfs_mask, axis=-1)\n",
    "        pf_encoded = self.act_obj(self.nn_pf_embedding(pfs_pad))*pfs_mask\n",
    "        num_pfs = torch.sum(pfs_mask, axis=1)\n",
    "        jet_encoded1 = self.act_obj(torch.sum(pf_encoded, axis=1)/num_pfs)\n",
    "        ret = self.nn_pred(jet_encoded1)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "484ad2e6-aa61-452a-8c25-eac3b5ea239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loop(model, optimizer, ds_loader, dev, is_train=True, kind=\"binary\"):\n",
    "    loss_tot = 0.0\n",
    "    pred_vals = []\n",
    "    true_vals = []\n",
    "    for ibatch, batched_jets in enumerate(tqdm.tqdm(ds_loader, total=len(ds_loader), ncols=80)):\n",
    "        \n",
    "        pfs = batched_jets.pfs.to(dev, non_blocking=True)\n",
    "        pfs_mask = batched_jets.pfs_mask.to(dev, non_blocking=True)\n",
    "        gen_tau_label = batched_jets.gen_tau_label.to(dev, non_blocking=True)\n",
    "        true_istau = gen_tau_label!=-1\n",
    "\n",
    "        pred = model(pfs, pfs_mask)\n",
    "\n",
    "        if kind == \"binary\":\n",
    "            assert(pred.shape[1] == 2)\n",
    "            pred_vals.append(pred[:, 1].detach().cpu())\n",
    "            true_vals.append(true_istau.cpu())\n",
    "            loss = cls_loss(pred, true_istau.long()).mean()\n",
    "        elif kind == \"ptreg\":\n",
    "            #pred = log(ptgen/ptreco) -> ptgen = exp(pred)*ptreco\n",
    "            assert(pred.shape[1] == 1)\n",
    "            pred = torch.squeeze(pred, dim=-1)\n",
    "            gen_tau_pt = batched_jets.gen_tau_pt.to(dev, non_blocking=True)\n",
    "            reco_jet_pt = batched_jets.reco_jet_pt.to(dev, non_blocking=True)\n",
    "\n",
    "            target = torch.log(gen_tau_pt/reco_jet_pt)\n",
    "            \n",
    "            pred_pt = torch.exp(pred) * reco_jet_pt\n",
    "            pred_vals.append(pred_pt[gen_tau_label!=-1].detach().cpu())\n",
    "            true_vals.append(gen_tau_pt[gen_tau_label!=-1].cpu())\n",
    "            loss = reg_loss(pred[true_istau], target[true_istau])\n",
    "            loss = torch.sum(loss) / torch.sum(true_istau)\n",
    "        elif kind == \"dm_multiclass\":\n",
    "            assert(pred.shape[1] == 16)\n",
    "            pred_vals.append(torch.argmax(pred[true_istau], axis=-1).detach().cpu())\n",
    "            true_vals.append(gen_tau_label[true_istau].cpu())\n",
    "            target_onehot = torch.nn.functional.one_hot(gen_tau_label[true_istau].long(), 16).float()\n",
    "            \n",
    "            # print(\"target\", target_onehot.shape)\n",
    "            # print(\"target\", target_onehot)\n",
    "            print(\"pred\", pred.shape)\n",
    "            print(\"pred\", pred)\n",
    "            # print(\"-----------------\")\n",
    "            print(torch.argmax(pred, axis=-1))\n",
    "            # print(torch.argmax(pred[true_istau], axis=-1)[0])\n",
    "            # print(gen_tau_label[true_istau])\n",
    "            \n",
    "            loss = dm_loss(pred[true_istau], target_onehot)\n",
    "            loss = torch.sum(loss) / torch.sum(true_istau)\n",
    "        else:\n",
    "            raise Exception(\"Unknown kind={}\".format(kind))\n",
    "            \n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        loss_tot += loss.detach().cpu().item()\n",
    "    return loss_tot, pred_vals, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e10e7a77-ce23-4799-acf2-5d376c4a30f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "argmax(input) -> LongTensor\n",
       "\n",
       "Returns the indices of the maximum value of all elements in the :attr:`input` tensor.\n",
       "\n",
       "This is the second value returned by :meth:`torch.max`. See its\n",
       "documentation for the exact semantics of this method.\n",
       "\n",
       ".. note:: If there are multiple maximal values then the indices of the first maximal value are returned.\n",
       "\n",
       "Args:\n",
       "    input (Tensor): the input tensor.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> a = torch.randn(4, 4)\n",
       "    >>> a\n",
       "    tensor([[ 1.3398,  0.2663, -0.2686,  0.2450],\n",
       "            [-0.7401, -0.8805, -0.3402, -1.1936],\n",
       "            [ 0.4907, -1.3948, -1.0691, -0.3132],\n",
       "            [-1.6092,  0.5419, -0.2993,  0.3195]])\n",
       "    >>> torch.argmax(a)\n",
       "    tensor(0)\n",
       "\n",
       ".. function:: argmax(input, dim, keepdim=False) -> LongTensor\n",
       "   :noindex:\n",
       "\n",
       "Returns the indices of the maximum values of a tensor across a dimension.\n",
       "\n",
       "This is the second value returned by :meth:`torch.max`. See its\n",
       "documentation for the exact semantics of this method.\n",
       "\n",
       "Args:\n",
       "    input (Tensor): the input tensor.\n",
       "    dim (int): the dimension to reduce. If ``None``, the argmax of the flattened input is returned.\n",
       "    keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> a = torch.randn(4, 4)\n",
       "    >>> a\n",
       "    tensor([[ 1.3398,  0.2663, -0.2686,  0.2450],\n",
       "            [-0.7401, -0.8805, -0.3402, -1.1936],\n",
       "            [ 0.4907, -1.3948, -1.0691, -0.3132],\n",
       "            [-1.6092,  0.5419, -0.2993,  0.3195]])\n",
       "    >>> torch.argmax(a, dim=1)\n",
       "    tensor([ 0,  2,  0,  1])\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.argmax?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9b1df3-5d33-4f08-bff7-1068e8776d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train binary classification head with two outputs (tau vs. notau logits)\n",
    "model_binary_classifier = DeepSet(2).to(device)\n",
    "optimizer = torch.optim.AdamW(model_binary_classifier.parameters(), lr=1e-3)\n",
    "\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "\n",
    "for iepoch in range(20):\n",
    "    loss_train, _, _ = model_loop(model_binary_classifier, optimizer, dl_sig_and_bkg_train, device, True, kind=\"binary\")\n",
    "    loss_val, pred_val_cls, true_val_cls = model_loop(model_binary_classifier, optimizer, dl_sig_and_bkg_val, device, False, kind=\"binary\")\n",
    "    print(\"{} L={:.2f}/{:.2f}\".format(iepoch, loss_train, loss_val))\n",
    "    losses_train.append(loss_train)\n",
    "    losses_val.append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c17f2a-7a09-4a19-9d3c-008d50b294ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = sklearn.metrics.roc_curve(torch.concatenate(true_val_cls), torch.concatenate(pred_val_cls))\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title(\"epoch={} val_loss={:.2f}\".format(iepoch, loss_val))\n",
    "plt.plot(tpr, fpr)\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim(1e-6,1)\n",
    "plt.xlim(0,1)\n",
    "plt.xlabel(\"TPR\")\n",
    "plt.ylabel(\"FPR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fac614-3ab0-440c-9b78-cb9b3c5856fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses_train, label=\"train\")\n",
    "plt.plot(losses_val, label=\"validation\")\n",
    "plt.ylim(losses_val[-1]*0.5, losses_val[-1]*4)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss, tau identification\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3aafd4-b1a2-4cbb-ae1e-d27336f82d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train pt regression head, predicts one value: y=log(ptgen/ptreco)\n",
    "model_ptreg = DeepSet(1).to(device)\n",
    "optimizer = torch.optim.AdamW(model_ptreg.parameters(), lr=1e-3)\n",
    "\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "\n",
    "for iepoch in range(20):\n",
    "    loss_train, _, _ = model_loop(model_ptreg, optimizer, dl_sig_train, device, is_train=True, kind=\"ptreg\")\n",
    "    loss_val, pred_val_reg, true_val_reg = model_loop(model_ptreg, optimizer, dl_sig_val, device, is_train=False, kind=\"ptreg\")\n",
    "    print(\"{} L={:.2f}/{:.2f}\".format(iepoch, loss_train, loss_val))\n",
    "    losses_train.append(loss_train)\n",
    "    losses_val.append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13571b3c-93a5-4e16-8534-946c01a2b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses_train, label=\"train\")\n",
    "plt.plot(losses_val, label=\"validation\")\n",
    "#plt.ylim(losses_val[-1]*0.8, losses_val[-1]*1.5)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss, pt regression\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f86af3-f4fd-486a-a265-b392ae9304ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pts = torch.concatenate(true_val_reg)\n",
    "pred_pts = torch.concatenate(pred_val_reg)\n",
    "b = np.linspace(0,200,100)\n",
    "plt.hist(true_pts, bins=b, histtype=\"step\", lw=1, label=\"true\");\n",
    "plt.hist(pred_pts, bins=b, histtype=\"step\", lw=1, label=\"pred\");\n",
    "plt.xlabel(\"pT\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132329b3-d8c5-40a9-8430-a8f491678a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.linspace(0,200,100)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist2d(true_pts, pred_pts, bins=(b,b), cmap=\"Blues\");\n",
    "plt.plot([0,200], [0,200], color=\"black\", ls=\"--\", lw=0.5)\n",
    "plt.xlabel(\"true pT\")\n",
    "plt.ylabel(\"pred pT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d92fe5f-1e1f-4f9c-9e73-226f1cce6872",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.linspace(0,200,100)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist2d(true_pts, pred_pts, bins=(b,b), cmap=\"Blues\", norm=matplotlib.colors.LogNorm());\n",
    "plt.plot([0,200], [0,200], color=\"black\", ls=\"--\", lw=0.5)\n",
    "plt.xlabel(\"true pT\")\n",
    "plt.ylabel(\"pred pT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67683138-2702-4dea-9fea-678161e88bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.linspace(0,2,100)\n",
    "plt.figure(figsize=(5,5))\n",
    "ratio = pred_pts/true_pts\n",
    "plt.hist(ratio, bins=b, histtype=\"step\", lw=1);\n",
    "med, iqr = med_iqr(ratio)\n",
    "plt.title(\"M={:.2f}, IQR/M={:.2f}\".format(med, iqr/med))\n",
    "plt.axvline(1.0, color=\"black\", ls=\"--\", lw=0.5)\n",
    "plt.xlabel(\"pred/true pT\")\n",
    "plt.ylabel(\"number of jets / bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba97e08e-2642-4c9e-9516-745ea0f7e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pts[(true_pts>20) & (true_pts<30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84383ea6-f942-451f-a8b1-cf8c0c87f8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.linspace(0,10,100)\n",
    "plt.figure(figsize=(5,5))\n",
    "ratio = pred_pts/true_pts\n",
    "plt.hist(ratio, bins=b, histtype=\"step\", lw=1);\n",
    "plt.yscale(\"log\")\n",
    "med, iqr = med_iqr(ratio)\n",
    "plt.title(\"M={:.2f}, IQR/M={:.2f}\".format(med, iqr/med))\n",
    "plt.axvline(1.0, color=\"black\", ls=\"--\", lw=0.5)\n",
    "plt.xlabel(\"pred/true pT\")\n",
    "plt.ylabel(\"number of jets / bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e63b00-2f6b-4819-923d-7f53abae39bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [20,30,40,50,60,70,80,90,100,125,150,175,200]\n",
    "medvals = []\n",
    "meanvals = []\n",
    "iqrvals = []\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "for ibin in range(len(bins)-1):\n",
    "    msk = (true_pts>bins[ibin]) & (true_pts<bins[ibin+1])\n",
    "    med, iqr = med_iqr(ratio[msk])\n",
    "    meanvals.append(ratio[msk].mean())\n",
    "    ax1 = plt.subplot(3, 4, ibin+1)\n",
    "    plt.title(\"bin={},{}\".format(bins[ibin], bins[ibin+1]))\n",
    "    plt.hist(ratio[msk], bins=np.linspace(0.5,1.5,101), histtype=\"step\", lw=0.5, density=1, color=\"black\")\n",
    "    medvals.append(med)\n",
    "    iqrvals.append(iqr/med)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684d9d8f-7efc-4927-98e1-ba42351bd250",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(bins[:-1], medvals, marker=\"o\")\n",
    "plt.ylabel(\"median of pred/true pT\")\n",
    "plt.axhline(1.0, color=\"black\", ls=\"--\")\n",
    "plt.ylim(0.95,1.05)\n",
    "plt.xlabel(\"true pT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbefbf22-7b37-4fe5-986f-7a06e8bc882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(bins[:-1], iqrvals, marker=\"o\")\n",
    "plt.ylabel(\"IQR/median of pred/true pT\")\n",
    "plt.xlabel(\"true pT\")\n",
    "plt.ylim(0.0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79515bec-4cb7-4205-b141-60b77a27e69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 1/1167 [00:02<50:50,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred torch.Size([2048, 16])\n",
      "pred tensor([[ 0.0351, -0.2065,  0.2026,  ...,  0.0713, -0.0439, -0.0272],\n",
      "        [-0.0097, -0.1422,  0.1584,  ...,  0.0242, -0.0528, -0.0526],\n",
      "        [ 0.0017, -0.1560,  0.1268,  ...,  0.0235, -0.0215, -0.0631],\n",
      "        ...,\n",
      "        [-0.0849, -0.1639,  0.1564,  ...,  0.0175, -0.0050, -0.1179],\n",
      "        [ 0.0499, -0.1587,  0.1605,  ...,  0.0879, -0.0410, -0.0129],\n",
      "        [-0.0111, -0.1507,  0.1327,  ...,  0.0293, -0.0663, -0.0427]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([ 2,  2,  2,  ...,  2, 11, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 2/1167 [00:03<26:31,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred torch.Size([2048, 16])\n",
      "pred tensor([[-0.0322, -0.1238,  0.1523,  ...,  0.0061,  0.0257, -0.1456],\n",
      "        [-0.0427, -0.0812,  0.1197,  ..., -0.0076, -0.0448, -0.1854],\n",
      "        [-0.0197, -0.1014,  0.1294,  ...,  0.0091, -0.0666, -0.1692],\n",
      "        ...,\n",
      "        [-0.0086, -0.0493,  0.1655,  ...,  0.0021, -0.0100, -0.0564],\n",
      "        [ 0.0280, -0.0543,  0.1408,  ...,  0.0148, -0.0871, -0.0623],\n",
      "        [ 0.0104, -0.0874,  0.1508,  ...,  0.0077, -0.1012, -0.0920]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([2, 5, 2,  ..., 2, 2, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 3/1167 [00:03<16:19,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred torch.Size([2048, 16])\n",
      "pred tensor([[-0.0066, -0.0419,  0.1598,  ...,  0.0045, -0.1137, -0.1301],\n",
      "        [ 0.0207, -0.0196,  0.1986,  ..., -0.0242, -0.1004, -0.1001],\n",
      "        [-0.0387, -0.0668,  0.1508,  ...,  0.0540, -0.0353, -0.1040],\n",
      "        ...,\n",
      "        [ 0.0835, -0.0506,  0.1541,  ...,  0.0072, -0.1580, -0.0860],\n",
      "        [ 0.0603, -0.0479,  0.2256,  ...,  0.0353, -0.0743, -0.0921],\n",
      "        [ 0.0122, -0.0270,  0.2125,  ..., -0.0128, -0.0988, -0.1693]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([2, 2, 2,  ..., 2, 2, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                         | 4/1167 [00:03<12:05,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred torch.Size([2048, 16])\n",
      "pred tensor([[ 0.0519, -0.0320,  0.1547,  ..., -0.0007, -0.0538, -0.1894],\n",
      "        [ 0.0522, -0.0355,  0.2177,  ..., -0.0155, -0.0637, -0.1615],\n",
      "        [ 0.0222,  0.0224,  0.2269,  ...,  0.0694, -0.0795, -0.1351],\n",
      "        ...,\n",
      "        [-0.0126, -0.0301,  0.1819,  ...,  0.0502, -0.1261, -0.1538],\n",
      "        [ 0.0175,  0.0438,  0.2075,  ...,  0.0121, -0.1162, -0.0779],\n",
      "        [-0.0063, -0.0550,  0.2155,  ..., -0.0810, -0.0707, -0.1454]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([ 2,  2,  2,  ..., 10,  2,  2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                         | 4/1167 [00:04<19:59,  1.03s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m losses_val \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iepoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     loss_train, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_sig_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdm_multiclass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     loss_val, pred_val_dm, true_val_dm \u001b[38;5;241m=\u001b[39m model_loop(model_dm, optimizer, dl_sig_val, device, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdm_multiclass\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m L=\u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(iepoch, loss_train, loss_val))\n",
      "Cell \u001b[0;32mIn[59], line 12\u001b[0m, in \u001b[0;36mmodel_loop\u001b[0;34m(model, optimizer, ds_loader, dev, is_train, kind)\u001b[0m\n\u001b[1;32m      9\u001b[0m gen_tau_label \u001b[38;5;241m=\u001b[39m batched_jets\u001b[38;5;241m.\u001b[39mgen_tau_label\u001b[38;5;241m.\u001b[39mto(dev, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m true_istau \u001b[38;5;241m=\u001b[39m gen_tau_label\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 12\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpfs_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m(pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 33\u001b[0m, in \u001b[0;36mDeepSet.forward\u001b[0;34m(self, pfs_pad, pfs_mask)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, pfs_pad, pfs_mask):\n\u001b[1;32m     32\u001b[0m     pfs_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(pfs_mask, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m     pf_encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_obj(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn_pf_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpfs_pad\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m*\u001b[39mpfs_mask\n\u001b[1;32m     34\u001b[0m     num_pfs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(pfs_mask, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     35\u001b[0m     jet_encoded1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_obj(torch\u001b[38;5;241m.\u001b[39msum(pf_encoded, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m/\u001b[39mnum_pfs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train pt regression head, predicts one value: y=log(ptgen/ptreco)\n",
    "model_dm = DeepSet(16).to(device)\n",
    "optimizer = torch.optim.AdamW(model_dm.parameters(), lr=1e-3)\n",
    "\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "\n",
    "for iepoch in range(20):\n",
    "    loss_train, _, _ = model_loop(model_dm, optimizer, dl_sig_train, device, is_train=True, kind=\"dm_multiclass\")\n",
    "    loss_val, pred_val_dm, true_val_dm = model_loop(model_dm, optimizer, dl_sig_val, device, is_train=False, kind=\"dm_multiclass\")\n",
    "    print(\"{} L={:.2f}/{:.2f}\".format(iepoch, loss_train, loss_val))\n",
    "    losses_train.append(loss_train)\n",
    "    losses_val.append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "298c93f7-a58f-4397-a307-d60cc1451913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8e5b754220>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGwCAYAAABIC3rIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABpl0lEQVR4nO3deXhMZ/sH8O9MkpnsM4nsRMQWCYldxFqvEGtRXagqLdWfUiUo2lpKa2uLeqtU376li3q11qKIfYvQ2PckQkI2EslkkW3m/P4YmWZkQiZmMpPk+7muc8mc88yZ+3Ewt+c8535EgiAIICIiIqrFxKYOgIiIiMjUmBARERFRrceEiIiIiGo9JkRERERU6zEhIiIiolqPCRERERHVekyIiIiIqNazNHUA1YVKpUJSUhIcHBwgEolMHQ4RERFVgCAIyM7OhpeXF8Ti8seBmBBVUFJSEry9vU0dBhEREVVCYmIi6tWrV+5xJkQV5ODgAED9G+ro6GjiaIiIiKgiFAoFvL29Nd/j5WFCVEElt8kcHR2ZEBEREVUzz5ruwknVREREVOsxISIiIqJajwkRERER1XqcQ0RERLWOUqlEUVGRqcMgA7CysoKFhcVzn4cJERER1RqCICAlJQWZmZmmDoUMSC6Xw8PD47nqBDIhIiKiWqMkGXJzc4OtrS0L7VZzgiAgLy8PaWlpAABPT89Kn4sJERER1QpKpVKTDNWpU8fU4ZCB2NjYAADS0tLg5uZW6dtnnFRNRES1QsmcIVtbWxNHQoZWck2fZ14YEyIiIqpVeJus5jHENWVCRERERLUeEyIiIiKq9ZgQERER1SINGjTAihUrTB2G2eFTZiZ2+V4WXOyl8JBZmzoUIiIyUy+88AJatWplkETmzJkzsLOze/6gahgmRCb0qFCJ9349i4e5hZjZrxmGt68PsZiT/YiISD+CIECpVMLS8tlf666urlUQUfXDW2Ym9DCvEE52EmQXFOPjrZcx/PtTuHU/x9RhERHVCoIgIK+w2CSbIAgVjnP06NE4cuQIvv76a4hEIohEIqxbtw4ikQh//fUX2rZtC6lUiuPHjyMuLg6DBg2Cu7s77O3t0b59e+zfv1/rfE/eMhOJRPjPf/6DIUOGwNbWFk2aNMGOHTsM9dtcbZh0hOjo0aP44osvEB0djeTkZGzduhWDBw/WHN+yZQvWrFmD6OhoZGRk4Ny5c2jVqpXWOfLz8zF16lRs3LgRBQUFCAsLw7fffgt3d3dNm4SEBIwfPx6HDh2Cvb09Ro0ahUWLFlUokzYmL7kNtozvhHUnb+PLvTcQFZ+BPl8fw+TQJnina0NYWTBfJSIylkdFSgTM2WuSz746Pwy2kop9B3399de4efMmWrRogfnz5wMArly5AgCYOXMmvvzySzRs2BBOTk5ITExEv3798Pnnn0MqleKnn37CwIEDcePGDdSvX7/cz/j000+xdOlSfPHFF/j3v/+NESNG4M6dO3B2dn7+zlYTJv3Gzc3NRcuWLbFq1apyj3fp0gVLliwp9xxTpkzBn3/+id9//x1HjhxBUlISXnrpJc1xpVKJ/v37o7CwECdPnsT69euxbt06zJkzx+D9qQwLsQhjuvhi35Ru6NrEBYXFKizdcwODV53A5XtZpg6PiIhMTCaTQSKRwNbWFh4eHvDw8NBUY54/fz569eqFRo0awdnZGS1btsS7776LFi1aoEmTJliwYAEaNWr0zBGf0aNHY/jw4WjcuDEWLlyInJwcnD59uiq6ZzZMOkTSt29f9O3bt9zjI0eOBADcvn1b5/GsrCz88MMP2LBhA/71r38BAH788Uf4+/vj1KlT6NixI/bt24erV69i//79cHd3R6tWrbBgwQLMmDED8+bNg0QiMXi/KsPb2RY/vd0Bm8/ew4KdV3ElSYFBq05gbFdfTAltCmur51/Jl4iI/mFjZYGr88NM9tmG0K5dO63XOTk5mDdvHnbt2oXk5GQUFxfj0aNHSEhIeOp5goKCND/b2dnB0dFRsz5YbVGt78lER0ejqKgIoaGhmn3NmjVD/fr1ERkZCQCIjIxEYGCg1i20sLAwKBQKzZCjLgUFBVAoFFqbsYlEIrzcth72h3dH/0BPKFUCvjtyC31WHEVkXLrRP5+IqDYRiUSwlViaZDNUtewnnxabNm0atm7dioULF+LYsWM4f/48AgMDUVhY+NTzWFlZlfm9UalUBomxuqjWCVFKSgokEgnkcrnWfnd3d6SkpGjalE6GSo6XHCvPokWLIJPJNJu3t7dhg38KVwcpVo1og7Uj28LdUYrb6XkY/v0pzNpyEVmPKr9OCxERVU8SiQRKpfKZ7U6cOIHRo0djyJAhCAwMhIeHR7l3WUhbtU6IjGnWrFnIysrSbImJiVUeQ+/mHogI747Xg9UT4X47nYhey45g75XyEzkiIqp5GjRogKioKNy+fRsPHjwod/SmSZMm2LJlC86fP48LFy7g9ddfr3UjPZVVrRMiDw8PFBYWIjMzU2t/amoqPDw8NG1SU1PLHC85Vh6pVApHR0etzRQcra2wcEggNo7rCF8XO6RlF+Ddn6Px3q/RSMvON0lMRERUtaZNmwYLCwsEBATA1dW13DlBy5Ytg5OTEzp16oSBAwciLCwMbdq0qeJoq6dqXZixbdu2sLKywoEDBzB06FAAwI0bN5CQkICQkBAAQEhICD7//HOkpaXBzc0NABAREQFHR0cEBASYLHZ9dWxYB3990BVfH4jB2qO3sPtSCk7EpuPj/v54pW09rt5MRFSDNW3aVDM3tsTo0aPLtGvQoAEOHjyotW/ChAlar5+8haarJtKTAw21gUkTopycHMTGxmpex8fH4/z583B2dkb9+vWRkZGBhIQEJCUlAVAnOwA0jx3KZDKMGTMG4eHhcHZ2hqOjI95//32EhISgY8eOAIDevXsjICAAI0eOxNKlS5GSkoJPPvkEEyZMgFQqrfpOPwdrKwvM6NMM/QM9MWPzRVxJUuDDPy5ix/kkLBwSiPp1bE0dIhERUbVk0ltmf//9N1q3bo3WrVsDAMLDw9G6dWtNjaAdO3agdevW6N+/PwBg2LBhaN26NdasWaM5x/LlyzFgwAAMHToU3bp1g4eHB7Zs2aI5bmFhgZ07d8LCwgIhISF444038Oabb2qKW1VHLerKsH1CZ8zs2wxSSzGOxz5A2Iqj+M+xW1CqKl79lIiIiNREgj71w2sxhUIBmUyGrKwsk80n0iX+QS5mbbmIU7cyAAAt68mw5OUgNPMwnxiJiMxBfn4+4uPj4evrC2trLqhdkzzt2lb0+7taT6omwNfFDhvGdsSilwLhILXEhbtZGLDyOL7adwMFxc9+RJOIiIiYENUIYrEIwzvUx/6p3dE7wB3FKgH/PhiLfl8fw9+3M0wdHhERkdljQlSDuDta47uRbfHtiDZwsZci7n4uXvkuEnO2X0ZOQbGpwyMiIjJbTIhqGJFIhH6Bntgf3g2vtK0HQQB+iryD3suO4ND12rUuDRERUUUxIaqh5LYSfPFKS/wyJhjezjZIysrHW+vO4ION55CeU2Dq8IiIiMwKE6IarksTF+yd3A1ju/hCLAK2n09Cr+VHse3cPZ3FuIiIqOZp0KABVqxYoXktEomwbdu2ctvfvn0bIpEI58+ff67PNdR5qgITolrAVmKJTwYEYMt7ndHMwwEZuYWY/L/zeGvdGdzLfGTq8IiIqIolJyejb9++Bj3n6NGjMXjwYK193t7eSE5ORosWLQz6WcbAhKgWaeUtx46JXTC1V1NILMQ4fOM+ei87gvUnb0PFgo5ERLWGh4dHlazWYGFhAQ8PD1hamv9KYUyIahmJpRjv92yC3R90QTsfJ+QWKjF3xxW88l0kYtOyTR0eERE9Ye3atfDy8iqzav2gQYPw9ttvIy4uDoMGDYK7uzvs7e3Rvn177N+//6nnfPKW2enTp9G6dWtYW1ujXbt2OHfunFZ7pVKJMWPGwNfXFzY2NvDz88PXX3+tOT5v3jysX78e27dvh0gkgkgkwuHDh3XeMjty5Ag6dOgAqVQKT09PzJw5E8XF/zwJ/cILL2DSpEn48MMP4ezsDA8PD8ybN0//3zg9MSGqpRq7OWDTuyGYP6g57CQWiL7zEP2+Po6VB2JQWKx69gmIiKo7QQAKc02z6TGH85VXXkF6ejoOHTqk2ZeRkYE9e/ZgxIgRyMnJQb9+/XDgwAGcO3cOffr0wcCBA5GQkFCh8+fk5GDAgAEICAhAdHQ05s2bh2nTpmm1UalUqFevHn7//XdcvXoVc+bMwUcffYRNmzYBAKZNm4ZXX30Vffr0QXJyMpKTk9GpU6cyn3Xv3j3069cP7du3x4ULF7B69Wr88MMP+Oyzz7TarV+/HnZ2doiKisLSpUsxf/58REREVPj3rDLMfwyLjEYsFuHNkAbo6e+OT7ZewqEb97Es4iZ2X0rG4qFBaOUtN3WIRETGU5QHLPQyzWd/lARI7CrU1MnJCX379sWGDRvQs2dPAMAff/wBFxcX9OjRA2KxGC1bttS0X7BgAbZu3YodO3Zg4sSJzzz/hg0boFKp8MMPP8Da2hrNmzfH3bt3MX78eE0bKysrfPrpp5rXvr6+iIyMxKZNm/Dqq6/C3t4eNjY2KCgogIeHR7mf9e2338Lb2xvffPMNRCIRmjVrhqSkJMyYMQNz5syBWKwepwkKCsLcuXMBAE2aNME333yDAwcOoFevXhX6PasMjhAR6spt8N/R7fH1sFZwtpPgeko2Xvr2BBbsvIq8QhZ0JCIytREjRmDz5s0oKFCXTfn1118xbNgwiMVi5OTkYNq0afD394dcLoe9vT2uXbtW4RGia9euISgoSGsNsJCQkDLtVq1ahbZt28LV1RX29vZYu3ZthT+j9GeFhIRAJBJp9nXu3Bk5OTm4e/euZl9QUJDW+zw9PZGWZtxaehwhIgDq+8mDWtVFl8YuWLDzKradT8IPx+Ox72oKFg0JQpcmLqYOkYjIsKxs1SM1pvpsPQwcOBCCIGDXrl1o3749jh07huXLlwNQ366KiIjAl19+icaNG8PGxgYvv/wyCgsLDRbuxo0bMW3aNHz11VcICQmBg4MDvvjiC0RFRRnsM0qzsrLSei0SicrMoTI0JkSkpY69FCuGtcag1nXx8ZZLSMx4hDd+iMLLbevhk/7+kNtKTB0iEZFhiEQVvm1latbW1njppZfw66+/IjY2Fn5+fmjTpg0A4MSJExg9ejSGDBkCQD0n6Pbt2xU+t7+/P37++Wfk5+drRolOnTql1ebEiRPo1KkT3nvvPc2+uLg4rTYSiQRK5dMXFff398fmzZshCIJmlOjEiRNwcHBAvXr1KhyzMfCWGenUw88N+8K7Y1SID0Qi4I/ouwhddhS7LiazoCMRkQmMGDECu3btwn//+1+MGDFCs79JkybYsmULzp8/jwsXLuD111/XazTl9ddfh0gkwjvvvIOrV69i9+7d+PLLL7XaNGnSBH///Tf27t2LmzdvYvbs2Thz5oxWmwYNGuDixYu4ceMGHjx4gKKiojKf9d577yExMRHvv/8+rl+/ju3bt2Pu3LkIDw/XzB8yFSZEVC57qSU+HdQCf/xfCBq52uFBTgEmbDiLcT9HIyUr39ThERHVKv/617/g7OyMGzdu4PXXX9fsX7ZsGZycnNCpUycMHDgQYWFhmtGjirC3t8eff/6JS5cuoXXr1vj444+xZMkSrTbvvvsuXnrpJbz22msIDg5Genq61mgRALzzzjvw8/NDu3bt4OrqihMnTpT5rLp162L37t04ffo0WrZsif/7v//DmDFj8Mknn+j5u2F4IoH/3a8QhUIBmUyGrKwsODo6mjqcKldQrMSqg7H49nAcilUCHKSWmNXPH8Pae0MsFj37BEREJpafn4/4+Hj4+vpqTSCm6u9p17ai398cIaIKkVpaILy3H3ZO6oKW3nJkFxTjo62XMPz7U4h/kGvq8IiIiJ4LEyLSSzMPR2wZ3wmf9PeHjZUFouIz0GfFUaw+HIdiJQs6EhFR9cSEiPRmIRZhbNeG2DelG7o0dkFBsQpL9lzHoFUncPlelqnDIyIi0hsTIqo0b2db/DymA754OQgyGytcSVJg0KoTWPzXdeQXPf3RSyIiInPChIiei0gkwivtvBER3g39Az2hVAlYcyQOfb8+hlO30k0dHhFRGXyWqOYxxDVlQkQG4eZgjVUj2mDtyLZwd5Qi/kEuhq09hVlbLkGRX7YWBRFRVSupfpyXl2fiSMjQSq7pkxWu9cFK1WRQvZt7oGOjOli0+zp+O52A304n4OD1VCwY1AK9m5e/4B8RkbFZWFhALpdr1sSytbXVWlOLqh9BEJCXl4e0tDTI5XJYWFhU+lysQ1RBtb0OUWWcupWOmZsv4na6OnPvH+iJeS82h6uD1MSREVFtJQgCUlJSkJmZaepQyIDkcjk8PDx0JrgV/f5mQlRBTIgqJ79IiRX7Y/D9sVtQqgTIbKzwSX9/vNy2Hv9nRkQmo1QqdS4tQdWPlZXVU0eGmBAZGBOi53P5XhZmbL6IK0kKAEDXJi5YOCQQ3s76rfhMRESkD1aqJrPSoq4M2yZ0xow+zSC1FONYzAP0Xn4U/3k8ckRERGRKTIioylhZiDH+hUbYM7kbgn2d8ahIic92XcNLq0/ieorC1OEREVEtxoSIqpyvix1+e6cjFg4JhIPUEhcSMzFg5XEs23cDBcUs6EhERFWPCRGZhFgswuvB9RER3h29AtxRrBKw8mAs+q88jug7GaYOj4iIahkmRGRSHjJrrB3ZFqtebwMXewli03Lw8ppIzN1+GTkFxaYOj4iIagkmRGRyIpEI/YM8sT+8O15uWw+CAKyPvIPey47g0I00U4dHRES1ABMiMhtyWwm+fKUlfh7TAfWcbJCUlY+3fjyDyRvPISO30NThERFRDcaEiMxO1yau2DelG8Z08YVYBGw7n4TQZUew/fw9LspIRERGwYSIzJKtxBKzBwRgy3ud4efugIzcQnyw8TzeXncG9zIfmTo8IiKqYZgQkVlr5S3Hn+93QXivppBYiHHoxn30XnYEP0XehooFHYmIyECYEJHZk1iKMalnE+z+oAva+jght1CJOduv4NXvIhGblmPq8IiIqAZgQkTVRmM3B/z+bgg+fbE57CQW+PvOQ/T7+hj+fSAGhcUqU4dHRETVGBMiqlbEYhFGdWqAfeHd8YKfKwqVKnwVcRMvfnMcFxIzTR0eERFVU0yIqFqqK7fBj6PbY8VrreBka4XrKdkY8u0JfLbzKvIKWdCRiIj0w4SIqi2RSITBretif3h3DG7lBZUA/Od4PMJWHMXxmAemDo+IiKoRJkRU7dWxl2LFsNb4cXR7eMmskZjxCG/8EIXpv19AVl6RqcMjIqJqgAkR1Rg9mrlhX3h3vBniA5EI+D36LnouO4Ldl5JZ0JGIiJ6KCRHVKPZSS8wf1AK/vxuCRq52eJBTgPd+PYt3f45GqiLf1OEREZGZMmlCdPToUQwcOBBeXl4QiUTYtm2b1nFBEDBnzhx4enrCxsYGoaGhiImJ0WqTkZGBESNGwNHREXK5HGPGjEFOjnZtmosXL6Jr166wtraGt7c3li5dauyukYm1a+CMXZO64v1/NYalWIR9V1MRuuwIfjudwNEiIiIqw6QJUW5uLlq2bIlVq1bpPL506VKsXLkSa9asQVRUFOzs7BAWFob8/H/+pz9ixAhcuXIFERER2LlzJ44ePYpx48ZpjisUCvTu3Rs+Pj6Ijo7GF198gXnz5mHt2rVG7x+ZlrWVBab29sOf73dBy3oyZOcXY9aWSxj+/SncfpBr6vCIiMiMiAQz+e+ySCTC1q1bMXjwYADq0SEvLy9MnToV06ZNAwBkZWXB3d0d69atw7Bhw3Dt2jUEBATgzJkzaNeuHQBgz5496NevH+7evQsvLy+sXr0aH3/8MVJSUiCRSAAAM2fOxLZt23D9+vVy4ykoKEBBQYHmtUKhgLe3N7KysuDo6Gik3wUyFqVKwI8n4vHlvhvIL1JBainGlF5NMbaLLywteOeYiKimUigUkMlkz/z+Nttvgvj4eKSkpCA0NFSzTyaTITg4GJGRkQCAyMhIyOVyTTIEAKGhoRCLxYiKitK06datmyYZAoCwsDDcuHEDDx8+LPfzFy1aBJlMptm8vb0N3UWqQhZiEcZ2bYh9k7ujS2MXFBSrsPiv6xj87QlcScoydXhERGRiZpsQpaSkAADc3d219ru7u2uOpaSkwM3NTeu4paUlnJ2dtdroOkfpz9Bl1qxZyMrK0myJiYnP1yEyC/Xr2OLnMR2w9OUgOFpb4vI9BV785gSW7LmO/CKlqcMjIiITsazMm1QqFWJjY5GWlgaVSnsNqW7duhkkMFOTSqWQSqWmDoOMQCQS4dV23njBzxXzdlzB7kspWH04Dnsup2DxS4EIbljH1CESEVEV0zshOnXqFF5//XXcuXOnzNM6IpEISqVh/pft4eEBAEhNTYWnp6dmf2pqKlq1aqVpk5aWpvW+4uJiZGRkaN7v4eGB1NRUrTYlr0vaUO3k5mCNb0e0xd4rKZi97TLiH+TitbWn8Hpwfczs2wyO1lamDpGIiKqI3rfM/u///g/t2rXD5cuXkZGRgYcPH2q2jIwMgwXm6+sLDw8PHDhwQLNPoVAgKioKISEhAICQkBBkZmYiOjpa0+bgwYNQqVQIDg7WtDl69CiKiv6pWBwREQE/Pz84OTkZLF6qvsKaeyAivDuGd6gPANgQlYBey44g4mrqM95JREQ1hd5PmdnZ2eHChQto3Ljxc394Tk4OYmNjAQCtW7fGsmXL0KNHDzg7O6N+/fpYsmQJFi9ejPXr18PX1xezZ8/GxYsXcfXqVVhbWwMA+vbti9TUVKxZswZFRUV466230K5dO2zYsAGA+sk0Pz8/9O7dGzNmzMDly5fx9ttvY/ny5VqP5z9LRWepU/UWGZeOWVsu4nZ6HgCgf5An5g1sDlcH3j4lIqqOKvz9LeipR48ewl9//aXv23Q6dOiQAKDMNmrUKEEQBEGlUgmzZ88W3N3dBalUKvTs2VO4ceOG1jnS09OF4cOHC/b29oKjo6Pw1ltvCdnZ2VptLly4IHTp0kWQSqVC3bp1hcWLF+sda1ZWlgBAyMrKqnR/qXp4VFgsLNx9VWg4a5fgM2OnEDRvr/D734mCSqUydWhERKSnin5/6z1CtHXrVnzyySeYPn06AgMDYWWlPc8iKChIv9StmuAIUe1z+V4WPvzjIq4mKwAAXZu4YOGQQHg725o4MiIiqqiKfn/rnRCJxWWnHYlEIgiCYNBJ1eaGCVHtVKRU4T/H4rFi/00UFKtgY2WBaWF+GN2pASzEIlOHR0REz2C0hOjOnTtPPe7j46PP6aoNJkS1W/yDXMzcfBFR8eoHB1p5y7FkaBD8PBxMHBkRET2N0RKi2ooJEalUAjaeScSi3deQXVAMKwsRxr/QGBN6NILU0sLU4RERkQ5GTYji4uKwYsUKXLt2DQAQEBCADz74AI0aNap8xGaOCRGVSMnKxyfbLmP/NfVj+Y3d7LFkaBDa+rCMAxGRuTHaWmZ79+5FQEAATp8+jaCgIAQFBSEqKgrNmzdHRETEcwVNVB14yKzx/Zttser1NnCxlyA2LQcvrzmJeTuuILeg2NThERFRJeg9QtS6dWuEhYVh8eLFWvtnzpyJffv24ezZswYN0FxwhIh0ycwrxGe7ruGP6LsAgLpyG3w+pAVe8HN7xjuJiKgqGO2WmbW1NS5duoQmTZpo7b958yaCgoKQn59fuYjNHBMieppjMfcxa8sl3H34CAAwpHVdzB4QAGc7iYkjIyKq3Yx2y8zV1RXnz58vs//8+fNlVp4nqi26NnHFvindMKaLL0QiYOu5ewhddgTbz98rs+YfERGZH70Xd33nnXcwbtw43Lp1C506dQIAnDhxAkuWLEF4eLjBAySqLmwllpg9IAADgjwxc/Ml3EjNxgcbz2P7+SR8NrgFvOQ2pg6RiIjKofctM0EQsGLFCnz11VdISkoCAHh5eWH69OmYNGkSRKKaWayOt8xIH4XFKqw5EodvDsaiUKmCvdQSM/r4YUSwD8Qs6EhEVGWqpA5RdnY2AMDBoeYXp2NCRJURk5qNmVsuIfrOQwBA+wZOWPRSEBq72Zs4MiKi2oGFGQ2MCRFVlkol4OdTd7B0z3XkFiohsRBjUs/GeLd7I1hZ6D2Nj4iI9GDQhKhNmzY4cOAAnJyc0Lp166feFuNj90S63ct8hI+3XsLhG/cBAM08HLD05SAE1ZObNjAiohqsot/fFZpUPWjQIEilUs3PNXWeEJEx1ZXb4MfR7bHt/D3M//MqrqdkY/CqExjTxRfhvfxgI+HyH0REpsJbZhXEESIypPScAszfeRXbz6sfTKjvbItFLwWic2MXE0dGRFSzGK0OUcOGDZGenl5mf2ZmJho2bKjv6YhqpTr2Unw9rDX+O7odvGTWSMjIw4j/ROHDPy4gK6/I1OEREdU6eidEt2/fhlKpLLO/oKAAd+/eNUhQRLXFv5q5Y194d7wZ4gMA2PT3XfRcdgR/XUo2cWRERLVLhQsz7tixQ/Pz3r17IZPJNK+VSiUOHDgAX19fw0ZHVAvYSy0xf1ALvNjSCzM2X0Tc/VyM//Uswpq7Y/6gFnB3tDZ1iERENV6F5xCJxerBJJFIVGYpAisrKzRo0ABfffUVBgwYYPgozQDnEFFVyC9S4puDsVhzJA7FKgEO1pb4uJ8/XmvvzYcZiIgqwWh1iHx9fXHmzBm4uNSuyZ9MiKgqXUtWYObmi7hwNwsAENKwDha9FIgGLnYmjoyIqHphYUYDY0JEVU2pEvDjiXh8ue8G8otUkFqKEd6rKcZ08YUlCzoSEVWIUROi3NxcHDlyBAkJCSgsLNQ6NmnSJP2jrQaYEJGpJKTnYdbWizgRq366s0VdRywZGoTmXrJnvJOIiIyWEJ07dw79+vVDXl4ecnNz4ezsjAcPHsDW1hZubm64devWcwdvjpgQkSkJgoDfo+/is51XocgvhoVYhHe7NcSknk1gbcWCjkRE5TFaHaIpU6Zg4MCBePjwIWxsbHDq1CncuXMHbdu2xZdffvlcQRORbiKRCK+288b+qd3RL9ADSpWAbw/Hod/XxxB1q2xdMCIi0o/eI0RyuRxRUVHw8/ODXC5HZGQk/P39ERUVhVGjRuH69evGitWkOEJE5mTP5RTM2X4ZadkFAIARwfUxs28zOFhbmTgyIiLzYrQRIisrK80j+G5ubkhISAAAyGQyJCYmVjJcItJHnxYeiAjvjuEdvAEAv0YloNeyo9h/NdXEkRERVU96J0StW7fGmTNnAADdu3fHnDlz8Ouvv2Ly5Mlo0aKFwQMkIt1kNlZY9FIQNrwTjAZ1bJGiyMfYn/7GhA1ncf/xyBEREVWM3gnRwoUL4enpCQD4/PPP4eTkhPHjx+P+/fv47rvvDB4gET1dp0Yu2DO5G97t3hAWYhF2XUxGr+VHsDn6bpkiqkREpBvrEFUQ5xBRdXD5XhY+/OMiriYrAABdm7hg4ZBAeDvbmjgyIiLTMNocovj4eMTExJTZHxMTg9u3b+t7OiIyoBZ1Zdg+sTM+7OMHiaUYx2IeIGzFUfz3eDyUKv7fh4ioPHonRKNHj8bJkyfL7I+KisLo0aMNERMRPQcrCzHee6Ex9nzQFR18nZFXqMT8nVcxdPVJ3EzNNnV4RERmSe+E6Ny5c+jcuXOZ/R07dsT58+cNERMRGUBDV3tsfKcjPh/SAg5SS5xPzET/lcewLOImCoqVpg6PiMis6J0QiUQiZGeX/V9mVlYWlEr+I0tkTsRiEUYE+yAivDtC/d1RpBSw8kAMBqw8jug7D00dHhGR2dA7IerWrRsWLVqklfwolUosWrQIXbp0MWhwRGQYHjJrfP9mW3zzemu42EsQk5aDl9ecxLwdV5BbUGzq8IiITE7vp8yuXr2Kbt26QS6Xo2vXrgCAY8eOQaFQ4ODBgzW2FhGfMqOa4mFuIT7bdQ2bz94FANSV22DhS4Ho3tTVxJERERmeUVe7T0pKwjfffIMLFy7AxsYGQUFBmDhxIpydnZ8raHPGhIhqmqM37+OjrZdw9+EjAMBLrevikwEBcLaTmDgyIiLDMWpCVBsxIaKaKLegGF/tu4kfT8ZDEIA6dhLMGRiAF1t6QSQSmTo8IqLnZtCE6OLFi2jRogXEYjEuXrz41LZBQUH6R1sNMCGimuxcwkPM2HwRN1NzAAA9m7lhweAW8JLbmDgyIqLnY9CESCwWIyUlBW5ubhCLxRCJRDqXBBCJRDX2STMmRFTTFRarsPpwHL45FIMipQB7qSVm9G2GER3qQyzmaBERVU8GTYju3LmD+vXrQyQS4c6dO09t6+Pjo3+01QATIqotYlKzMWPzRZxNyAQAdGjgjEVDA9HI1d60gRERVYJBl+4YMmQIMjMzAQDr16+Hq6srfHx8dG5EVL01cXfA7//XCfMGBsBWYoHTtzPQ9+tjWHUoFkVKlanDIyIyigqNENnY2CAmJgb16tWDhYUFkpOT4ebmVhXxmQ2OEFFtdPdhHj7eehlHbt4HADTzcMDSl4MQVE9u2sCIiCrIoLfMQkJCYG9vjy5duuDTTz/FtGnTYG+ve/h8zpw5lY/ajDEhotpKEARsO38P8/+8iod5RRCLgDFdfBHeyw82EgtTh0dE9FQGTYhu3LiBuXPnIi4uDmfPnkVAQAAsLS3LnkwkwtmzZ58vcjPFhIhquwc5BZj/51XsuJAEAKjvbIvFLwWiU2MXE0dGRFQ+g84h8vPzw8aNG3HmzBkIgoADBw7g3LlzZTZjJEPZ2dmYPHkyfHx8YGNjg06dOuHMmTOa44IgYM6cOfD09ISNjQ1CQ0MRExOjdY6MjAyMGDECjo6OkMvlGDNmDHJycgweK1FN5mIvxcrhrfHf0e3gKbNGQkYeXv9PFGb8cRFZeUWmDo+I6LnovZaZSqWq0vlDY8eORUREBH7++WdcunQJvXv3RmhoKO7duwcAWLp0KVauXIk1a9YgKioKdnZ2CAsLQ35+vuYcI0aMwJUrVxAREYGdO3fi6NGjGDduXJX1gagm+Vczd+yb0g0jO6ofovjf34kIXX4Eey4nmzgyIqLKq9Atsx07dqBv376wsrLCjh07ntr2xRdfNFhwjx49goODA7Zv347+/ftr9rdt2xZ9+/bFggUL4OXlhalTp2LatGkAgKysLLi7u2PdunUYNmwYrl27hoCAAJw5cwbt2rUDAOzZswf9+vXD3bt34eXlVaFYeMuMqKwztzMwY/NF3LqfCwDo09wD8wc1h5ujtYkjIyJSq+j3d9mJQDoMHjxYU5hx8ODB5bYzdGHG4uJiKJVKWFtr/+NqY2OD48ePIz4+HikpKQgNDdUck8lkCA4ORmRkJIYNG4bIyEjI5XJNMgQAoaGhEIvFiIqKwpAhQ3R+dkFBAQoKCjSvFQqFwfpFVFO0b+CM3ZO64puDsVhzJA57rqTgRNwDfNzPH6+19+byH0RUbVTollnp22QqlarczdBVqh0cHBASEoIFCxYgKSkJSqUSv/zyCyIjI5GcnIyUlBQAgLu7u9b73N3dNcdKErnSLC0t4ezsrGmjy6JFiyCTyTSbt7e3QftGVFNYW1lgWpgfdkzsgqB6MmTnF2Pmlkt4/fso3H6Qa+rwiIgqRO85RLqUFG00hp9//hmCIKBu3bqQSqVYuXIlhg8fDrHYIKGXa9asWcjKytJsiYmJRv08ououwMsRW8Z3wsf9/GFtJUbkrXT0+foo1h6NQzELOhKRmdM7q1iyZAn+97//aV6/8sorcHZ2Rt26dXHhwgWDBgcAjRo1wpEjR5CTk4PExEScPn0aRUVFaNiwITw8PAAAqampWu9JTU3VHPPw8EBaWprW8eLiYmRkZGja6CKVSuHo6Ki1EdHTWVqI8U63htg7uRs6NaqD/CIVFu6+jiHfnsTVJN52JiLzpXdCtGbNGs3to4iICOzfvx979uxB3759MX36dIMHWMLOzg6enp54+PAh9u7di0GDBsHX1xceHh44cOCApp1CoUBUVBRCQkIAqItKZmZmIjo6WtPm4MGDUKlUCA4ONlq8RLWZTx07/Do2GEuHBsHR2hKX7mXhxW+O44u915FfVDMXgCai6q1CT5mVZmNjg5s3b8Lb2xsffPAB8vPz8d133+HmzZsIDg7Gw4cPDRrg3r17IQgC/Pz8EBsbi+nTp8Pa2hrHjh2DlZUVlixZgsWLF2P9+vXw9fXF7NmzcfHiRVy9elUzGbtv375ITU3FmjVrUFRUhLfeegvt2rXDhg0bKhwHnzIjqpw0RT7m7riCvy6r5+w1dLHD4qFB6ODrbOLIiKg2MGhhxtKcnJw082n27NmjecJLEASDT6oG1I/RT5gwAc2aNcObb76JLl26YO/evbCysgIAfPjhh3j//fcxbtw4tG/fHjk5OdizZ4/Wk2m//vormjVrhp49e6Jfv37o0qUL1q5da/BYiagsN0drrH6jLda80RZuDlLcepCLV7+LxMdbLyE7nwUdicg86D1CNHHiROzcuRNNmjTBuXPncPv2bdjb22Pjxo1YunQpl+4gonJlPSrCot3XsPGM+j9VnjJrfDa4BXr6uz/jnURElWO0EaLly5dj4sSJCAgIQEREhGaR1+TkZLz33nuVj5iIajyZjRUWDw3ChneC4VPHFslZ+Riz/m+8/9s5PMgpePYJiIiMRO8RotqKI0REhvWoUIkV+2/i+2O3oBIAua0V5gwIwJDWdVnQkYgMxmgjROvXr8euXbs0rz/88EPI5XJ06tQJd+7cqVy0RFTr2EgsMKufP7ZP6AJ/T0dk5hUhfNMFjPrxDBIz8kwdHhHVMnonRAsXLoSNjQ0AIDIyEqtWrcLSpUvh4uKCKVOmGDxAIqrZAuvJsGNiZ0wP84PEUoyjN+8jbMVR/Pd4PJQqDmATUdXQ+5aZra0trl+/jvr162PGjBlITk7GTz/9hCtXruCFF17A/fv3jRWrSfGWGZHxxd3PwazNl3D6dgYAoHV9OZYMDUJTdwcTR0ZE1ZXRbpnZ29sjPT0dALBv3z706tULAGBtbY1Hjx5VMlwiIqCRqz02juuIzwa3gL3UEucSMtF/5TGs2H8ThcVc/oOIjEfvhKhXr14YO3Ysxo4di5s3b6Jfv34AgCtXrqBBgwaGjo+IahmxWIQ3OvogIrwbQv3dUKQUsGJ/DAb8+xjOJhi28CsRUQm9E6JVq1YhJCQE9+/fx+bNm1GnTh0AQHR0NIYPH27wAImodvKU2eD7N9vh38Nbo46dBDdTczB09UnM23EFuQXFpg6PiGoYPnZfQZxDRGQ6D3MLsWDXVWw5ew8AUFdug4UvBaJ7U1cTR0ZE5q6i39+VTojy8vKQkJCAwsJCrf1BQUGVOZ3ZY0JEZHpHbt7HR1su4V6mer7iS63rYvaAADjZSUwcGRGZK6MlRPfv38fo0aOxZ88enceNsZ6ZOWBCRGQecguK8eW+G1h38jYEAahjJ8G8F5tjQJAnCzoSURlGe8ps8uTJyMrKQlRUFGxsbLBnzx6sX78eTZo0wY4dO54raCKiZ7GTWmLuwObYPL4TmrrbIz23EO//dg7v/PQ3krP4pCsRVY7eI0Senp7Yvn07OnToAEdHR/z9999o2rQpduzYgaVLl+L48ePGitWkOEJEZH4Ki1X49nAsVh2KRZFSgL3UEjP6NsOIDvUhFnO0iIiMOEKUm5sLNzc3AICTk5OmEGNgYGCNXemeiMyTxFKMyaFNsWtSV7SuL0dOQTFmb7uMYWtPIe5+jqnDI6JqRO+EyM/PDzdu3AAAtGzZEt999x3u3buHNWvWwNPT0+ABEhE9S1N3B/zxf50wd2AAbCUWOH07A32/PvZ45IgFHYno2fS+ZfbLL7+guLgYo0ePRnR0NPr06YOMjAxIJBKsW7cOr732mrFiNSneMiOqHu4+zMNHWy/j6E316LW/pyOWDg1CYD2ZiSMjIlMw+mP3JfLy8jRrm7m4uDzPqcwaEyKi6kMQBGw9dw/zd15FZl4RxCLgna4NMTm0KWwkFqYOj4iqUJUlRLUFEyKi6udBTgHm/3kVOy4kAQB86thi0ZBAdGpcc//zRkTaDJoQhYeHV/iDly1bVuG21QkTIqLq68C1VHyy7TKSs/IBAK+188ZH/f0hs7EycWREZGwV/f62rMjJzp07V6EPZVE0IjJHPf3d0cHXGUv2XMcvpxLwv78TcfBGGhYMao4+LfgwCBHxllmFcYSIqGY4HZ+BmZsv4taDXABA3xYe+HRQc7g5WJs4MiIyBqPNIcrKyoJSqYSzs7PW/oyMDFhaWtbYZIEJEVHNkV+kxL8PxuC7I7dQrBLgYG2Jzo1c0NjNHo3c7NDI1R4NXe1hL63QIDoRmTGjJUR9+/bFwIED8d5772ntX7NmDXbs2IHdu3dXLmIzx4SIqOa5mqTAjM0Xcelels7jnjJrNHK1RyNXO3Wy5GqPRm72cHOQcooAUTVhtITI2dkZJ06cgL+/v9b+69evo3PnzkhPT69cxGaOCRFRzVSsVOHUrQzcTM1G7P0cxKXlIO5+Lh7kFJT7HgepJRq6qRMldcJkj8Zu9vCpYwsrC73r3RKRERl0UnVpBQUFKC4uLrO/qKgIjx5xYUUiql4sLcTo0sQFXZpoP4qflVekTpBKtrRcxN3PwZ30XGQXFONCYiYuJGZqn0ssQv06tmj8eCSpZHSpkZs9HK35RBuROdN7hKhHjx5o0aIF/v3vf2vtnzBhAi5evIhjx44ZNEBzwREiIgKAgmIlEtLzEJtWkizlPk6YcpBbqCz3fW4O0se33Oy0EiZPmTVvvxEZkdFGiD777DOEhobiwoUL6NmzJwDgwIEDOHPmDPbt21f5iImIqgGppQWauDugibuD1n5BEJCiyEdcWi5i07L/SZTu5yBVUYC0bPUWeUt7WoGtxOKfkaTHt94aPb79JrVkVW2iqlKpx+7Pnz+PL774AufPn4eNjQ2CgoIwa9YsNGnSxBgxmgWOEBFRZSnyi3Drfu7j+Uk5mtGlO+l5KFbp/idYLALqO9v+M5lbM7rkAJktb78RVRSX7jAwJkREZGhFShXupOdpzVOKvZ+DW2k5yC4oO1ezhIu9BA1LRpNKjS7VldtALObtN6LSjHbLjIiIDMPKQozGburEpjRBEHA/u0DrqbeSkaXkrHw8yCnEg5wMnI7P0HqftZUYDV1K5if9UyrA18UO1la8/Ub0NBwhqiCOEBGROcgpKEZ8qQSpZHQp/kEuipS6/zkXiQBvJ9t/ygS4/TO65GwnqeIeEFUt3jIzMCZERGTOipUqJD58VGaeUmxaDhT55d9+c7K1+mcyd6l5SnWdbGDB229UAzAhMjAmRERUHQmCgPTcwn9Gk9L+GV26l1l+7TiJpRgNXf4ZUSoZXWroagdbCWdbUPVh9DlEsbGxiIuLQ7du3WBjYwNBEFhLg4jIzIhEIrjYS+FiL0XHhnW0jj0qVOLWg5LRpH/qKd16kIvCYhWup2Tjekp2mXPWlduUmafUyNUeLvYSfg9QtaX3CFF6ejpee+01HDx4ECKRCDExMWjYsCHefvttODk54auvvjJWrCbFESIiqi2UKgH3Hj7SzE8qXYQyI7ew3Pc5WltqrflWcivO28kGllzShEzEaCNEU6ZMgaWlJRISErTWM3vttdcQHh5eYxMiIqLawuLxEiT169iiRzM3rWMZuYWakaR/kqVcJD7MgyK/GGcTMnE2IVPrPVYWIjSoY6c1T6lkVMlOyttvZB70/pO4b98+7N27F/Xq1dPa36RJE9y5c8dggRERkflxtpPA2c4Z7Rs4a+3PL1LidnquOkEqNU/p1oMc5BepEJOWg5i0nDLn85RZa2oplR5dcnOQ8vYbVSm9E6Lc3FzY2tqW2Z+RkQGpVGqQoIiIqHqxtrJAMw9HNPPQviWhUglIynqEuPu5pSZ2q399kFOI5Kx8JGfl43jsA633OUgt0dDtiSVNXNVLmljx9hsZgd4JUdeuXfHTTz9hwYIFANQT9lQqFZYuXYoePXoYPEAiIqq+xGIR6jnZop6TLbo3ddU6lplXqDWZu2Se0p30XGQXFONCYiYuJGZqvcfy8e280gvkNnK1QyM3ezhac0kTqjy9J1VfvnwZPXv2RJs2bXDw4EG8+OKLuHLlCjIyMnDixAk0atTIWLGaFCdVExFVjYJipXpJk1JJUsnoUl6hstz3uTlIS40m2WkSJk+ZNW+/1WJGrUOUlZWFb775BhcuXEBOTg7atGmDCRMmwNPT87mCNmdMiIiITEsQBKQo8h/PU9Je0iQtu6Dc99lKLLTWfGvsph5d8qljC6kllzSp6ViY0cCYEBERmS9FfhFu3c9FXFpOqTXgcnAnPQ/FKt1fcxZiEeo7l1rSpGRZE1d7yGx5+62mMGhCdPHixQp/cFBQUIXbVidMiIiIqp8ipUp9++2+dpmAW2k5yC4of0kTF3sJGpZe0uTxU3BeMhuIuaRJtWLQhEgsFkMkEpWpRl3y1tL7lMry7+9WZ0yIiIhqDkEQcD+7QKvoZMnPyVn55b7P2kqMhi7/jCSV1FTydbGDtRVvv5kjgxZmjI+P1/x87tw5TJs2DdOnT0dISAgAIDIyEl999RWWLl36nGETEREZn0gkgpujNdwcrdGpsYvWsZyCYsTfz0Xs/WxNTaW4+zmIf5CL/CIVriYrcDVZ8cT5AG8n2zLzlBq52sPZTlKVXaNK0nsOUYcOHTBv3jz069dPa//u3bsxe/ZsREdHGyw4pVKJefPm4ZdffkFKSgq8vLwwevRofPLJJ5pRKUEQMHfuXHz//ffIzMxE586dsXr1ajRp0kRznoyMDLz//vv4888/IRaLMXToUHz99dewt7evcCwcISIiqt2KlSokPnz0RJVu9a+K/PJvvznZWmmt+dbIzQ6NXR1Q18kGFrz9ZnRGW7rj0qVL8PX1LbPf19cXV69e1fd0T7VkyRKsXr0a69evR/PmzfH333/jrbfegkwmw6RJkwAAS5cuxcqVK7F+/Xr4+vpi9uzZCAsLw9WrV2FtbQ0AGDFiBJKTkxEREYGioiK89dZbGDduHDZs2GDQeImIqOaytBDD18UOvi52CIW7Zr8gCHiQU6gZSYpLy9VM7L6X+QgP84pw5vZDnLn9UOt8EksxGrrYlVr77Z/J3TYS3n6ranqPELVp0wYtWrTAf/7zH0gk6mHAwsJCjB07FpcvX8bZs2cNFtyAAQPg7u6OH374QbNv6NChsLGxwS+//AJBEODl5YWpU6di2rRpANQlAdzd3bFu3ToMGzYM165dQ0BAAM6cOYN27doBAPbs2YN+/frh7t278PLy0vnZBQUFKCj45zFOhUIBb29vjhAREVGF5RUWq59+u5+jVYTy1oNcFBaryn1fXbmNJkkqPbrkYi9hTSU9GW2EaM2aNRg4cCDq1auneaLs4sWLEIlE+PPPPysfsQ6dOnXC2rVrcfPmTTRt2hQXLlzA8ePHsWzZMgDquU0pKSkIDQ3VvEcmkyE4OBiRkZEYNmwYIiMjIZfLNckQAISGhkIsFiMqKgpDhgzR+dmLFi3Cp59+atD+EBFR7WIrsUSLujK0qCvT2q9UCbj38JHWrbeSnx/mFeFe5iPcy3yEozfva71PZmP1z0iSZmK3PbydbGDJJU2ei94JUYcOHXDr1i38+uuvuH79OgD1Svevv/467OzsDBrczJkzoVAo0KxZM1hYWECpVOLzzz/HiBEjAAApKSkAAHd3d633ubu7a46lpKTAzU17tWZLS0s4Oztr2ugya9YshIeHa16XjBARERE9L4vHS5DUr2OLHs20v6Mycgs1I0mln4JLfJiHrEdFOJuQibMJmVrvsbIQoUGd0gvk/nP7zU6q91d9rVSp3yU7OzuMGzfO0LGUsWnTJvz666/YsGEDmjdvjvPnz2Py5Mnw8vLCqFGjjPrZUqmUi9USEVGVc7aTwNnOGe0bOGvtzy9SIv5Bbpl5Srce5CC/SIWYtBzEpOWUOZ+nzFp7SZPHo0puDlLefiulUglRXFwcVqxYgWvXrgEAmjdvjkmTJhl8HbPp06dj5syZGDZsGAAgMDAQd+7cwaJFizBq1Ch4eHgAAFJTU7WWDUlNTUWrVq0AAB4eHkhLS9M6b3FxMTIyMjTvJyIiMnfWVhbw93SEv6f2PBiVSkBS1iNN0cnSi+U+yClEclY+krPycTz2gdb7HKSWaOj2xJImruolTaxq4e03vROivXv34sUXX0SrVq3QuXNnAMCJEyfw3Xff4c8//0SvXr0MFlxeXh7EYu2LYmFhAZVKPRHN19cXHh4eOHDggCYBUigUiIqKwvjx4wEAISEhyMzMRHR0NNq2bQsAOHjwIFQqFYKDgw0WKxERkSmIxSLUc7JFPSdbvOCnfSwzr1CdJJWapxR3Pxd30nORXVCMC4mZuJCYqfUeS7EIPnVsSz39pk6WGrrawdG65i5povdTZq1bt0ZYWBgWL16stX/mzJnYt2+fQZ8yGz16NPbv34/vvvsOzZs3x7lz5zBu3Di8/fbbWLJkCQD1o/mLFy/Weuz+4sWLWo/d9+3bF6mpqVizZo3msft27drp9dg96xAREVFNUVCsVC9pkqa9pEnc/RzkFZa/4oSbg1T79pub+mcPR2uzvf1mtMVdra2tcenSJa3ChwBw8+ZNBAUFIT+//JLn+srOzsbs2bOxdetWpKWlwcvLC8OHD8ecOXM0j/yXFGZcu3YtMjMz0aVLF3z77bdo2rSp5jwZGRmYOHGiVmHGlStXsjAjERFRKYIgIDkrv9Rtt3+WNEnLLij3fbYSC60130pGl3zq2EJqadqaSkZLiLy9vbFs2TK88sorWvs3bdqEadOmISEhoXIRmzkmREREVJsp8otwq1SCFJeWg9j7ObiTngelSncqYSEWob6zrdZk7kau6nIBMtuquf1mtDpE77zzDsaNG4dbt26hU6dOANRziJYsWaL1mDoRERHVHI7WVmjlLUcrb7nW/sJiFRIy8p6oqaSet5RTUIz4B7mIf5CL/de0H3BysZdoJUmNXO3QsWEdky2Sq/cIkSAIWLFiBb766iskJSUBALy8vDB9+nRMmjTJbO8hPi+OEBEREVWcIAhIyy4oNaH7n9Gl5Czd02suzOlt8JEjo90yKy07OxsA4ODgUNlTVBtMiIiIiAwjp6AYt0qt/RZ3PwfpOYXY9H8hBv8so90yK602JEJERERkWPZSSwTVkyOontzUoWjonRClp6djzpw5OHToENLS0jQ1gUpkZGQYLDgiIiKiqqB3QjRy5EjExsZizJgxcHd3r7FzhoiIiKj20DshOnbsGI4fP46WLVsaIx4iIiKiKqf3YiXNmjXDo0ePjBELERERkUnonRB9++23+Pjjj3HkyBGkp6dDoVBobURERETVjd63zORyORQKBf71r39p7RcEASKRCEpl+WugEBEREZkjvROiESNGwMrKChs2bOCkaiIiIqoR9E6ILl++jHPnzsHPz88Y8RARERFVOb3nELVr1w6JiYnGiIWIiIjIJPQeIXr//ffxwQcfYPr06QgMDISVlfaaI0FBQQYLjoiIiKgq6L2WmVhcdlBJJBLV+EnVXMuMiIio+jHaWmbx8fHPFRgRERGRudE7IfLx8TFGHEREREQmo/ekaiIiIqKahgkRERER1XpMiIiIiKjWY0JEREREtZ7eCdGoUaNw9OhRY8RCREREZBJ6J0RZWVkIDQ1FkyZNsHDhQty7d88YcRERERFVGb0Tom3btuHevXsYP348/ve//6FBgwbo27cv/vjjDxQVFRkjRiIiIiKjqtQcIldXV4SHh+PChQuIiopC48aNMXLkSHh5eWHKlCmIiYkxdJxERERERvNck6qTk5MRERGBiIgIWFhYoF+/frh06RICAgKwfPlyQ8VIREREZFR6J0RFRUXYvHkzBgwYAB8fH/z++++YPHkykpKSsH79euzfvx+bNm3C/PnzjREvERERkcHpvXSHp6cnVCoVhg8fjtOnT6NVq1Zl2vTo0QNyudwA4REREREZn94J0fLly/HKK6/A2tq63DZyuZyLwBIREVG1oXdCNHLkSGPEQURERGQyeidEAPD3339j06ZNSEhIQGFhodaxLVu2GCQwIiIioqqi96TqjRs3olOnTrh27Rq2bt2KoqIiXLlyBQcPHoRMJjNGjERERERGpXdCtHDhQixfvhx//vknJBIJvv76a1y/fh2vvvoq6tevb4wYiYiIiIxK74QoLi4O/fv3BwBIJBLk5uZCJBJhypQpWLt2rcEDJCIiIjI2vRMiJycnZGdnAwDq1q2Ly5cvAwAyMzORl5dn2OiIiIiIqoDek6q7deuGiIgIBAYG4pVXXsEHH3yAgwcPIiIiAj179jRGjERERERGpXdC9M033yA/Px8A8PHHH8PKygonT57E0KFD8cknnxg8QCIiIiJjEwmCIJg6iOpAoVBAJpMhKysLjo6Opg6HiIiIKqCi3996zyHavXs39u7dW2b/vn378Ndff+l7OiIiIiKT0zshmjlzJpRKZZn9KpUKM2fONEhQRERERFVJ74QoJiYGAQEBZfY3a9YMsbGxBgmKiIiIqCrpnRDJZDLcunWrzP7Y2FjY2dkZJCgiIiKiqqR3QjRo0CBMnjwZcXFxmn2xsbGYOnUqXnzxRYMGR0RERFQV9E6Ili5dCjs7OzRr1gy+vr7w9fWFv78/6tSpgy+//NIYMRIREREZVaVumZ08eRK7du3Ce++9h6lTp+LAgQM4ePAg5HK5wQNs0KABRCJRmW3ChAkAgPz8fEyYMAF16tSBvb09hg4ditTUVK1zJCQkoH///rC1tYWbmxumT5+O4uJig8dKRERE1ZPehRkBQCQSoXfv3ujWrRukUilEIpGh49I4c+aM1lNtly9fRq9evfDKK68AAKZMmYJdu3bh999/h0wmw8SJE/HSSy/hxIkTAAClUon+/fvDw8MDJ0+eRHJyMt58801YWVlh4cKFRoubiIiIqg+9CzOqVCp8/vnnWLNmDVJTU3Hz5k00bNgQs2fPRoMGDTBmzBhjxQoAmDx5Mnbu3ImYmBgoFAq4urpiw4YNePnllwEA169fh7+/PyIjI9GxY0f89ddfGDBgAJKSkuDu7g4AWLNmDWbMmIH79+9DIpFU6HNZmJGIiKj6MVphxs8++wzr1q3D0qVLtZKJFi1a4D//+U/loq2gwsJC/PLLL3j77bchEokQHR2NoqIihIaGato0a9YM9evXR2RkJAAgMjISgYGBmmQIAMLCwqBQKHDlypVyP6ugoAAKhUJrIyIioppJ74Top59+wtq1azFixAhYWFho9rds2RLXr183aHBP2rZtGzIzMzF69GgAQEpKCiQSSZm5S+7u7khJSdG0KZ0MlRwvOVaeRYsWQSaTaTZvb2/DdYSIiIjMit4J0b1799C4ceMy+1UqFYqKigwSVHl++OEH9O3bF15eXkb9HACYNWsWsrKyNFtiYqLRP5OIiIhMQ++EKCAgAMeOHSuz/48//kDr1q0NEpQud+7cwf79+zF27FjNPg8PDxQWFiIzM1OrbWpqKjw8PDRtnnzqrOR1SRtdpFIpHB0dtTYiIiKqmfR+ymzOnDkYNWoU7t27B5VKhS1btuDGjRv46aefsHPnTmPECAD48ccf4ebmhv79+2v2tW3bFlZWVjhw4ACGDh0KALhx4wYSEhIQEhICAAgJCcHnn3+OtLQ0uLm5AQAiIiLg6OiocwkSIiIiqn30fsoMAI4dO4b58+fjwoULyMnJQZs2bTBnzhz07t3bGDFCpVLB19cXw4cPx+LFi7WOjR8/Hrt378a6devg6OiI999/HwBw8uRJAOrH7lu1agUvLy8sXboUKSkpGDlyJMaOHavXY/d8yoyIiKj6qej3d6XqEHXt2hURERGVDk5f+/fvR0JCAt5+++0yx5YvXw6xWIyhQ4eioKAAYWFh+PbbbzXHLSwssHPnTowfPx4hISGws7PDqFGjMH/+/CqLn4iIiMxbpUaIaiOOEBEREVU/Bh0hcnJyqnA16oyMjIpFSERERGQmKpQQrVixQvNzeno6PvvsM4SFhWkmLkdGRmLv3r2YPXu2UYIkIiIiMia9b5kNHToUPXr0wMSJE7X2f/PNN9i/fz+2bdtmyPjMBm+ZERERVT9GW7pj79696NOnT5n9ffr0wf79+/U9HREREZHJ6Z0Q1alTB9u3by+zf/v27ahTp45BgiIiIiKqSno/dv/pp59i7NixOHz4MIKDgwEAUVFR2LNnD77//nuDB0hERERkbHonRKNHj4a/vz9WrlyJLVu2AAD8/f1x/PhxTYJEREREVJ2wDlEFcVI1ERFR9WO0SdVERERENQ0TIiIiIqr1mBARERFRrceEiIiIiGo9JkRERERU6xk0IXr77bfx888/G/KUREREREZn0ITo1q1bmD17Nlq1amXI0xIREREZld6FGZ/m8OHDAICrV68a8rRERERERmWUOUQBAQHGOC0RERGRUeidEK1fvx67du3SvP7www8hl8vRqVMn3Llzx6DBEREREVUFvROihQsXwsbGBgAQGRmJVatWYenSpXBxccGUKVMMHiARERGRsek9hygxMRGNGzcGAGzbtg1Dhw7FuHHj0LlzZ7zwwguGjo+IiIjI6PQeIbK3t0d6ejoAYN++fejVqxcAwNraGo8ePTJsdERERERVQO8Rol69emHs2LFo3bo1bt68iX79+gEArly5ggYNGhg6PiIiIiKj03uEaNWqVQgJCcH9+/exefNm1KlTBwAQHR2N4cOHGzxAIiIiImMTCYIgmDqI6kChUEAmkyErKwuOjo6mDoeIiIgqoKLf33qPEO3ZswfHjx/XvF61ahVatWqF119/HQ8fPqxctEREREQmpHdCNH36dCgUCgDApUuXMHXqVPTr1w/x8fEIDw83eIBERERExqb3pOr4+HhNJerNmzdjwIABWLhwIc6ePauZYE1ERERUneg9QiSRSJCXlwcA2L9/P3r37g0AcHZ21owcEREREVUneo8QdenSBeHh4ejcuTNOnz6N//3vfwCAmzdvol69egYPkIiIiMjY9B4h+uabb2BpaYk//vgDq1evRt26dQEAf/31F/r06WPwAImIiIiMjY/dVxAfuyciIqp+Kvr9rfctMwBQKpXYtm0brl27BgBo3rw5XnzxRVhYWFQuWiIiIiIT0jshio2NRb9+/XDv3j34+fkBABYtWgRvb2/s2rULjRo1MniQRERERMak9xyiSZMmoVGjRkhMTMTZs2dx9uxZJCQkwNfXF5MmTTJGjERERERGpfcI0ZEjR3Dq1Ck4Oztr9tWpUweLFy9G586dDRocERERUVXQe4RIKpUiOzu7zP6cnBxIJBKDBEVERERUlfROiAYMGIBx48YhKioKgiBAEAScOnUK//d//4cXX3zRGDESERERGZXeCdHKlSvRqFEjhISEwNraGtbW1ujcuTMaN26Mr7/+2hgxEhERERmV3nOI5HI5tm/fjpiYGFy/fh0A4O/vj8aNGxs8OCIiIqKqUKk6RADQpEkTNGnSxJCxEBEREZlEhRKi8PDwCp9w2bJllQ6GiIiIyBQqlBCdO3euQicTiUTPFQwRERGRKVQoITp06JCx4yAiIiIyGb2fMiMiIiKqacw+Ibp37x7eeOMN1KlTBzY2NggMDMTff/+tOS4IAubMmQNPT0/Y2NggNDQUMTExWufIyMjAiBEj4OjoCLlcjjFjxiAnJ6equ0JERERmyqwToocPH6Jz586wsrLCX3/9hatXr+Krr76Ck5OTps3SpUuxcuVKrFmzBlFRUbCzs0NYWBjy8/M1bUaMGIErV64gIiICO3fuxNGjRzFu3DhTdImIiIjMkEgQBMHUQZRn5syZOHHiBI4dO6bzuCAI8PLywtSpUzFt2jQAQFZWFtzd3bFu3ToMGzYM165dQ0BAAM6cOYN27doBAPbs2YN+/frh7t278PLyqlAsCoUCMpkMWVlZcHR0NEwHAeC34YCFFSDzBuT1H//qrf7VRm64zyEiIqqFKvr9Xek6RFVhx44dCAsLwyuvvIIjR46gbt26eO+99/DOO+8AAOLj45GSkoLQ0FDNe2QyGYKDgxEZGYlhw4YhMjIScrlckwwBQGhoKMRiMaKiojBkyBCdn11QUICCggLNa4VCYfgOKouBm3sBQan7uNSxVIJUr9TP9dW/2rkBYrMe5CMiIqoWzDohunXrFlavXo3w8HB89NFHOHPmDCZNmgSJRIJRo0YhJSUFAODu7q71Pnd3d82xlJQUuLm5aR23tLSEs7Ozpo0uixYtwqeffmrgHj1JAF79CchKBDITgayEx78mAnnpQIECSLui3nSxkDyRKHlr/+xYF7DkgrtERETPYtYJkUqlQrt27bBw4UIAQOvWrXH58mWsWbMGo0aNMupnz5o1S6sgpUKhgLe3t2E/xMIK8B+g+1hhHpB1VztJKv1rdhKgLAQybqk3nUSAg+c/CZJmpKn+P/uk9obtExERUTVk1gmRp6cnAgICtPb5+/tj8+bNAAAPDw8AQGpqKjw9PTVtUlNT0apVK02btLQ0rXMUFxcjIyND835dpFIppFKpIbpRORJbwLWpetNFWQQokh4nTTpGmLLuAsX56sQpOwlIjNJ9Hhsn3fOXZPXU+2zrACy4SURENZxZJ0SdO3fGjRs3tPbdvHkTPj4+AABfX194eHjgwIEDmgRIoVAgKioK48ePBwCEhIQgMzMT0dHRaNu2LQDg4MGDUKlUCA4OrrrOGJqFFeDko950EQQg9/4/iVLW3SdGmhKA/Czg0UP1lnJR93msbMvelitJnmT1AEcvQGxhvH4SERFVAbNOiKZMmYJOnTph4cKFePXVV3H69GmsXbsWa9euBaBeKmTy5Mn47LPP0KRJE/j6+mL27Nnw8vLC4MGDAahHlPr06YN33nkHa9asQVFRESZOnIhhw4ZV+AmzakkkAuzd1Fu9trrb5CueuBWXoD3ilJMCFOUBD26qN52fY6GeqyR/Yv5SyeRvWT3Aytp4/SQiIjIAs37sHgB27tyJWbNmISYmBr6+vggPD9c8ZQaoH72fO3cu1q5di8zMTHTp0gXffvstmjb951ZTRkYGJk6ciD///BNisRhDhw7FypUrYW9f8fkzRnvs3pwVFzxxS67Ur1mJQNY9QFX07PPYueoeYWJ5ASIiMrKKfn+bfUJkLmplQvQsKiWQk/rECNMTyVNR7rPPU1JeQFav7AgTywsQEdFzqBF1iMjMiS3Uc4gcvQDomI8lCOr5SWVGmCpbXuCJJ+RYXoCIiAyECREZj0gE2DqrN8+WutsU5pZ/W66y5QU0I00sL0BERBXDhIhMS2IHuPqpN1005QUSSz0pZ4DyAlq351hegIiotmNCROZN3/ICmYllazM9V3mBx/scPAEL/nUhIqqp+C88VW+VLi9QasTpucsLPB5xsrIxXj+JiMiomBBRzWftCFg3B9yb6z5e0fICWQnqrTxPLS9QD7CW87YcEZGZYkJEZCkF6jRSb7pUtLxA7n31lnRW93kkDuUXsGR5ASIik2JCRPQshiovUJgNpF1Vb7pYSErdlmN5ASKiqsSEiOh5GbK8wMN49ab7g9STu8srYMnyAkRElcaEiKgqGLq8wN3Tus+jVV5Ax1NzLC9ARKQTEyIic2Cy8gJPVP9meQEiqqX4Lx9RdWDS8gL1tEedWF6AiGogJkRENcXzlBfITAAU9wBVceXLC5TMbWJ5ASKqhpgQEdUW5lBeQFYPsHdneQEiMjtMiIhIjeUFiKgWY0JERBWjT3mB0pW+K1VewKP8ApYsL0BERsCEiIgMR5/yArqSJk15gWT1Vl55AWt5+SNMLC9ARJXAhIiIqk6lygs8UZspPwvIzwRSMoGUS7rPY2nzxBNy3iwvQERPxX8RiMh8PE95gZLaTDkpQPEjPcoLlEqa5PX/mfxtZW28fhKR2WFCRETVS5WVF3Arfw6T3Buwlhmnf0RkEkyIiKhmMVh5gTT1di9a93msZeXMYXqcPNm5cB4TUTXChIiIapeKlhfITNCRLD1+/ejh47lMl4DUp8xjKilWWVK8UvPr43lMYgujdpWIKo4JERFRaaXLC3i10t2mILvsIrylk6eSeUzpMepNF7GlOinTGmUq9bOsnnq0i4iqBBMiIiJ9SR0AN3/1pktF5zGVjELdKedz7D10lxUoeS11MFoXiWobJkRERIZWkXlM2clPn8dU/Eg90pSTAtw9o/s8Nk5lk6TS85hsnTmPiaiCmBAREVU1scXjx/3rAQgpe1wQ1Mug6JzHVKoe06OH6i3lou7PsbJ7+jwmew+uK0f0GBMiIiJzIxKpn1KzcwHqttHdptx6TI/nNOWmqZ+We3BDvekitgJkdZ9IlErNY+K6clSLMCEiIqqOnlWPqSj/8TymBB3zmBIfz2MqAh7eVm86idRPwz1tHpPEzkgdJKpaTIiIiGoiK2vApbF600VZ/HgeU4L2rbgy68olqbfEKN3nsa1TfvFKmbd6nhPnMVE1wISIiKg2srB8PLfIW/dxXevKPTmfqUChnuuUlw4kn9d9Hol92VtxpZMnOzfOYyKzwISIiIjKqsi6co8yn7KuXKI6oSrMAe5fU2+6WEh0LMJbeh6Tl3pRYCIjY0JERESVYyNXbx6Buo8X5j19HlN2EqAsBDJuqTddRGLAwUv3Eilyn8cL8doYq4dUizAhIiIi45DYAq5N1ZsuyiJAkaT9dNyT85iUhYDirnpDpO7z2LmWP+lb5q1O2oiegQkRERGZhoUV4OSj3nRRqdTlA55MlDJL/VyYo741l3sfSDqr+zxSx/KLV8q91QkVJ37XekyIiIjIPInFgIOHevNuX/Z4yUK8ugpXlrzOS1dP/k69rN50sbTWnsckr6/9xJyDp3oSOtVovMJERFQ9lV6I17Ol7jaFuU9fIiU7WV1eID1Wven8HAt1kUpd85hk9R/PY7I2Xj+pSjAhIiKimktiB7g1U2+6FBeqi1Q+eSuuJHnKelzAMitBvZXH3v3p85isHY3TPzIYJkRERFR7WUoAZ1/1potKCeSkPmWUKQEoylO3yUkF7v2t+zzW8vKLV8rrqwtcch6TSTEhIiIiKo/YQl0LydELQHDZ44IA5GWUU1rgcfL06CGQnwmkZAIpl3R/jpXtM+YxeahjIaNhQkRERFRZIhFgV0e9ebXW3aYgW11CIDNB9zymnBT1KNODm+pNF7Hl43lMOp6Wk9cHHOtxId7nxISIiIjImKQOgJu/etOluOBxActEHaUFEtS1mlTFQOYd9aaTSD2KVF5pAZk3ILU3WhdrAiZEREREpmQpBeo0Um+6qJSPF+J9ytNyxY/UbbKTgbundZ/HxqnUCNOTI031a/1CvEyIiIiIzJnY4vH8onoAQsoeFwQg90H5S6RkJQD5Weq5TI8eAskXdH+OlZ12gvTkE3P27jV6IV4mRERERNWZSATYu6q3uuUsxJuv+CdBykwomzzlpgFFucD96+pNFwtJqXpM9csmT451q/VCvEyIiIiIajprR8C6OeDeXPfxonzdC/GW3J5TPF6I92G8etNFJFZX9X7aPCaJrfH6+JzMPiGaN28ePv30U619fn5+uH5dncHm5+dj6tSp2LhxIwoKChAWFoZvv/0W7u7umvYJCQkYP348Dh06BHt7e4waNQqLFi2CpaXZd5+IiMj4rKwBl8bqTRdlMZCdVP4SKZmJgLJAXeRScQ9IPKX7PLYu5RevlHur6zWZaB5TtcgImjdvjv3792tel05kpkyZgl27duH333+HTCbDxIkT8dJLL+HEiRMAAKVSif79+8PDwwMnT55EcnIy3nzzTVhZWWHhwoVV3hciIqJqx8Ly8a2x+rqPq1TqBXbLm/SdlaheUy7vgXpLOqf7PNPjADsX4/XjKapFQmRpaQkPD48y+7OysvDDDz9gw4YN+Ne//gUA+PHHH+Hv749Tp06hY8eO2LdvH65evYr9+/fD3d0drVq1woIFCzBjxgzMmzcPEgnrNhARET0XsRhwcFdv9drpbvMoU0dpgVLJU1GeumK3iVSLhCgmJgZeXl6wtrZGSEgIFi1ahPr16yM6OhpFRUUIDQ3VtG3WrBnq16+PyMhIdOzYEZGRkQgMDNS6hRYWFobx48fjypUraN1adyGtgoICFBQUaF4rFArjdZCIiKims5GrN49A3ceL8k362L/ZPz8XHByMdevWYc+ePVi9ejXi4+PRtWtXZGdnIyUlBRKJBHK5XOs97u7uSElJAQCkpKRoJUMlx0uOlWfRokWQyWSazdvb27AdIyIion9YWZv0481+hKhv376an4OCghAcHAwfHx9s2rQJNjY2RvvcWbNmITw8XPNaoVAwKSIiIqqhzH6E6ElyuRxNmzZFbGwsPDw8UFhYiMzMTK02qampmjlHHh4eSE1NLXO85Fh5pFIpHB0dtTYiIiKqmapdQpSTk4O4uDh4enqibdu2sLKywoEDBzTHb9y4gYSEBISEqKt5hoSE4NKlS0hLS9O0iYiIgKOjIwICAqo8fiIiIjI/Zn/LbNq0aRg4cCB8fHyQlJSEuXPnwsLCAsOHD4dMJsOYMWMQHh4OZ2dnODo64v3330dISAg6duwIAOjduzcCAgIwcuRILF26FCkpKfjkk08wYcIESKVSE/eOiIiIzIHZJ0R3797F8OHDkZ6eDldXV3Tp0gWnTp2Cq6srAGD58uUQi8UYOnSoVmHGEhYWFti5cyfGjx+PkJAQ2NnZYdSoUZg/f76pukRERERmRiQIgmDqIKoDhUIBmUyGrKwsziciIiKqJir6/V3t5hARERERGRoTIiIiIqr1mBARERFRrceEiIiIiGo9JkRERERU6zEhIiIiolqPCRERERHVemZfmNFclJRrUigUJo6EiIiIKqrke/tZZReZEFVQdnY2AHDFeyIiomooOzsbMpms3OOsVF1BKpUKSUlJcHBwgEgkMth5FQoFvL29kZiYWCMrYNf0/gE1v481vX9Aze8j+1f91fQ+GrN/giAgOzsbXl5eEIvLnynEEaIKEovFqFevntHO7+joWCP/kJeo6f0Dan4fa3r/gJrfR/av+qvpfTRW/542MlSCk6qJiIio1mNCRERERLUeEyITk0qlmDt3LqRSqalDMYqa3j+g5vexpvcPqPl9ZP+qv5reR3PoHydVExERUa3HESIiIiKq9ZgQERERUa3HhIiIiIhqPSZEREREVOsxITKCVatWoUGDBrC2tkZwcDBOnz791Pa///47mjVrBmtrawQGBmL37t1axwVBwJw5c+Dp6QkbGxuEhoYiJibGmF14Kn369/3336Nr165wcnKCk5MTQkNDy7QfPXo0RCKR1tanTx9jd6Nc+vRv3bp1ZWK3trbWamNu1w/Qr48vvPBCmT6KRCL0799f08acruHRo0cxcOBAeHl5QSQSYdu2bc98z+HDh9GmTRtIpVI0btwY69atK9NG37/XxqJv/7Zs2YJevXrB1dUVjo6OCAkJwd69e7XazJs3r8z1a9asmRF7UT59+3f48GGdfz5TUlK02pnL9QP076Ouv18ikQjNmzfXtDGna7ho0SK0b98eDg4OcHNzw+DBg3Hjxo1nvs/U34VMiAzsf//7H8LDwzF37lycPXsWLVu2RFhYGNLS0nS2P3nyJIYPH44xY8bg3LlzGDx4MAYPHozLly9r2ixduhQrV67EmjVrEBUVBTs7O4SFhSE/P7+quqWhb/8OHz6M4cOH49ChQ4iMjIS3tzd69+6Ne/fuabXr06cPkpOTNdtvv/1WFd0pQ9/+AerKqqVjv3PnjtZxc7p+gP593LJli1b/Ll++DAsLC7zyyita7czlGubm5qJly5ZYtWpVhdrHx8ejf//+6NGjB86fP4/Jkydj7NixWklDZf5cGIu+/Tt69Ch69eqF3bt3Izo6Gj169MDAgQNx7tw5rXbNmzfXun7Hjx83RvjPpG//Sty4cUMrfjc3N80xc7p+gP59/Prrr7X6lpiYCGdn5zJ/B83lGh45cgQTJkzAqVOnEBERgaKiIvTu3Ru5ubnlvscsvgsFMqgOHToIEyZM0LxWKpWCl5eXsGjRIp3tX331VaF///5a+4KDg4V3331XEARBUKlUgoeHh/DFF19ojmdmZgpSqVT47bffjNCDp9O3f08qLi4WHBwchPXr12v2jRo1Shg0aJChQ60Uffv3448/CjKZrNzzmdv1E4Tnv4bLly8XHBwchJycHM0+c7qGpQEQtm7d+tQ2H374odC8eXOtfa+99poQFhamef28v2fGUpH+6RIQECB8+umnmtdz584VWrZsabjADKQi/Tt06JAAQHj48GG5bcz1+glC5a7h1q1bBZFIJNy+fVuzz1yvoSAIQlpamgBAOHLkSLltzOG7kCNEBlRYWIjo6GiEhoZq9onFYoSGhiIyMlLneyIjI7XaA0BYWJimfXx8PFJSUrTayGQyBAcHl3tOY6lM/56Ul5eHoqIiODs7a+0/fPgw3Nzc4Ofnh/HjxyM9Pd2gsVdEZfuXk5MDHx8feHt7Y9CgQbhy5YrmmDldP8Aw1/CHH37AsGHDYGdnp7XfHK5hZTzr76Ahfs/MiUqlQnZ2dpm/gzExMfDy8kLDhg0xYsQIJCQkmCjCymnVqhU8PT3Rq1cvnDhxQrO/pl0/QP13MDQ0FD4+Plr7zfUaZmVlAUCZP3OlmcN3IRMiA3rw4AGUSiXc3d219ru7u5e5n10iJSXlqe1LftXnnMZSmf49acaMGfDy8tL6Q92nTx/89NNPOHDgAJYsWYIjR46gb9++UCqVBo3/WSrTPz8/P/z3v//F9u3b8csvv0ClUqFTp064e/cuAPO6fsDzX8PTp0/j8uXLGDt2rNZ+c7mGlVHe30GFQoFHjx4Z5M+9Ofnyyy+Rk5ODV199VbMvODgY69atw549e7B69WrEx8eja9euyM7ONmGkFePp6Yk1a9Zg8+bN2Lx5M7y9vfHCCy/g7NmzAAzz75Y5SUpKwl9//VXm76C5XkOVSoXJkyejc+fOaNGiRbntzOG7kKvdU5VZvHgxNm7ciMOHD2tNPB42bJjm58DAQAQFBaFRo0Y4fPgwevbsaYpQKywkJAQhISGa1506dYK/vz++++47LFiwwISRGccPP/yAwMBAdOjQQWt/db6GtcmGDRvw6aefYvv27VpzbPr27av5OSgoCMHBwfDx8cGmTZswZswYU4RaYX5+fvDz89O87tSpE+Li4rB8+XL8/PPPJozMONavXw+5XI7Bgwdr7TfXazhhwgRcvnzZZPOZ9MERIgNycXGBhYUFUlNTtfanpqbCw8ND53s8PDye2r7kV33OaSyV6V+JL7/8EosXL8a+ffsQFBT01LYNGzaEi4sLYmNjnztmfTxP/0pYWVmhdevWmtjN6foBz9fH3NxcbNy4sUL/uJrqGlZGeX8HHR0dYWNjY5A/F+Zg48aNGDt2LDZt2lTm1sST5HI5mjZtWi2uny4dOnTQxF5Trh+gfsrqv//9L0aOHAmJRPLUtuZwDSdOnIidO3fi0KFDqFev3lPbmsN3IRMiA5JIJGjbti0OHDig2adSqXDgwAGtUYTSQkJCtNoDQEREhKa9r68vPDw8tNooFApERUWVe05jqUz/APWTAQsWLMCePXvQrl27Z37O3bt3kZ6eDk9PT4PEXVGV7V9pSqUSly5d0sRuTtcPeL4+/v777ygoKMAbb7zxzM8x1TWsjGf9HTTEnwtT++233/DWW2/ht99+0yqXUJ6cnBzExcVVi+uny/nz5zWx14TrV+LIkSOIjY2t0H9KTHkNBUHAxIkTsXXrVhw8eBC+vr7PfI9ZfBcaZGo2aWzcuFGQSqXCunXrhKtXrwrjxo0T5HK5kJKSIgiCIIwcOVKYOXOmpv2JEycES0tL4csvvxSuXbsmzJ07V7CyshIuXbqkabN48WJBLpcL27dvFy5evCgMGjRI8PX1FR49emT2/Vu8eLEgkUiEP/74Q0hOTtZs2dnZgiAIQnZ2tjBt2jQhMjJSiI+PF/bv3y+0adNGaNKkiZCfn2/2/fv000+FvXv3CnFxcUJ0dLQwbNgwwdraWrhy5YqmjTldP0HQv48lunTpIrz22mtl9pvbNczOzhbOnTsnnDt3TgAgLFu2TDh37pxw584dQRAEYebMmcLIkSM17W/duiXY2toK06dPF65duyasWrVKsLCwEPbs2aNp86zfM3Pu36+//ipYWloKq1at0vo7mJmZqWkzdepU4fDhw0J8fLxw4sQJITQ0VHBxcRHS0tLMvn/Lly8Xtm3bJsTExAiXLl0SPvjgA0EsFgv79+/XtDGn6ycI+vexxBtvvCEEBwfrPKc5XcPx48cLMplMOHz4sNafuby8PE0bc/wuZEJkBP/+97+F+vXrCxKJROjQoYNw6tQpzbHu3bsLo0aN0mq/adMmoWnTpoJEIhGaN28u7Nq1S+u4SqUSZs+eLbi7uwtSqVTo2bOncOPGjaroik769M/Hx0cAUGabO3euIAiCkJeXJ/Tu3VtwdXUVrKysBB8fH+Gdd94x2T9UgqBf/yZPnqxp6+7uLvTr1084e/as1vnM7foJgv5/Rq9fvy4AEPbt21fmXOZ2DUsew35yK+nTqFGjhO7du5d5T6tWrQSJRCI0bNhQ+PHHH8uc92m/Z1VJ3/517979qe0FQV1mwNPTU5BIJELdunWF1157TYiNja3ajj2mb/+WLFkiNGrUSLC2thacnZ2FF154QTh48GCZ85rL9ROEyv0ZzczMFGxsbIS1a9fqPKc5XUNdfQOg9ffKHL8LRY+DJyIiIqq1OIeIiIiIaj0mRERERFTrMSEiIiKiWo8JEREREdV6TIiIiIio1mNCRERERLUeEyIiIiKq9ZgQERERUa3HhIiIqBIOHz4MkUiEzMxMU4dCRAbAhIiIiIhqPSZEREREVOsxISKiakmlUmHRokXw9fWFjY0NWrZsiT/++APAP7ezdu3ahaCgIFhbW6Njx464fPmy1jk2b96M5s2bQyqVokGDBvjqq6+0jhcUFGDGjBnw9vaGVCpF48aN8cMPP2i1iY6ORrt27WBra4tOnTrhxo0bxu04ERkFEyIiqpYWLVqEn376CWvWrMGVK1cwZcoUvPHGGzhy5IimzfTp0/HVV1/hzJkzcHV1xcCBA1FUVARAnci8+uqrGDZsGC5duoR58+Zh9uzZWLduneb9b775Jn777TesXLkS165dw3fffQd7e3utOD7++GN89dVX+Pvvv2FpaYm33367SvpPRIbF1e6JqNopKCiAs7Mz9u/fj5CQEM3+sWPHIi8vD+PGjUOPHj2wceNGvPbaawCAjIwM1KtXD+vWrcOrr76KESNG4P79+9i3b5/m/R9++CF27dqFK1eu4ObNm/Dz80NERARCQ0PLxHD48GH06NED+/fvR8+ePQEAu3fvRv/+/fHo0SNYW1sb+XeBiAyJI0REVO3ExsYiLy8PvXr1gr29vWb76aefEBcXp2lXOllydnaGn58frl27BgC4du0aOnfurHXezp07IyYmBkqlEufPn4eFhQW6d+/+1FiCgoI0P3t6egIA0tLSnruPRFS1LE0dABGRvnJycgAAu3btQt26dbWOSaVSraSosmxsbCrUzsrKSvOzSCQCoJ7fRETVC0eIiKjaCQgIgFQqRUJCAho3bqy1eXt7a9qdOnVK8/PDhw9x8+ZN+Pv7AwD8/f1x4sQJrfOeOHECTZs2hYWFBQIDA6FSqbTmJBFRzcURIiKqdhwcHDBt2jRMmTIFKpUKXbp0QVZWFk6cOAFHR0f4+PgAAObPn486derA3d0dH3/8MVxcXDB48GAAwNSpU9G+fXssWLAAr732GiIjI/HNN9/g22+/BQA0aNAAo0aNwttvv42VK1eiZcuWuHPnDtLS0vDqq6+aqutEZCRMiIioWlqwYAFcXV2xaNEi3Lp1C3K5HG3atMFHH32kuWW1ePFifPDBB4iJiUGrVq3w559/QiKRAADatGmDTZs2Yc6cOViwYAE8PT0xf/58jB49WvMZq1evxkcffYT33nsP6enpqF+/Pj766CNTdJeIjIxPmRFRjVPyBNjDhw8hl8tNHQ4RVQOcQ0RERES1HhMiIiIiqvV4y4yIiIhqPY4QERERUa3HhIiIiIhqPSZEREREVOsxISIiIqJajwkRERER1XpMiIiIiKjWY0JEREREtR4TIiIiIqr1/h9FtscqN957bwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses_train, label=\"train\")\n",
    "plt.plot(losses_val, label=\"validation\")\n",
    "#plt.ylim(losses_val[-1]*0.5, losses_val[-1]*1.5)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss, decay mode classification\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4083a464-b07f-4a14-8fc4-503c5d2dfaa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

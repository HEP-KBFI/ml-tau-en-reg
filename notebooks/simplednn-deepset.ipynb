{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf2e03a-2a98-4267-a4a4-707c76abe414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import torch\n",
    "import numpy as np\n",
    "import vector\n",
    "import tqdm\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80efbc5d-a691-4272-8e1c-1d59586d2284",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "cls_loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "reg_loss = nn.L1Loss(reduction=\"none\")\n",
    "dm_loss = nn.CrossEntropyLoss(reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc2025e-ae5f-479a-96db-ac4563109346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def med_iqr(arr):\n",
    "    if len(arr) > 0:\n",
    "        p25 = np.percentile(arr, 25)\n",
    "        p50 = np.percentile(arr, 50)\n",
    "        p75 = np.percentile(arr, 75)\n",
    "    else:\n",
    "        p25 = 0.0\n",
    "        p50 = 0.0\n",
    "        p75 = 0.0\n",
    "    return p50, p75 - p25\n",
    "\n",
    "def to_p4(p4_obj):\n",
    "    if \"tau\" in p4_obj.fields:\n",
    "        return vector.awk(\n",
    "            ak.zip(\n",
    "                {\n",
    "                    \"mass\": p4_obj.tau,\n",
    "                    \"px\": p4_obj.x,\n",
    "                    \"py\": p4_obj.y,\n",
    "                    \"pz\": p4_obj.z,\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    elif \"t\" in p4_obj.fields:\n",
    "        return vector.awk(\n",
    "            ak.zip(\n",
    "                {\n",
    "                    \"energy\": p4_obj.t,\n",
    "                    \"px\": p4_obj.x,\n",
    "                    \"py\": p4_obj.y,\n",
    "                    \"pz\": p4_obj.z,\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        raise Exception(\"Unknown fields: {}\".format(p4_obj.fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf21d0e-7195-47fb-90a3-d57abc0abbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ak.from_parquet(\"../data/zh.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224302fa-c097-4cc4-bf29-3717f3e94c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stores the observables and targets for either one jet, or a batch of jets\n",
    "class Jet:\n",
    "    def __init__(\n",
    "        self,\n",
    "        pfs: torch.Tensor,\n",
    "        pfs_mask: torch.Tensor,\n",
    "        reco_jet_pt: torch.Tensor,\n",
    "        gen_tau_label: torch.Tensor,\n",
    "        gen_tau_pt: torch.Tensor\n",
    "    ):\n",
    "        self.pfs = pfs\n",
    "        self.pfs_mask = pfs_mask\n",
    "        self.reco_jet_pt = reco_jet_pt\n",
    "        self.gen_tau_label = gen_tau_label\n",
    "        self.gen_tau_pt = gen_tau_pt\n",
    "        \n",
    "class TauDataset(Dataset):\n",
    "    def __init__(self, filenames):\n",
    "        datas = []\n",
    "\n",
    "        #load all files, concatenate, shuffle\n",
    "        for fn in filenames:\n",
    "            d = ak.from_parquet(fn)\n",
    "            datas.append(d)\n",
    "        data_all = ak.concatenate(datas, axis=0)\n",
    "        sort_idx = np.random.permutation(len(data_all))\n",
    "        data_all = data_all[sort_idx]\n",
    "\n",
    "        #per-jet PF candidates\n",
    "        pf_p4s = to_p4(data_all[\"reco_cand_p4s\"])\n",
    "\n",
    "        #indices to map each PF candidate to jet \n",
    "        self.pf_lengths = ak.to_numpy(ak.num(pf_p4s))\n",
    "        self.pf_startidx = np.cumsum(self.pf_lengths)\n",
    "        self.pf_startidx -= self.pf_lengths\n",
    "\n",
    "        #per PF candidate observables\n",
    "        self.pf_pt = torch.unsqueeze(torch.tensor(ak.to_numpy(ak.flatten(pf_p4s.pt))), axis=-1).to(torch.float32)\n",
    "        self.pf_eta = torch.unsqueeze(torch.tensor(ak.to_numpy(ak.flatten(pf_p4s.eta))), axis=-1).to(torch.float32)\n",
    "        self.pf_phi = torch.unsqueeze(torch.tensor(ak.to_numpy(ak.flatten(pf_p4s.phi))), axis=-1).to(torch.float32)\n",
    "        self.pf_energy = torch.unsqueeze(torch.tensor(ak.to_numpy(ak.flatten(pf_p4s.energy))), axis=-1).to(torch.float32)\n",
    "        self.pf_pdg = torch.unsqueeze(torch.tensor(ak.to_numpy(ak.flatten(np.abs(data_all[\"reco_cand_pdg\"])))), axis=-1).to(torch.float32)\n",
    "        self.pf_charge = torch.unsqueeze(torch.tensor(ak.to_numpy(ak.flatten(data_all[\"reco_cand_charge\"]))), axis=-1).to(torch.float32)\n",
    "\n",
    "        #per-jet observables\n",
    "        reco_jet_p4s = to_p4(data_all[\"reco_jet_p4s\"])\n",
    "        self.reco_jet_pts = torch.unsqueeze(torch.tensor(ak.to_numpy(reco_jet_p4s.pt)), axis=-1).to(torch.float32)\n",
    "\n",
    "        #per-jet targets\n",
    "        gen_jet_p4s = to_p4(data_all[\"gen_jet_tau_p4s\"])\n",
    "        print(gen_jet_p4s.fields)\n",
    "        self.gen_tau_labels = torch.unsqueeze(torch.tensor(ak.to_numpy(data_all[\"gen_jet_tau_decaymode\"])), axis=-1).to(torch.float32)\n",
    "        self.gen_tau_pts = torch.unsqueeze(torch.tensor(ak.to_numpy(gen_jet_p4s.pt)), axis=-1).to(torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pf_lengths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert(isinstance(idx, int))\n",
    "\n",
    "        #get the indices of the PF candidates of the jet at 'idx'\n",
    "        pf_range = range(self.pf_startidx[idx], self.pf_startidx[idx] + self.pf_lengths[idx])\n",
    "        pf_pt = self.pf_pt[pf_range]\n",
    "        pf_eta = self.pf_eta[pf_range]\n",
    "        pf_phi = self.pf_phi[pf_range]\n",
    "        pf_energy = self.pf_energy[pf_range]\n",
    "        pf_pdg = self.pf_pdg[pf_range] #FIXME: this could be better as a one-hot encoded value, rather than a floating-point PDGID value\n",
    "        pf_charge = self.pf_charge[pf_range]\n",
    "        pfs = torch.concatenate([pf_pt, pf_eta, torch.sin(pf_phi), torch.cos(pf_phi), pf_energy, pf_pdg, pf_charge], axis=-1)\n",
    "        \n",
    "        return Jet(\n",
    "            pfs=pfs,\n",
    "            pfs_mask=torch.ones(pfs.shape[0], dtype=torch.float32),\n",
    "            reco_jet_pt=self.reco_jet_pts[idx],\n",
    "            gen_tau_label=self.gen_tau_labels[idx],\n",
    "            gen_tau_pt=self.gen_tau_pts[idx]\n",
    "        )\n",
    "        \n",
    "#given multiple jets with a variable number of PF candidates per jet, create 3d-padded arrays\n",
    "#in the shape [Njets, Npfs_max, Nfeat]\n",
    "def pad_collate(jets):\n",
    "    pfs = [jet.pfs for jet in jets]\n",
    "    pfs_mask = [jet.pfs_mask for jet in jets]\n",
    "    gen_tau_label = [jet.gen_tau_label for jet in jets]\n",
    "    gen_tau_pt = [jet.gen_tau_pt for jet in jets]\n",
    "    reco_jet_pt = [jet.reco_jet_pt for jet in jets]\n",
    "    \n",
    "    pfs = torch.nn.utils.rnn.pad_sequence(pfs, batch_first=True)\n",
    "    pfs_mask = torch.nn.utils.rnn.pad_sequence(pfs_mask, batch_first=True)\n",
    "    gen_tau_label = torch.concatenate(gen_tau_label, axis=0)\n",
    "    gen_tau_pt = torch.concatenate(gen_tau_pt, axis=0)\n",
    "    reco_jet_pt = torch.concatenate(reco_jet_pt, axis=0)\n",
    "    \n",
    "    return Jet(\n",
    "        pfs=pfs,\n",
    "        pfs_mask=pfs_mask,\n",
    "        reco_jet_pt=reco_jet_pt,\n",
    "        gen_tau_label=gen_tau_label,\n",
    "        gen_tau_pt=gen_tau_pt\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8876aaf-8ff8-47c5-bb27-6c064f1fe69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_kwargs = {\n",
    "    \"batch_size\": 2048,\n",
    "    \"collate_fn\": pad_collate,\n",
    "    \"num_workers\": 8,\n",
    "    \"prefetch_factor\": 20,\n",
    "    # \"pin_memory\": True,\n",
    "    # \"pin_memory_device\": \"cuda\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eee254-84e3-47c8-994b-70da77619a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = ak.from_parquet(\"../data/qq.parquet\")\n",
    "d1[\"gen_jet_tau_p4s\"].fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df4435-d30a-45a2-b700-2b49be8dc90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = ak.from_parquet(\"../data/z.parquet\")\n",
    "d2[\"gen_jet_tau_p4s\"].fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ad1701-8f8a-444d-963e-c8976b4aff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d3 = ak.from_parquet(\"../data/zh.parquet\")\n",
    "d3[\"gen_jet_tau_p4s\"].fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87179ebc-dfbb-4fc1-81aa-535766736dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for training the tau classifier, use tau and non-tau datasets\n",
    "ds_sig_and_bkg = TauDataset([\"../data/qq.parquet\", \"../data/z.parquet\"])\n",
    "# ds_sig_and_bkg = torch.utils.data.Subset(ds_sig_and_bkg, range(200000))\n",
    "ds_train, ds_val = torch.utils.data.random_split(ds_sig_and_bkg, [0.6, 0.4])\n",
    "\n",
    "dl_sig_and_bkg_train = torch.utils.data.DataLoader(ds_train, **loader_kwargs)\n",
    "dl_sig_and_bkg_val = torch.utils.data.DataLoader(ds_val, **loader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18afa5ca-cf47-47e5-9ef3-22969e07d53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for training tau pt regression and decay mode, only use the tau dataset\n",
    "ds_sig = TauDataset([\"../data/z.parquet\", \"../data/zh.parquet\"])\n",
    "# ds_sig = torch.utils.data.Subset(ds_sig, range(200000))\n",
    "ds_train, ds_val = torch.utils.data.random_split(ds_sig_and_bkg, [0.6, 0.4])\n",
    "\n",
    "dl_sig_train = torch.utils.data.DataLoader(ds_train, **loader_kwargs)\n",
    "dl_sig_val = torch.utils.data.DataLoader(ds_val, **loader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489ad1c9-b51c-4c7c-bfe5-bfa009362975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffn(input_dim, output_dim, width, act, dropout):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, width),\n",
    "        act(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(width, width),\n",
    "        act(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(width, width),\n",
    "        act(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(width, output_dim),\n",
    "    )\n",
    "    \n",
    "class DeepSet(nn.Module):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(DeepSet, self).__init__()\n",
    "\n",
    "        self.act = nn.ReLU\n",
    "        self.act_obj = self.act()\n",
    "        self.dropout = 0.1\n",
    "        self.width = 64\n",
    "        self.embedding_dim = 64\n",
    "\n",
    "        #number of inputs\n",
    "        self.num_pf_features = 7\n",
    "\n",
    "        self.nn_pf_embedding = ffn(self.num_pf_features, self.embedding_dim, self.width, self.act, self.dropout)\n",
    "        self.nn_pred = ffn(self.embedding_dim, num_outputs, self.width, self.act, self.dropout)\n",
    "\n",
    "    def forward(self, pfs_pad, pfs_mask):\n",
    "        pfs_mask = torch.unsqueeze(pfs_mask, axis=-1)\n",
    "        pf_encoded = self.act_obj(self.nn_pf_embedding(pfs_pad))*pfs_mask\n",
    "        num_pfs = torch.sum(pfs_mask, axis=1)\n",
    "        jet_encoded1 = self.act_obj(torch.sum(pf_encoded, axis=1)/num_pfs)\n",
    "        ret = self.nn_pred(jet_encoded1)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484ad2e6-aa61-452a-8c25-eac3b5ea239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loop(model, optimizer, ds_loader, dev, is_train=True, kind=\"binary\"):\n",
    "    loss_tot = 0.0\n",
    "    pred_vals = []\n",
    "    true_vals = []\n",
    "    for ibatch, batched_jets in enumerate(tqdm.tqdm(ds_loader, total=len(ds_loader), ncols=80)):\n",
    "        \n",
    "        pfs = batched_jets.pfs.to(dev, non_blocking=True)\n",
    "        pfs_mask = batched_jets.pfs_mask.to(dev, non_blocking=True)\n",
    "        gen_tau_label = batched_jets.gen_tau_label.to(dev, non_blocking=True)\n",
    "        true_istau = gen_tau_label!=-1\n",
    "\n",
    "        pred = model(pfs, pfs_mask)\n",
    "\n",
    "        if kind == \"binary\":\n",
    "            assert(pred.shape[1] == 2)\n",
    "            pred_vals.append(pred[:, 1].detach().cpu())\n",
    "            true_vals.append(true_istau.cpu())\n",
    "            loss = cls_loss(pred, true_istau.long()).mean()\n",
    "        elif kind == \"ptreg\":\n",
    "            #pred = log(ptgen/ptreco) -> ptgen = exp(pred)*ptreco\n",
    "            assert(pred.shape[1] == 1)\n",
    "            pred = torch.squeeze(pred, dim=-1)\n",
    "            gen_tau_pt = batched_jets.gen_tau_pt.to(dev, non_blocking=True)\n",
    "            reco_jet_pt = batched_jets.reco_jet_pt.to(dev, non_blocking=True)\n",
    "\n",
    "            target = torch.log(gen_tau_pt/reco_jet_pt)\n",
    "            \n",
    "            pred_pt = torch.exp(pred) * reco_jet_pt\n",
    "            pred_vals.append(pred_pt[gen_tau_label!=-1].detach().cpu())\n",
    "            true_vals.append(gen_tau_pt[gen_tau_label!=-1].cpu())\n",
    "            loss = reg_loss(pred[true_istau], target[true_istau])\n",
    "            loss = torch.sum(loss) / torch.sum(true_istau)\n",
    "        elif kind == \"dm_multiclass\":\n",
    "            assert(pred.shape[1] == 16)\n",
    "            pred_vals.append(torch.argmax(pred[true_istau], axis=-1).detach().cpu())\n",
    "            true_vals.append(gen_tau_label[true_istau].cpu())\n",
    "            target_onehot = torch.nn.functional.one_hot(gen_tau_label[true_istau].long(), 16).float()\n",
    "            loss = dm_loss(pred[true_istau], target_onehot)\n",
    "            loss = torch.sum(loss) / torch.sum(true_istau)\n",
    "        else:\n",
    "            raise Exception(\"Unknown kind={}\".format(kind))\n",
    "            \n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        loss_tot += loss.detach().cpu().item()\n",
    "    return loss_tot, pred_vals, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9b1df3-5d33-4f08-bff7-1068e8776d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train binary classification head with two outputs (tau vs. notau logits)\n",
    "model_binary_classifier = DeepSet(2).to(device)\n",
    "optimizer = torch.optim.AdamW(model_binary_classifier.parameters(), lr=1e-3)\n",
    "\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "\n",
    "for iepoch in range(20):\n",
    "    loss_train, _, _ = model_loop(model_binary_classifier, optimizer, dl_sig_and_bkg_train, device, True, kind=\"binary\")\n",
    "    loss_val, pred_val_cls, true_val_cls = model_loop(model_binary_classifier, optimizer, dl_sig_and_bkg_val, device, False, kind=\"binary\")\n",
    "    print(\"{} L={:.2f}/{:.2f}\".format(iepoch, loss_train, loss_val))\n",
    "    losses_train.append(loss_train)\n",
    "    losses_val.append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c17f2a-7a09-4a19-9d3c-008d50b294ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = sklearn.metrics.roc_curve(torch.concatenate(true_val_cls), torch.concatenate(pred_val_cls))\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title(\"epoch={} val_loss={:.2f}\".format(iepoch, loss_val))\n",
    "plt.plot(tpr, fpr)\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim(1e-6,1)\n",
    "plt.xlim(0,1)\n",
    "plt.xlabel(\"TPR\")\n",
    "plt.ylabel(\"FPR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fac614-3ab0-440c-9b78-cb9b3c5856fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses_train, label=\"train\")\n",
    "plt.plot(losses_val, label=\"validation\")\n",
    "plt.ylim(losses_val[-1]*0.5, losses_val[-1]*4)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss, tau identification\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3aafd4-b1a2-4cbb-ae1e-d27336f82d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train pt regression head, predicts one value: y=log(ptgen/ptreco)\n",
    "model_ptreg = DeepSet(1).to(device)\n",
    "optimizer = torch.optim.AdamW(model_ptreg.parameters(), lr=1e-3)\n",
    "\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "\n",
    "for iepoch in range(20):\n",
    "    loss_train, _, _ = model_loop(model_ptreg, optimizer, dl_sig_train, device, is_train=True, kind=\"ptreg\")\n",
    "    loss_val, pred_val_reg, true_val_reg = model_loop(model_ptreg, optimizer, dl_sig_val, device, is_train=False, kind=\"ptreg\")\n",
    "    print(\"{} L={:.2f}/{:.2f}\".format(iepoch, loss_train, loss_val))\n",
    "    losses_train.append(loss_train)\n",
    "    losses_val.append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13571b3c-93a5-4e16-8534-946c01a2b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses_train, label=\"train\")\n",
    "plt.plot(losses_val, label=\"validation\")\n",
    "#plt.ylim(losses_val[-1]*0.8, losses_val[-1]*1.5)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss, pt regression\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f86af3-f4fd-486a-a265-b392ae9304ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pts = torch.concatenate(true_val_reg)\n",
    "pred_pts = torch.concatenate(pred_val_reg)\n",
    "b = np.linspace(0,200,100)\n",
    "plt.hist(true_pts, bins=b, histtype=\"step\", lw=1, label=\"true\");\n",
    "plt.hist(pred_pts, bins=b, histtype=\"step\", lw=1, label=\"pred\");\n",
    "plt.xlabel(\"pT\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132329b3-d8c5-40a9-8430-a8f491678a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.linspace(0,200,100)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist2d(true_pts, pred_pts, bins=(b,b), cmap=\"Blues\");\n",
    "plt.plot([0,200], [0,200], color=\"black\", ls=\"--\", lw=0.5)\n",
    "plt.xlabel(\"true pT\")\n",
    "plt.ylabel(\"pred pT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d92fe5f-1e1f-4f9c-9e73-226f1cce6872",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.linspace(0,200,100)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist2d(true_pts, pred_pts, bins=(b,b), cmap=\"Blues\", norm=matplotlib.colors.LogNorm());\n",
    "plt.plot([0,200], [0,200], color=\"black\", ls=\"--\", lw=0.5)\n",
    "plt.xlabel(\"true pT\")\n",
    "plt.ylabel(\"pred pT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67683138-2702-4dea-9fea-678161e88bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.linspace(0,2,100)\n",
    "plt.figure(figsize=(5,5))\n",
    "ratio = pred_pts/true_pts\n",
    "plt.hist(ratio, bins=b, histtype=\"step\", lw=1);\n",
    "med, iqr = med_iqr(ratio)\n",
    "plt.title(\"M={:.2f}, IQR/M={:.2f}\".format(med, iqr/med))\n",
    "plt.axvline(1.0, color=\"black\", ls=\"--\", lw=0.5)\n",
    "plt.xlabel(\"pred/true pT\")\n",
    "plt.ylabel(\"number of jets / bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba97e08e-2642-4c9e-9516-745ea0f7e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pts[(true_pts>20) & (true_pts<30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84383ea6-f942-451f-a8b1-cf8c0c87f8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.linspace(0,10,100)\n",
    "plt.figure(figsize=(5,5))\n",
    "ratio = pred_pts/true_pts\n",
    "plt.hist(ratio, bins=b, histtype=\"step\", lw=1);\n",
    "plt.yscale(\"log\")\n",
    "med, iqr = med_iqr(ratio)\n",
    "plt.title(\"M={:.2f}, IQR/M={:.2f}\".format(med, iqr/med))\n",
    "plt.axvline(1.0, color=\"black\", ls=\"--\", lw=0.5)\n",
    "plt.xlabel(\"pred/true pT\")\n",
    "plt.ylabel(\"number of jets / bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e63b00-2f6b-4819-923d-7f53abae39bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [20,30,40,50,60,70,80,90,100,125,150,175,200]\n",
    "medvals = []\n",
    "meanvals = []\n",
    "iqrvals = []\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "for ibin in range(len(bins)-1):\n",
    "    msk = (true_pts>bins[ibin]) & (true_pts<bins[ibin+1])\n",
    "    med, iqr = med_iqr(ratio[msk])\n",
    "    meanvals.append(ratio[msk].mean())\n",
    "    ax1 = plt.subplot(3, 4, ibin+1)\n",
    "    plt.title(\"bin={},{}\".format(bins[ibin], bins[ibin+1]))\n",
    "    plt.hist(ratio[msk], bins=np.linspace(0.5,1.5,101), histtype=\"step\", lw=0.5, density=1, color=\"black\")\n",
    "    medvals.append(med)\n",
    "    iqrvals.append(iqr/med)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684d9d8f-7efc-4927-98e1-ba42351bd250",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(bins[:-1], medvals, marker=\"o\")\n",
    "plt.ylabel(\"median of pred/true pT\")\n",
    "plt.axhline(1.0, color=\"black\", ls=\"--\")\n",
    "plt.ylim(0.95,1.05)\n",
    "plt.xlabel(\"true pT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbefbf22-7b37-4fe5-986f-7a06e8bc882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(bins[:-1], iqrvals, marker=\"o\")\n",
    "plt.ylabel(\"IQR/median of pred/true pT\")\n",
    "plt.xlabel(\"true pT\")\n",
    "plt.ylim(0.0, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79515bec-4cb7-4205-b141-60b77a27e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train pt regression head, predicts one value: y=log(ptgen/ptreco)\n",
    "model_dm = DeepSet(16).to(device)\n",
    "optimizer = torch.optim.AdamW(model_dm.parameters(), lr=1e-3)\n",
    "\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "\n",
    "for iepoch in range(20):\n",
    "    loss_train, _, _ = model_loop(model_dm, optimizer, dl_sig_train, device, is_train=True, kind=\"dm_multiclass\")\n",
    "    loss_val, pred_val_dm, true_val_dm = model_loop(model_dm, optimizer, dl_sig_val, device, is_train=False, kind=\"dm_multiclass\")\n",
    "    print(\"{} L={:.2f}/{:.2f}\".format(iepoch, loss_train, loss_val))\n",
    "    losses_train.append(loss_train)\n",
    "    losses_val.append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298c93f7-a58f-4397-a307-d60cc1451913",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses_train, label=\"train\")\n",
    "plt.plot(losses_val, label=\"validation\")\n",
    "#plt.ylim(losses_val[-1]*0.5, losses_val[-1]*1.5)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss, decay mode classification\")\n",
    "plt.legend(loc=\"best\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

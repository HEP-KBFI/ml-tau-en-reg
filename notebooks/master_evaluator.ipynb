{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master notebook for evaluating  performaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import mplhep as hep\n",
    "import awkward as ak\n",
    "import matplotlib.pyplot as plt\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from enreg.tools import general as g\n",
    "from enreg.tools.metrics import (\n",
    "    regression_evaluator as re,\n",
    "    decay_mode_evaluator as dme,\n",
    "    tagger_evaluator as te\n",
    ")\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../enreg/config/\", job_name=\"test_app\"):\n",
    "    cfg = compose(config_name=\"benchmarking\")\n",
    "\n",
    "hep.style.use(hep.styles.CMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"/home/hardiveski/ml-tau-en-reg/z_temp_output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1] Loading from /scratch/persistent/laurits/ml-tau/20241002_Training_ntuples_geq20gev/zh_test.parquet\n",
      "Input data loaded\n"
     ]
    }
   ],
   "source": [
    "# Import training files\n",
    "\n",
    "# Training files base directory\n",
    "BASE_DATA_DIR = \"/scratch/persistent/laurits/ml-tau/20241002_Training_ntuples_geq20gev\"\n",
    "\n",
    "# Data directory\n",
    "SAMPLE_DIR = {\n",
    "    \"z_test\": os.path.join(BASE_DATA_DIR, \"z_test.parquet\"),\n",
    "    \"zh_test\": os.path.join(BASE_DATA_DIR, \"zh_test.parquet\"),\n",
    "    \"qq_test\": os.path.join(BASE_DATA_DIR, \"qq_test.parquet\"),\n",
    "    \"z_train\": os.path.join(BASE_DATA_DIR, \"z_train.parquet\"),\n",
    "    \"zh_train\": os.path.join(BASE_DATA_DIR, \"zh_train.parquet\"),\n",
    "    \"qq_train\": os.path.join(BASE_DATA_DIR, \"qq_train.parquet\"),\n",
    "}\n",
    "\n",
    "def train_data_loader(key):\n",
    "    \"\"\"\n",
    "    Returns ak.Array\n",
    "    \"\"\"\n",
    "    return g.load_all_data(SAMPLE_DIR[key])\n",
    "\n",
    "# z_test_data = train_data_loader(\"z_test\")\n",
    "zh_test_data = train_data_loader(\"zh_test\")\n",
    "# qq_test_data = train_data_loader(\"qq_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to /home/hardiveski/ml-tau-en-reg/z_temp_output/recoJet/z_test.parquet\n",
      "Saving to /home/hardiveski/ml-tau-en-reg/z_temp_output/recoJet/zh_test.parquet\n"
     ]
    }
   ],
   "source": [
    "def create_reco_entries(base_dir, key,  output_dir):\n",
    "    \"\"\"\n",
    "    Creates reconstruced stuffs\n",
    "    \"\"\"\n",
    "    data = ak.from_parquet(base_dir, columns=['reco_jet_p4s', \"gen_jet_tau_p4s\"])\n",
    "    data = ak.Array({k: data[k] for k in data.fields})\n",
    "    data_to_save = {\n",
    "        \"reco_jet_pt\": g.reinitialize_p4(data.reco_jet_p4s).pt,\n",
    "        \"gen_tau_pt\": g.reinitialize_p4(data.gen_jet_tau_p4s).pt\n",
    "    }\n",
    "    output_dir = os.path.join(output_dir, \"recoJet\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f\"{key}.parquet\")\n",
    "    print(f\"Saving to {output_path}\")\n",
    "    ak.to_parquet(ak.Record(data_to_save), output_path, row_group_size=1024)\n",
    "\n",
    "for idx, (key, value) in enumerate(SAMPLE_DIR.items()):\n",
    "    if idx == 2:\n",
    "        break\n",
    "    else:\n",
    "        create_reco_entries(SAMPLE_DIR[key], key, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for ParticleTransformer_v1_trainfrac_1e4_jet_regression_zh_test\n",
      "Input loc: /home/laurits/ml-tau-en-reg/training-outputs/20201204_ParT_ntrain_v2/v1/trainfrac_1e4/jet_regression/ParticleTransformer/zh_test.parquet Type: <class 'str'>\n",
      "Failed to load ParticleTransformer_v1_trainfrac_1e4_jet_regression_zh_test: Unexpected input_loc\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "BASE_MODEL_DIR = '/home/laurits/ml-tau-en-reg/training-outputs/20201204_ParT_ntrain_v2'\n",
    "\n",
    "# Model types\n",
    "version = [\"v1\", \"v2\", \"v3\"]\n",
    "train_frac = [\"trainfrac_1e4\", \"trainfrac_1e5\", \"trainfrac_1e6\", \"trainfrac_2e3\"]\n",
    "tasks = ['jet_regression', 'dm_multiclass', 'tagger', 'binary_classification']\n",
    "models = [\"ParticleTransformer\", \"LorentzNet\", \"DeepSet\", \"HPS\", \"OmniParT_from_scratch\", \"OmniParT_fine_tuning\", \"OmniParT_fixed_backbone\"]\n",
    "model_test_type = [\"z_test\", \"zh_test\"]\n",
    "\n",
    "def model_loader(base_dir, v, fraction, task, model, test_type):\n",
    "    full_directory = os.path.join(base_dir, v, fraction, task, model, test_type + '.parquet')\n",
    "    return g.load_all_data(full_directory)\n",
    "\n",
    "def load_model_data(base_dir, versions, fractions, tasks, models, test_type):\n",
    "    \"\"\"\n",
    "    Dynamically load data for specified model parameters.\n",
    "    Args:\n",
    "    - base_dir (str): Base directory for models.\n",
    "    - versions (str or list): Single version or list of versions to process.\n",
    "    - fractions (str or list): Single fraction or list of fractions to process.\n",
    "    - tasks (str or list): Single task or list of tasks to process.\n",
    "    - models (str or list): Single model or list of models to process.\n",
    "    - test_type (str or list): Test type (e.g., 'zh_test').\n",
    "    Returns:\n",
    "    - dict: Loaded data indexed by parameter combinations.\n",
    "    \"\"\"\n",
    "    # Convert inputs into lists if they aren't already lists\n",
    "    if isinstance(versions, str):\n",
    "        versions = [versions]\n",
    "    if isinstance(fractions, str):\n",
    "        fractions = [fractions]\n",
    "    if isinstance(tasks, str):\n",
    "        tasks = [tasks]\n",
    "    if isinstance(models, str):\n",
    "        models = [models]\n",
    "    if isinstance(test_type, str):\n",
    "        test_type = [test_type]\n",
    "    \n",
    "    loaded_data = {}\n",
    "    # Loop over all combinations of the parameters\n",
    "    for v in versions:\n",
    "        for fraction in fractions:\n",
    "            for task in tasks:\n",
    "                for model in models:\n",
    "                    for test in test_type:\n",
    "                        dataset_name = f\"{model}_{v}_{fraction}_{task}_{test}\"\n",
    "                        try:\n",
    "                            print(f\"Loading data for {dataset_name}\")\n",
    "                            loaded_data[dataset_name] = model_loader(base_dir, v, fraction, task, model, test)\n",
    "                        except ValueError as e:\n",
    "                            print(f\"Failed to load {dataset_name}: {e}\")\n",
    "    return loaded_data\n",
    "\n",
    "# Example: Load data for ParticleTransformer with single version and task\n",
    "loaded_data = load_model_data(\n",
    "    BASE_MODEL_DIR,\n",
    "    version[0],\n",
    "    train_frac[0],\n",
    "    tasks[0],\n",
    "    models[0],\n",
    "    model_test_type[1]\n",
    ")\n",
    "\n",
    "# Access specific datasets after loading\n",
    "PT_jet_regression = loaded_data.get(\"ParticleTransformer_v1_trainfrac_1e4_jet_regression_zh_test\")\n",
    "# PT_dm_multiclass = loaded_data.get(\"ParticleTransformer_v1_trainfrac_1e4_dm_multiclass_z_test\")\n",
    "print(PT_jet_regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: False\n",
      "Is it a file?: False\n",
      "Can we read the file?: False\n"
     ]
    }
   ],
   "source": [
    "input_loc = \"/home/laurits/ml-tau-en-reg/training-outputs/20201204_ParT_ntrain_v2/v1/trainfrac_1e4/jet_regression/ParticleTransformer/zh_test.parquet\"\n",
    "print(\"File exists:\", os.path.exists(input_loc))\n",
    "print(\"Is it a file?:\", os.path.isfile(input_loc))\n",
    "print(\"Can we read the file?:\", os.access(input_loc, os.R_OK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input loc: /home/laurits/ml-tau-en-reg/training-outputs/20201204_ParT_ntrain_v2/v1/trainfrac_1e4/jet_regression/ParticleTransformer/zh_test.parquet Type: <class 'str'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected input_loc",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m PT_data \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mload_all_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/laurits/ml-tau-en-reg/training-outputs/20201204_ParT_ntrain_v2/v1/trainfrac_1e4/jet_regression/ParticleTransformer/zh_test.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m LN_data \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mload_all_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/laurits/ml-tau-en-reg/training-outputs/20240921_recoPtCut_removed_samples/v1/jet_regression/LorentzNet/zh_test.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m DS_data \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mload_all_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/laurits/ml-tau-en-reg/training-outputs/20240921_recoPtCut_removed_samples/v1/jet_regression/DeepSet/zh_test.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ml-tau-en-reg/enreg/tools/general.py:40\u001b[0m, in \u001b[0;36mload_all_data\u001b[0;34m(input_loc, n_files, columns)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput loc:\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_loc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m(input_loc))\n\u001b[0;32m---> 40\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected input_loc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected input_loc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpected input_loc"
     ]
    }
   ],
   "source": [
    "PT_data = g.load_all_data(\"/home/laurits/ml-tau-en-reg/training-outputs/20201204_ParT_ntrain_v2/v1/trainfrac_1e4/jet_regression/ParticleTransformer/zh_test.parquet\")\n",
    "LN_data = g.load_all_data(\"/home/laurits/ml-tau-en-reg/training-outputs/20240921_recoPtCut_removed_samples/v1/jet_regression/LorentzNet/zh_test.parquet\")\n",
    "DS_data = g.load_all_data(\"/home/laurits/ml-tau-en-reg/training-outputs/20240921_recoPtCut_removed_samples/v1/jet_regression/DeepSet/zh_test.parquet\")\n",
    "hps_data = g.load_all_data(\"/home/laurits/HPS_recoCut0_ntuples/zh.parquet\")\n",
    "recoJet_data = g.load_all_data(\"/home/laurits/ntuples/20240924_lowered_recoPtCut/recoJet/zh.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpsPlus_mask = hps_data.true_decay_mode == hps_data.pred_decay_mode\n",
    "cfg.metrics.regression.ratio_plot.resolution_plot.ylim = [0, 0.2]\n",
    "cfg.metrics.regression.ratio_plot.response_plot.ylim = [0.96, 1.04]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluators = {\n",
    "    \"HPS\":  re.RegressionEvaluator(hps_data.pred_pt, hps_data.true_pt, cfg.metrics.regression, \"zh\", \"HPS\"),\n",
    "    \"HPS_\":  re.RegressionEvaluator(hps_data.pred_pt[hpsPlus_mask], hps_data.true_pt[hpsPlus_mask], cfg.metrics.regression, \"zh\", \"HPS_\"),\n",
    "    \"RecoJet\":  re.RegressionEvaluator(recoJet_data.reco_jet_pt, recoJet_data.gen_tau_pt, cfg.metrics.regression, \"zh\", \"RecoJet\"),\n",
    "    \"PT\":   re.RegressionEvaluator(PT_data.jet_regression.pred, PT_data.jet_regression.target, cfg.metrics.regression, \"zh\", \"ParticleTransformer\"),\n",
    "    \"LN\":  re.RegressionEvaluator(LN_data.jet_regression.pred, LN_data.jet_regression.target, cfg.metrics.regression, \"zh\", \"LorentzNet\"),\n",
    "    \"DS\":  re.RegressionEvaluator(DS_data.jet_regression.pred, DS_data.jet_regression.target, cfg.metrics.regression, \"zh\", \"DeepSet\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/hardiveski/tmp/20240923_recoPtCut_removed_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "rme = re.RegressionMultiEvaluator(output_dir, cfg.metrics.regression, \"zh\")\n",
    "\n",
    "rme.combine_results([evaluator for evaluator in evaluators.values()])\n",
    "rme.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rme.resolution_lineplot.fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rme.response_lineplot.fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decay mode performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {sample: g.load_all_data(os.path.join(cfg.base_ntuple_path, sample + \".parquet\")) for sample in cfg.comparison_samples}\n",
    "\n",
    "for algorithm, algo_info in cfg.metrics.dm_reconstruction.algorithms.items():\n",
    "    for signal_sample in cfg.metrics.dm_reconstruction.signal_samples:\n",
    "        sig_info_data = data[signal_sample]\n",
    "        if not os.path.exists(os.path.join(algo_info.data_dir, signal_sample + \".parquet\")):\n",
    "            continue\n",
    "        sig_data = g.load_all_data(os.path.join(algo_info.data_dir, signal_sample + \".parquet\"))\n",
    "\n",
    "        output_dir = \"output_plots_dm\"\n",
    "        evaluator = dme.DecayModeEvaluator(sig_data.dm_multiclass.pred, sig_data.dm_multiclass.target, output_dir, signal_sample, algorithm)\n",
    "        evaluator.save_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

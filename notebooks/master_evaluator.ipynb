{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master notebook for evaluating  performaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import mplhep as hep\n",
    "import awkward as ak\n",
    "import matplotlib.pyplot as plt\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from enreg.tools import general as g\n",
    "from enreg.tools.metrics import (\n",
    "    regression_evaluator as re,\n",
    "    decay_mode_evaluator as dme,\n",
    "    tagger_evaluator as te\n",
    ")\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../enreg/config/\", job_name=\"test_app\"):\n",
    "    cfg = compose(config_name=\"benchmarking\")\n",
    "\n",
    "hep.style.use(hep.styles.CMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge sample_files:\n",
    "SAMPLE_DIR = {\n",
    "    \"z_test\": \"/scratch/persistent/laurits/ml-tau/20241002_Training_ntuples_geq20gev/\",\n",
    "    \"zh_test\": \"/scratch/persistent/laurits/ml-tau/20241002_Training_ntuples_geq20gev/\",\n",
    "    # \"qq\": \"/home/laurits/HPS_recoCut0_ntuples/QQ\"\n",
    "}\n",
    "\n",
    "MERGED_OUTPUT_DIR = \"/home/hardiveski/HPS_recoCut0_ntuples\"\n",
    "BASE_NTUPLE_DIR = \"/home/laurits/ntuples/20240924_lowered_recoPtCut\"\n",
    "\n",
    "\n",
    "def merge_sample_files(sample_dirs, sample, output_dir):\n",
    "    \"\"\"\n",
    "    what are sample files?\n",
    "    \"\"\"\n",
    "    print(sample_dirs)\n",
    "    print(sample)\n",
    "    sample_dir = sample_dirs[sample]\n",
    "    print(\"sample_dir value:\", sample_dir)\n",
    "    print(\"sample_dir type:\", type(sample_dir))\n",
    "    #os.path.join(sample_dir)\n",
    "    data = g.load_all_data(sample_dir, 2)\n",
    "    output_path = os.path.join(output_dir, f\"{sample}.parquet\")\n",
    "    print(f\"output path {output_path}\")\n",
    "    ak.to_parquet(data, output_path, row_group_size=1024)\n",
    "\n",
    "        \n",
    "def create_reco_entries(base_dir, sample, output_dir):\n",
    "    sample_wcp = os.path.join(base_dir, f\"{sample}*.parquet\")\n",
    "    data = []\n",
    "    for path in tqdm.tqdm(glob.glob(sample_wcp)):\n",
    "        d = ak.from_parquet(path, columns=['reco_jet_p4s', \"gen_jet_tau_p4s\"])\n",
    "        d = ak.Array({k: d[k] for k in d.fields})\n",
    "        data.append(d)\n",
    "    data = ak.concatenate(data)\n",
    "    data_to_save = {\n",
    "        \"reco_jet_pt\": g.reinitialize_p4(data.reco_jet_p4s).pt,\n",
    "        \"gen_tau_pt\": g.reinitialize_p4(data.gen_jet_tau_p4s).pt\n",
    "    }\n",
    "    output_dir = os.path.join(output_dir, \"recoJet\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f\"{sample}.parquet\")\n",
    "    print(f\"Saving to {output_path}\")\n",
    "    ak.to_parquet(ak.Record(data_to_save), output_path, row_group_size=1024)\n",
    "\n",
    "\n",
    "for sample in SAMPLE_DIR.keys():\n",
    "    merge_sample_files(SAMPLE_DIR, sample, MERGED_OUTPUT_DIR)\n",
    "\n",
    "# for sample in SAMPLE_DIR.keys():\n",
    "#     create_reco_entries(BASE_NTUPLE_DIR, sample, MERGED_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_data = g.load_all_data(\"/home/laurits/ml-tau-en-reg/training-outputs/20240921_recoPtCut_removed_samples/v1/jet_regression/ParticleTransformer/zh_test.parquet\")\n",
    "LN_data = g.load_all_data(\"/home/laurits/ml-tau-en-reg/training-outputs/20240921_recoPtCut_removed_samples/v1/jet_regression/LorentzNet/zh_test.parquet\")\n",
    "DS_data = g.load_all_data(\"/home/laurits/ml-tau-en-reg/training-outputs/20240921_recoPtCut_removed_samples/v1/jet_regression/DeepSet/zh_test.parquet\")\n",
    "hps_data = g.load_all_data(\"/home/laurits/HPS_recoCut0_ntuples/zh.parquet\")\n",
    "recoJet_data = g.load_all_data(\"/home/laurits/ntuples/20240924_lowered_recoPtCut/recoJet/zh.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpsPlus_mask = hps_data.true_decay_mode == hps_data.pred_decay_mode\n",
    "cfg.metrics.regression.ratio_plot.resolution_plot.ylim = [0, 0.2]\n",
    "cfg.metrics.regression.ratio_plot.response_plot.ylim = [0.96, 1.04]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluators = {\n",
    "    \"HPS\":  re.RegressionEvaluator(hps_data.pred_pt, hps_data.true_pt, cfg.metrics.regression, \"zh\", \"HPS\"),\n",
    "    \"HPS_\":  re.RegressionEvaluator(hps_data.pred_pt[hpsPlus_mask], hps_data.true_pt[hpsPlus_mask], cfg.metrics.regression, \"zh\", \"HPS_\"),\n",
    "    \"RecoJet\":  re.RegressionEvaluator(recoJet_data.reco_jet_pt, recoJet_data.gen_tau_pt, cfg.metrics.regression, \"zh\", \"RecoJet\"),\n",
    "    \"PT\":   re.RegressionEvaluator(PT_data.jet_regression.pred, PT_data.jet_regression.target, cfg.metrics.regression, \"zh\", \"ParticleTransformer\"),\n",
    "    \"LN\":  re.RegressionEvaluator(LN_data.jet_regression.pred, LN_data.jet_regression.target, cfg.metrics.regression, \"zh\", \"LorentzNet\"),\n",
    "    \"DS\":  re.RegressionEvaluator(DS_data.jet_regression.pred, DS_data.jet_regression.target, cfg.metrics.regression, \"zh\", \"DeepSet\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/hardiveski/tmp/20240923_recoPtCut_removed_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "rme = re.RegressionMultiEvaluator(output_dir, cfg.metrics.regression, \"zh\")\n",
    "\n",
    "rme.combine_results([evaluator for evaluator in evaluators.values()])\n",
    "rme.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rme.resolution_lineplot.fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rme.response_lineplot.fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decay mode performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {sample: g.load_all_data(os.path.join(cfg.base_ntuple_path, sample + \".parquet\")) for sample in cfg.comparison_samples}\n",
    "\n",
    "for algorithm, algo_info in cfg.metrics.dm_reconstruction.algorithms.items():\n",
    "    for signal_sample in cfg.metrics.dm_reconstruction.signal_samples:\n",
    "        sig_info_data = data[signal_sample]\n",
    "        if not os.path.exists(os.path.join(algo_info.data_dir, signal_sample + \".parquet\")):\n",
    "            continue\n",
    "        sig_data = g.load_all_data(os.path.join(algo_info.data_dir, signal_sample + \".parquet\"))\n",
    "\n",
    "        output_dir = \"output_plots_dm\"\n",
    "        evaluator = dme.DecayModeEvaluator(sig_data.dm_multiclass.pred, sig_data.dm_multiclass.target, output_dir, signal_sample, algorithm)\n",
    "        evaluator.save_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

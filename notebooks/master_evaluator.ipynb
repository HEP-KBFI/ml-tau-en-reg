{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master notebook for evaluating  performaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import mplhep as hep\n",
    "import awkward as ak\n",
    "import matplotlib.pyplot as plt\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from enreg.tools import general as g\n",
    "from enreg.tools.metrics import (\n",
    "    regression_evaluator as re,\n",
    "    decay_mode_evaluator as dme,\n",
    "    tagger_evaluator as te\n",
    ")\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../enreg/config/\", job_name=\"test_app\"):\n",
    "    cfg = compose(config_name=\"benchmarking\")\n",
    "\n",
    "hep.style.use(hep.styles.CMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"/home/hardiveski/ml-tau-en-reg/z_temp_output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training files\n",
    "\n",
    "# Training files base directory\n",
    "BASE_DATA_DIR = \"/scratch/persistent/laurits/ml-tau/20241002_Training_ntuples_geq20gev\"\n",
    "\n",
    "# Data directory\n",
    "SAMPLE_DIR = {\n",
    "    \"z_test\": os.path.join(BASE_DATA_DIR, \"z_test.parquet\"),\n",
    "    \"zh_test\": os.path.join(BASE_DATA_DIR, \"zh_test.parquet\"),\n",
    "    \"qq_test\": os.path.join(BASE_DATA_DIR, \"qq_test.parquet\"),\n",
    "    \"z_train\": os.path.join(BASE_DATA_DIR, \"z_train.parquet\"),\n",
    "    \"zh_train\": os.path.join(BASE_DATA_DIR, \"zh_train.parquet\"),\n",
    "    \"qq_train\": os.path.join(BASE_DATA_DIR, \"qq_train.parquet\"),\n",
    "}\n",
    "\n",
    "def train_data_loader(key):\n",
    "    \"\"\"\n",
    "    Returns ak.Array\n",
    "    \"\"\"\n",
    "    return g.load_all_data(SAMPLE_DIR[key])\n",
    "\n",
    "# z_test_data = train_data_loader(\"z_test\")\n",
    "zh_test_data = train_data_loader(\"zh_test\")\n",
    "# qq_test_data = train_data_loader(\"qq_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reco_entries(base_dir, key,  output_dir):\n",
    "    \"\"\"\n",
    "    Creates reconstruced stuffs\n",
    "    \"\"\"\n",
    "    data = ak.from_parquet(base_dir, columns=['reco_jet_p4s', \"gen_jet_tau_p4s\"])\n",
    "    data = ak.Array({k: data[k] for k in data.fields})\n",
    "    data_to_save = {\n",
    "        \"reco_jet_pt\": g.reinitialize_p4(data.reco_jet_p4s).pt,\n",
    "        \"gen_tau_pt\": g.reinitialize_p4(data.gen_jet_tau_p4s).pt\n",
    "    }\n",
    "    output_dir = os.path.join(output_dir, \"recoJet\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f\"{key}.parquet\")\n",
    "    print(f\"Saving to {output_path}\")\n",
    "    ak.to_parquet(ak.Record(data_to_save), output_path, row_group_size=1024)\n",
    "\n",
    "for idx, (key, value) in enumerate(SAMPLE_DIR.items()):\n",
    "    if idx == 2:\n",
    "        break\n",
    "    else:\n",
    "        create_reco_entries(SAMPLE_DIR[key], key, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training itself\n",
    "BASE_MODEL_DIR = '/home/laurits/ml-tau-en-reg/training-outputs/20201204_ParT_ntrain_v2'\n",
    "\n",
    "# Model types\n",
    "version = [\"v1\", \"v2\", \"v3\"]\n",
    "train_frac = [\"trainfrac_1e4\", \"trainfrac_1e5\", \"trainfrac_1e6\", \"trainfrac_2e3\"]\n",
    "tasks = ['jet_regression', 'dm_multiclass', 'tagger', 'binary_classification']\n",
    "models = [\"ParticleTransformer\", \"LorentzNet\", \"DeepSet\", \"HPS\",\n",
    "          \"OmniParT_from_scratch\", \"OmniParT_fine_tuning\", \"OmniParT_fixed_backbone\"]\n",
    "model_test_type = [\"z_test\", \"zh_test\"]\n",
    "\n",
    "def model_loader(base_dir, v, fraction, task, model, model_test_type):\n",
    "    full_directory = [os.path.join(base_dir, v, fraction, task, model, model_test_type + '.parquet')]\n",
    "    return g.load_all_data(full_directory)\n",
    "                                  \n",
    "PT_data = model_loader(BASE_MODEL_DIR, version[0], train_frac[0], tasks[0], 'ParticleTransformer', model_test_type[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_data = g.load_all_data(\"/home/laurits/ml-tau-en-reg/training-outputs/20240921_recoPtCut_removed_samples/v1/jet_regression/ParticleTransformer/zh_test.parquet\")\n",
    "LN_data = g.load_all_data(\"/home/laurits/ml-tau-en-reg/training-outputs/20240921_recoPtCut_removed_samples/v1/jet_regression/LorentzNet/zh_test.parquet\")\n",
    "DS_data = g.load_all_data(\"/home/laurits/ml-tau-en-reg/training-outputs/20240921_recoPtCut_removed_samples/v1/jet_regression/DeepSet/zh_test.parquet\")\n",
    "hps_data = g.load_all_data(\"/home/laurits/HPS_recoCut0_ntuples/zh.parquet\")\n",
    "recoJet_data = g.load_all_data(\"/home/laurits/ntuples/20240924_lowered_recoPtCut/recoJet/zh.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpsPlus_mask = hps_data.true_decay_mode == hps_data.pred_decay_mode\n",
    "cfg.metrics.regression.ratio_plot.resolution_plot.ylim = [0, 0.2]\n",
    "cfg.metrics.regression.ratio_plot.response_plot.ylim = [0.96, 1.04]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluators = {\n",
    "    \"HPS\":  re.RegressionEvaluator(hps_data.pred_pt, hps_data.true_pt, cfg.metrics.regression, \"zh\", \"HPS\"),\n",
    "    \"HPS_\":  re.RegressionEvaluator(hps_data.pred_pt[hpsPlus_mask], hps_data.true_pt[hpsPlus_mask], cfg.metrics.regression, \"zh\", \"HPS_\"),\n",
    "    \"RecoJet\":  re.RegressionEvaluator(recoJet_data.reco_jet_pt, recoJet_data.gen_tau_pt, cfg.metrics.regression, \"zh\", \"RecoJet\"),\n",
    "    \"PT\":   re.RegressionEvaluator(PT_data.jet_regression.pred, PT_data.jet_regression.target, cfg.metrics.regression, \"zh\", \"ParticleTransformer\"),\n",
    "    \"LN\":  re.RegressionEvaluator(LN_data.jet_regression.pred, LN_data.jet_regression.target, cfg.metrics.regression, \"zh\", \"LorentzNet\"),\n",
    "    \"DS\":  re.RegressionEvaluator(DS_data.jet_regression.pred, DS_data.jet_regression.target, cfg.metrics.regression, \"zh\", \"DeepSet\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/hardiveski/tmp/20240923_recoPtCut_removed_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "rme = re.RegressionMultiEvaluator(output_dir, cfg.metrics.regression, \"zh\")\n",
    "\n",
    "rme.combine_results([evaluator for evaluator in evaluators.values()])\n",
    "rme.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rme.resolution_lineplot.fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rme.response_lineplot.fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decay mode performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {sample: g.load_all_data(os.path.join(cfg.base_ntuple_path, sample + \".parquet\")) for sample in cfg.comparison_samples}\n",
    "\n",
    "for algorithm, algo_info in cfg.metrics.dm_reconstruction.algorithms.items():\n",
    "    for signal_sample in cfg.metrics.dm_reconstruction.signal_samples:\n",
    "        sig_info_data = data[signal_sample]\n",
    "        if not os.path.exists(os.path.join(algo_info.data_dir, signal_sample + \".parquet\")):\n",
    "            continue\n",
    "        sig_data = g.load_all_data(os.path.join(algo_info.data_dir, signal_sample + \".parquet\"))\n",
    "\n",
    "        output_dir = \"output_plots_dm\"\n",
    "        evaluator = dme.DecayModeEvaluator(sig_data.dm_multiclass.pred, sig_data.dm_multiclass.target, output_dir, signal_sample, algorithm)\n",
    "        evaluator.save_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
